\documentclass[10pt,twocolumn,preprint,natbib,authoryear]{sigplanconf}
\usepackage{verbatim}
\usepackage{color}
\usepackage{graphicx}
\bibpunct{[}{]}{,}{a}{}{;}

% force pdflatex to use A4 paper
\setlength{\pdfpagewidth}{210mm}
\setlength{\pdfpageheight}{297mm}

\usepackage{amsmath}
\usepackage{subfigure}

\newcommand{\editorial}[1]{\textcolor{red}{\footnote{\textcolor{red}{#1}}}}
%\newcommand{\editorial}[1]{}
\newcommand{\needCite}{\editorial{need cite}}
\newcommand{\smh}[1]{\editorial{SMH says: #1}}

\newbox\subfigbox             % Create a box to hold the subfigure.
\makeatletter
  \newenvironment{subfloat}% % Create the new environment.
    {\def\caption##1{\gdef\subcapsave{\relax##1}}%
     \let\subcapsave=\@empty % Save the subcaption text.
     \let\sf@oldlabel=\label
     \def\label##1{\xdef\sublabsave{\noexpand\label{##1}}}%
     \let\sublabsave\relax    % Save the label key.
     \setbox\subfigbox\hbox
       \bgroup}%              % Open the box...
      {\egroup                % ... close the box and call \subfigure.
     \let\label=\sf@oldlabel
     \subfigure[\subcapsave]{\box\subfigbox}}%
\makeatother

\begin{document}

\conferenceinfo{Eurosys 2011}{date, City.} 
\copyrightyear{2011} 
\copyrightdata{[to be supplied]} 

\titlebanner{Submitted to EuroSys'11}        % These are ignored unless
%\preprintfooter{short description of paper}   % 'preprint' option specified.

\title{Speculative Lock Insertion}
%\subtitle{Subtitle Text, if any}

% For double-blind reviewing:
\authorinfo{}{}{}
%\authorinfo{Name1}
%           {Affiliation1}
%           {Email1}
%\authorinfo{Name2\and Name3}
%           {Affiliation2/3}
%           {Email2/3}

\maketitle

\begin{abstract}

The recent move to multicore hardware means that synchronization bugs
(e.g.\ race conditions, atomicity violations) will become increasingly
common.  In this paper, we introduce Speculative Lock Insertion (SLI),
a new technique which can automatically fix some of these kinds of
bugs in program binaries. SLI starts with a reproduction of the bug,
uses a combination of static and dynamic analysis to characterize it,
and finally generates and applies a binary patch which fixes the
bug. We demonstrate the technique's effectiveness using both real and
artificial bugs, and discuss some of the implementation challenges and
limitations.

\end{abstract}

%% \category{D.2.5}{Testing and Debugging}{Debugging aids}

%% \terms
%% Reliability

%% \keywords
%% Synchronization, automated bug-fixing

\section{Introduction}

The increasing availability of multi-core and multi-processor systems
is driving a trend towards software with a greater degree of
parallelism, but, while potentially paying dividends in improved
responsiveness, throughput, and power consumption, multi-threaded
programming has an unfortunate tendency to lead to very subtle bugs.
Even worse, it is often difficult to trigger these bugs reliably,
which means that they are less likely to be discovered by testing and
harder to fix once they have been discovered.  A number of techniques
have been proposed for reducing the likelihood of such errors,
including transactional memory\cite{Shavit1997} and automatic
parallelization\cite{Bacon1994}, but these cannot be transparently
applied to the large body of existing concurrent software.  There is
therefore a need for techniques which can assist in fixing bugs in
programs written using the currently widely-used shared memory model
of concurrency.  In this paper, we introduce SLI, or Speculative Lock
Insertion, as one potential approach to this problem.  SLI
automatically fixes observed synchronization bugs, given only the
program binary and a reproduction of the bug, generating a modified
binary whose behavior is identical to that of the original except that
it no longer suffers from the bug.  Furthermore, the fixes will
usually have very low performance overhead, and the process of
generating the fix itself takes only a moderate amount of time
(ranging from seconds in simple cases to a few hours in more
complicated ones).  SLI does not depend on programmer annotations or
semantic knowledge of the program's intended behavior.

SLI does not attempt to fix every possible synchronization bug.
Instead, we consider bugs caused by one thread reading an in-memory
structure while some other thread is on the process of updating it and
an unfortunate interleaving causes the reading thread to crash.  There
are several key challenges here:

\begin{itemize}
\item Extracting a higher level abstract ``read operation'' from the
  crashing thread.  This consists of the memory loads which are
  relevant to the observed crash, plus the minimal amount of local
  computation required to tie them together (address computations, for
  instance).

\item Identifying memory regions which constitute a structure.  These
  regions do not need to be contiguous.  A structure might, for
  instance, be the first three entries in a linked list, or all of the
  nodes on a particular path through a DAG.\editorial{Really need to
    mention the DRS bit before here.}

\item Determining which stores issued by other threads might have
  raced with the read operation in a dangerous way.

\item Embodying the information obtained as a fix which can be applied
  directly to the program binary.
\end{itemize}

The first challenge is key; given a characterisation of the read
operation and a DRS log, the other three are straightforward.  We
represent abstract operations using state machines derived using a
combination of static analysis, applied to the program text, and
dynamic analysis, applied to the DRS log.  These state machines
characterise and approximate the parts of the crashing thread's
behaviour which are most relevant to the observed crash, allowing SLI
to extract the useful information from the vast sea of superfluous
detail provided by the DRS and hence to proceed to a useful
fix\editorial{A bit purple?}.

\section{Capturing the bug}

Before SLI starts, the bug to be fixed must first be captured using a
deterministic replay system (DRS).  This work does not attempt to
advance the state of the art in DRSes, but does depend on them in
order to be feasible, and so we discuss them briefly here.  The only
requirement we place on the choice of DRS is that it must allow us to
replay the relevant fragment of execution as many times as necessary
and produce the same sequence of memory accesses each time.  This
captured execution does not need to be precisely the same as the
original crashing execution (although excessive imprecision here could lead
to SLI fixing the wrong bug).  The most obvious way of capturing an
execution, used in our prototype, is to simply record every single
memory access issued by the program, which is effective but has
extremely high overhead.  This could be reduced by using a more
intelligent recording mechanism such as PRES or ODR\cite{Altekar2009},
both of which record only a few critical events and discover the rest
only when they are needed during replay.  This can reduce overhead to
a level where it is sensible to run with recording enabled by default.
ESD\cite{Zamfir2010} is an extreme form of this approach, and logs
nothing at all but instead attempts to recreate the path to failure
given just the state of the program at the time of the crash.  In a
slightly different context, an automatic program exerciser such as
CHESS\cite{Musuvathi2008} could be used to detect unknown bugs, which
could then be passed to SLI to be automatically characterized and
fixed.\editorial{I want to use the phrase closed-loop here}

\section{Building abstract read operations}
\label{sect:build_state_machines}

The first phase of our algorithm is to identify the abstract read
operation which the program was performing when it crashed, and to
reify.  We start by using a dynamic analysis on the DRS log to
determine the first dynamic instruction at which the program has
definitely gone wrong, and to produce a direct explanation of the
crash considering only that instruction.  This might, for instance,
indicate that the program crashed because the instruction at address
\verb|40037e| dereferenced register \verb|rdi| which contained an
invalid pointer.  This is referred to as the proximal cause of the
crash, and is generally a trivial single-state state machine.  We then
expand upon this cause, finding earlier causes by translating it
backwards through the captured log using a scheme which combines both
static and dynamic analyses.  During this process, the cause will
usually become more complex.  The result of this phase of the
algorithm is a series of state machines which approximate steadily
growing suffixes of the crashing thread's execution, and which can be
treated either as ``explanations'' of the crash or as logical
operations performed by the thread towards the end of its life.

\begin{figure*}
 \begin{subfloat}
  \begin{minipage}{90mm}
\begin{verbatim}
A: mov (global1) -> %rax
B: mov %rax -> (%rsp)
C: cmp $0, %rax
D: jne F
E: mov &fallback -> (%rsp)
F: mov (%rsp) -> %rcx
G: mov (%rcx) -> %rdx
H: add $48, %rdx
J: mov (%rdx) -> %rax
K: ret
\end{verbatim}
  \end{minipage}
  \caption{Thread 1}
 \end{subfloat}
 \begin{subfloat}
  \begin{minipage}{90mm}
\begin{verbatim}
V: mov &struct1 -> (variable1)
W: mov &variable1 -> (global1)
...
X: mov $0 -> (global1)
Y: mov $0 -> (variable1)
...
Z: jmp V



\end{verbatim}
  \end{minipage}
  \caption{Thread 2}
 \end{subfloat}
 \caption{A buggy example of the privatize synchronization pattern.}
 \label{fig:broken_privatize}
\end{figure*}

We use a running example, shown in figure \editorial{...}, to
illustrate some of the details of our approach.  The example shows a
buggy instance of the common structure privatization pattern in an
x86-like assembly language.  Thread 2 initializes (\verb|V|) and
publishes (\verb|W|) a structure, does some unrelated work, and then
attempts to privatize (\verb|X|) and de-initialise (\verb|Y|) the
structure.  Meanwhile, thread 1 loads the pointer published by thread
2 (\verb|A|), checks whether it is valid (\verb|B|, \verb|C| and
\verb|D|), and, if it is not, loads a fallback version (\verb|E|),
before attempting to use it (\verb|F| through \verb|J|).  This will
lead to a crash if instructions \verb|X| and \verb|Y| occur between
instructions \verb|A| and \verb|G|, as in that case \verb|rdx| will
contain a bad pointer at instruction \verb|J|, which will cause an
immediate crash.  Figure \ref{fig:example_machines} then shows some of
the state machine generated by our algorithm.

\subsection{The proximal cause}
\label{sect:prox_cause}
The first step is to locate the first point in the log at which
something has definitely gone wrong, and hence to obtain the most
direct cause of the crash and to nominate one thread as being directly
responsible for it.  A naive approach would simply use the point at
which the program crashed.  In principle, this is always correct, and
for some simple bugs, such as \verb|NULL|-dereferences or assertion
failures, it works well.  However, for more complicated classes of
bugs, such as use-after-frees, there can be a significant lag between
the first definitely bad behavior (such as the use of released memory)
and the program crash, which can complicate later phases.  This can be
mitigated by applying a dynamic analysis tool, such as
Valgrind\cite{Nethercote2007}, to the captured execution, which
provides a more accurate starting point for the rest of the analysis.
We have implemented a simple analysis to detect use-after-free bugs at
the first reference to released memory as part of our prototype;
combining this with other forms of analysis or with
application-specific knowledge would be straightforward, and would
allow other classes of bugs to be detected.

The result of this initial analysis is generally a single-state state
machine which captures the reason for the crash using only information
which is available at the instruction on which the error is detected;
for the example, it is shown in figure~\ref{fig:example_machines:1}.

\subsection{Deriving earlier state machines}
This proximal cause is accurate but not, by itself, sufficient to
derive a fix, as by the time the faulty instruction is executed it is
usually too late to attempt to fix it.  It is therefore useful to move
the expression backwards through the captured execution, and hence to
determine an equivalent expression which can be evaluated earlier in
the execution.  We do this inductively, moving back one instruction at
a time through the DRS log.  There are three main classes of relevant
instructions: register-register arithmetic instructions, memory
accesses, and branches; we consider each in turn (more complicated
instructions can generally be treated as combinations of these basic
classes).

\subsubsection{Arithmetic instructions}

We assume, by induction, that we have a state machine corresponding to
the point immediately after the instruction in question, and we wish
to construct one corresponding to a point immediately before it.  If
the register-register arithmetic instruction is regarded as a
transformation on the program's register state then this can be
accomplished by applying the same transformation to the given state
machine.  For instance, in the example in
figure~\ref{fig:broken_privatize}, the instruction preceding the
proximal cause is \verb|add $48, %rdx|.  This transforms \verb|rdx|
into \verb|rdx+48|.  Applying this transformation to the proximal
cause of the crash produces the state machine shown in
figure~\ref{figure:example_machines:2}, which is valid at the start of
instruction \verb|H|.  Other simple register-to-register arithmetic
instructions can be handled in the same way, and hence the crash
reason can be backtracked across any sequence of such
instructions.\editorial{The reason this works is something to do with
  the underlying category of state machines being linear with respect
  to register-register instructions expressed as homomorphisms, but a)
  that's not really the kind of thing you say in a systems paper, and
  b) I don't understand it well enough to explain it correctly,
  anyway.}

\editorial{Our implementation uses libVEX to decode x86 instructions
  into a sequence of micro-operations which can be used as input to
  this process.} 

\subsubsection{Memory accesses}

Memory accesses are more difficult to handle, for three main reasons:

\begin{itemize}
\item The pointer aliasing problem\needCite{}: given a load and a
  store, it is not always clear whether they access the same memory
  location.
\item Non-determinism: due to the actions of other threads, it cannot
  be assumed that loading the same location twice will produce the
  same result.
\item Temporality: the exact order in which loads and stores are
  issued is often important in the kinds of synchronisation bugs which
  SLI targets, but the transformation-based approach used for
  arithmetic instructions does not preserve it.
\end{itemize}

We avoid these problems by leaving memory accesses explicit in the
state machines.  Loads are represented by special \verb|load|
expressions, tagged with the instruction which issued them, while
\verb|store|s are listed on the edges of the state machines.

For example, the state machine for instruction \verb|H| shown in
figure~\ref{fig:example_machines:2} can be backtracked to the start of
instruction \verb|G| to produce the state machine shown in
figure~\ref{fig:example_machines:3}, and then backtracked to the start
of \verb|F| to produce the machine shown in
figure~\ref{fig:example_machines:4}.  The production of machine
\ref{fig:example_machines:B} from \ref{fig:example_machines:C} shows
how stores are recorded.

Because the memory accessing instructions remain explicit in the state
machines, we do not need to be able to determine whether two pointers
alias.  This is fortunate, as doing so is difficult, even in a more
conventional model checking environment where higher-level information
and programmer annotations are available.  The downside of not
resolving aliasing problems is that we are less able to apply advanced
theorem proving and model checking algorithms to the state machines
themselves, and later stages of the analysis must be designed around
that.

Accesses to the local stack are an important exception.  Cross-thread
accesses to the stack are extremely rare, while intra-thread accesses
are extremely common, and so treating every stack access as
potentially involved in the race significantly complicates the
analysis for little gain in power.  We therefore use a simple
heuristic, based on the contents of the DRS log, to attempt to resolve
these accesses.  When we encounter a store instruction, we check
through the DRS log to determine whether it stored to the stack, and,
if it did, which loads then loaded the stored value.  If any of those
loads occur in the state machine after the store instruction then we
assume that they will always load the stored value, and so eliminate
them.\editorial{Now I think about it some more, I'm pretty much
  convinced that this is a really stupid thing to have done.  Hmm.  In
  addition to being not very safe, it's also not very useful.  I don't
  really want to have to re-do all of the evaluation with this turned
  off, though, which means I need to come up with a justification of
  some sort.}

\subsubsection{Branch instructions}\editotial{Move before memory accesses section.}
\label{sect:branch_instrs}
Branch instructions also require care, as they may involve parts of
the program which were not used in the captured execution and for
which no state machines will be available.  One simple approach would
be to assume that taking such branches is sufficient to avoid the
crash.  Unfortunately, this is often not true: there are often
irrelevant and distracting branches in the region of code to be
examined, and they must be eliminated.  Consider, for instance, this
example:

\begin{verbatim}
1   p = global_ptr;
2   assert(p->need_frob);
3   if (p->need_churn)
4       churn(p->bar->bazz);
\end{verbatim}

Assume that the program was observed to crash on line 4 because some
other thread was updating the structure and set \verb|need_churn|
before setting \verb|bar|.  Presumably, the assertion on line 2 was
true in this instance, and so naively assuming that any changes to the
control flow are sufficient to avoid a repeat of the crash would cause
SLI to attempt to fix the crash by making the assertion always
evaluate to false.  This is unlikely to lead to an acceptable fix.

We determine the effects of unexecuted code using a simple static
analysis.  The first stage of this analysis is to build an
approximation of the program's control flow graph starting from the
branch instruction and stopping when we encounter an instruction for
which we already have a state machine\footnote{We also impose a limit
  on the number of instructions examined, but this was not reached in
  any of our experiments.}.  These state machines can then be
propagated backwards through the graph exactly as if the instructions
had been executed in the dynamic trace, allowing us to assign a state
machine to the root of the graph and hence to the original branch
instruction.

\begin{figure*}[t]
\subfigure[Instruction D]{\includegraphics[scale=0.35]{diagrams/statementD.pdf}
  \label{fig:state_machines_instr_d}}
\subfigure[Instruction A]{\includegraphics[scale=0.35]{diagrams/statementA.pdf}
  \label{fig:state_machines_instr_a}}
\caption{State machines produced for the example program}
\end{figure*}

In the example, the next instruction which must be assigned a state
machine is \verb|D: je F|, as that preceded instruction \verb|F| in
the captured trace.  It is followed by instruction \verb|F|, which
already has a state machine, and \verb|E|, which does not, and
\verb|E| is followed by \verb|F|.  The CFG therefore contains just
three nodes, representing \verb|D|, \verb|E|, and \verb|F|, with edges
from \verb|D| to \verb|E| and \verb|F| and one from \verb|E| to
\verb|F|\editorial{Diagram?}.  We then proceed to derive a state
machine for \verb|E|, which is a simple store to a stack location.
Assuming that this store was ever executed in the captured execution,
the stack resolution heuristic will predict that the load at \verb|F|
will load the stored value.  The load will therefore be eliminated,
and so the state machine for instruction \verb|E| will be

\begin{verbatim}
if BadAddr (load(fallback@G)+48)
 then crash
 else no-crash
\end{verbatim}

\noindent
It is now possible to combine the machines for \verb|E| and \verb|F|
to produce one for \verb|D|.  This is illustrated in figure
\ref{fig:state_machines_instr_d}.  Backtracking further to instruction
\verb|A| will then produce the state machine illustrated in figure
\ref{fig:state_machines_instr_a}.

Note that identical state machines would have been derived if the
program had not taken the branch immediately before crashing (which
might happen if the \verb|fallback| structure was itself invalid); the
only difference is that \verb|E|'s state machine will be derived from
the captured execution rather than a hypothetical execution generated
by static analysis.  This is useful: by eliminating uninteresting
aspects of the observed behavior, SLI is able to generalize from one
crash to closely related ones, and hence fix them at the same time,
without eliminating an excessive number of safe schedules.  This
example also illustrates that the stack resolution heuristic is not
equivalent to assuming a completely static data flow graph, as it is
interleaved with control flow discovery and hence respects simple
control-flow dependencies.  Separating the two processes into
independent phases would lose this property, and result in far less
accurate characterizations.\editorial{ref phase order problem?}

\editorial{It also kind of shows why we need to dick about with
  untaken branches at all: it allows us to prove that they're
  irrelevant (or not), and hence means that we get a more accurate
  characterisation and better fixes.}

Indirect branches, and any other branches which compute their target
dynamically, pose an additional challenge here, as it is often
difficult to statically predict the target of the branch.  The most
common case is return instructions, and we handle these by inlining
called functions, eliminating most return instructions completely.
The remainder correspond to functions which had started but not
completed at the time of the crash, and we assume that if any of those
return then the bug has been avoided.

Other indirect branch instructions are more challenging.  We solve
this problem by using the captured trace as a simple oracle: if the
branch instruction exists in the dynamic trace, we assume that the
instruction will always branch to the same place (if it occurs several
times then we use the last target).  If the instruction did not occur,
we place a special analysis-failed node in the graph.  Once the CFG is
complete, we eliminate all branches to these failed nodes; if that
causes some node to have no known successors then that node is also
marked as analysis-failed, and the process iterates until all failed
nodes are removed.  Branches taken in the captured execution will
always be preserved at this stage, as the oracle will always be able
to provide at least some prediction of their target.  As such, this
step can be seen as pruning the set of paths considered to be only
those which are sufficiently similar to the captured execution.

Loops also complicate this simple algorithm.  We avoid the problem by
breaking them, removing a subset of the graph's edges so as to
eliminate the loop.  We choose edges to remove based on two
heuristics.  First, we try not to remove any edges which are present
in the captured execution.  Second, we try not to partition the graph,
so as many instructions as possible, and hence as much of the
program's behavior as possible, are represented in the final state
machine.

Breaking loops has the useful side-effect of disambiguating the labels
used to refer to load instructions: in a loop-free control flow graph,
each instruction is executed at most once, and so dynamic instructions
can be referred to unambiguously by their static location in the CFG.
In the case of the x86 architecture, all common instructions which
perform multiple loads can be converted into loops, which can then be
broken in the usual way, and so this is sufficient to ensure that any
static instruction issues at most one dynamic load and hence that load
labels refer to at most one load.

\section{Identifying relevant structures}

Once the abstract read operation has been suitably characterised, the
next step is to discover memory structures to which it can be applied.
Rather than attempting to represent these (potentially complicated)
structures explicitly, we instead represent them as specialisations of
the already-derived state machines.  In other words, we take each
state machine and convert it into a set of closely-related state
machines, each of which will check one particular dynamic instance of
the structure to be examined.  This has the useful side-effect of
eliminating any remaining references to registers or other
thread-local state, effectively ``detaching'' the state machine from a
particular point in the program's execution and allowing it to be
applied to other memory configurations.

We rely on the DRS log in order to achieve this.  Our approach is
simply to identify all points in the log which are ``similar'' to the
point for which the state machine was originally derived and to create
a specialisation for each by substituting in appropriate constant
values for all references to thread-local state such as registers,
stack locations, thread-local storage.  This often results in the
construction of duplicate state machines, and these are eliminated in
the obvious way\editorial{Someone complained that the previous draft
  didn't specify the definition of duplicate, but I really can't be
  bothered to spell it out.}.

Similar is defined here to mean that the instruction pointer and call
stack match.  Other definitions would also be possible.  All that SLI
requires for correctness is that the point for which the machine was
derived is similar to itself.  A more flexible definition would allow
more dynamic instances of the structure to be discovered, and so more
potentially-conflicting updates would be discovered and a more
complete fix could be generated, but would increase the risk of
unrelated concrete operations being falsely identified as instances of
the dynamic operation, and hence memory locations being falsely
labelled as dynamic instances of the structure to be synchronized, and
hence the generation of overly-pessimistic fixes\editorial{Holly run
  on sentence, Batman.}.  We have not investigated this trade off in
any detail.\editorial{I don't actually have any evidence that this
  actually helps you; blah.}

Dynamically allocated memory complicate this simple procedure.  The
specialisations, as described, in effect assume that memory locations
which are shared between threads have a form of type-stability in the
region of interest.  We mitigate\editorial{\emph{Should} mitigate; at
  the moment I completely ignore it.  That doesn't make any difference
  for any of my current tests, but would do for more realistic ones.}
this by limiting the range over which the specialised state machines
are applicable.  Newly-created specialised state machines are
evaluated at the point in the log at which they are constructed, and a
record kept of the memory locations which they access.  If any of
these locations were obtained through a known dynamic allocator then
the machine is restricted so that it is only used between the point at
which that memory was last allocated and the point at which it is
released (and if multiple locations are dynamically allocated then
their ranges of validity are intersected).  This effectively weakens
the type-stability assumption, from assuming that a particular memory
location always has a particular type to assuming that it can only be
re-typed after being released and re-allocated.

We still assume that the read operation can be applied at any point
where the memory structure has the correct type, and ignore any
existing synchronisation or control flow properties of the program
which would restrict the situations in which it could be
used\footnote{This assumption also implies that we can identify all of
  the program's memory allocation APIs.}.  If this assumption is false
then SLI will produce an overly-conservative fix, synchronising the
read operation against write operations with which it could never
actually race, fixing the bug but with unnecessarily high performance
overhead.  This could be ameliorated using programmer-supplied
semantic annotations, but we have not needed to do so yet.

\section{Discovering possible racing write operations}
\label{sect:multi_threading}

Once the read operation has been identified and a suitable selection
of dynamic instances of the racing structure discovered, SLI can
proceed to investigate the crashing operation's interactions with
other threads, and thence to determine what additional synchronisation
would be necessary to prevent the observed crash.  Our approach has
two stages.  First, we determine which stores could possibly conflict
with loads of memory locations used by the read operation; this allows
us to make the read operation behave as-if atomically.  Second, we
determine if there are any regions in the DRS log where executing the
read operation atomically would still crash; these generally
correspond to update operations against which the read operation must
be synchronised.

Determining the possibly-conflicting stores is straightforward.  We
already have, from the previous stage, a list of the memory locations
which each state machine loads, and it is then simple to use the DRS
log to discover all instructions which store to one of those
locations.  We use the same validity range restricting trick to model
the effects of dynamic memory allocation APIs.

To determine the regions of the log when a state machine would crash,
we replay the log over the range of validity of the state machine and
evaluate the state machine before and after every possibly-conflicting
store instruction.  In many cases, the machine will always evaluate to
\verb|no-crash|, which indicates that the read operation is always
safe when executed atomically and so no further synchronisation needs
to be added.  If the operation is not always safe to execute
atomically then there will (hopefully) be some \verb|crash| regions in
the log.  If the starting end ending stores of the region are issued
by the same thread then this corresponds to a simple update of the
memory structure, and all that is needed is for the relevant range of
instructions in the storing thread to be synchronised to not run in
parallel with the read operation.  Otherwise, the update operation
spans several threads, and SLI is unable to generate a fix.  In that
case, we simply ignore the crashing region and synchronise against any
remaining stores.\editorial{The actual mechanism I use for doing this
  is similar to but not identical to this (because I screwed up the
  implementation); need to make it be identical and re-run the
  evaluation.}

We now have, for each specialised state machine:

\begin{itemize}
\item A list of the loads which it issues which might be involved in a
  race.
\item A list of ranges of the dynamic execution where issuing the
  read operation might be unsafe.
\item A list of all of the store instructions which might race with
  the read operation.
\end{itemize}

The task is to combine these, across all of the state machines, and
synthesise from them an appropriate fix for the observed bug.  For
SLI, the fix will consist of a newly-created global (recursive) lock
plus a number of lock acquire and release operations.  We must use
these to ensure that the read operation does not occur in parallel
with any of the store instructions, and does not occur during any of
the unsafe ranges.

First, notice that the store instructions can be treated as
single-instruction ranges, and so do not need to be explicitly
handled.  Likewise, the load operations can be bundled into another
range\editorial{Actually, no they can't, but explaining the details is
  surprisingly tricky.}, and so all that is actually required is a
scheme for ensuring that two ranges of instructions do not race with
each other.

We now simplify the problem by expanding the dynamic ranges such that
their start and end points are in the same dynamic function
invocation.  To do this, we annotate each point in the DRS log with
the call stack which was in effect at the time, find the longest
common prefix of the start and end point call stacks, and declare the
actual start of the range to be the last point prior to the previous
start where that prefix was the entirety of the stack and the actual
end to be the first point after the previous end where that prefix was
the entirety of the stack\editorial{Huh?}.

We now have a list of instructions before which we need to acquire the
lock and a list of instructions after which we must release it, and
the additional constraint that any lock acquisition must be undone
before the containing function returns.  We then consider a function
at a time\editorial{Do I need to say how I identify functions?}.  We
build a control flow graph (CFG) for each, starting from the lock
acquiring instructions and moving outwards until we reach the end of
the function.  We then trim this CFG to remove any instructions which
definitely cannot reach a lock release operation before the function
returns.  All of the instructions which remain in the CFG are then
duplicated (being careful to update any instruction-pointer relative
addresses as appropriate), and appropriate synchronisation added: lock
acquires at the entry points, and lock releases whenever the new code
branches back into the existing code.  The lock acquiring instructions
in the original code and then modified to branch to the new
code.\editorial{Something about effectively taking the union of all
  proposed synchronisation?}  The resulting code is then compiled into
an ELF shared library which can be loaded into the target program
using \verb|LD_PRELOAD| (or an equivalent mechanism) and which will
apply the generated fix.

Duplicating the code to be patched in this way is useful because it is
impossible to be confident, without additional information, that SLI
has discovered every possible branch into the locked region, and so
inserting unlock operations directly would carry a risk of the program
releasing the lock without first acquiring it.  It is necessary that
the lock is only released by a releasing instruction if the thread has
previously passed through a locking instruction and acquired the lock;
the code duplication strategy achieves exactly this (assuming that the
patched program does not, for instance, \verb|longjmp| out of a
function called from the patch, which we do not correctly handle).

Modifying acquiring instructions to branch to the new code is
sometimes difficult, as the instruction to be patched might be too
small to encode a branch instruction, and enlarging an instruction is
dangerous unless one is able to prove that the following instruction
is never the target of a branch.  SLI avoids this issue by using the
processor's debugging facilities to set breakpoints on the acquiring
instructions, and then transferring to the new code from the relevant
exception handler.  On x86 architectures, the breakpoint instruction
is a single byte, and so always fits in the instruction to be patched.

There is also a risk that the proposed patch will introduce a
deadlock.  We avoid this issue with a simple timeout scheme: if a
thread takes more than a second to acquire an SLI-introduced lock, it
will time out, and immediately branch back to the unpatched code.
This is sufficient to ensure forward progress, but renders the
purported fix ineffective and could lead to very poor performance.
Fortunately, it has not been a problem for us so far.

\subsection{Selecting a fix}
\label{sect:selectfix}

This process might produce multiple possible fixes if multiple state
machines are available, and it is then necessary to select an
appropriate one to instantiate into a binary patch.  Some can be
discarded by very simple heuristics (for instance, fixes in which
every critical section is a single access can be immediately
eliminated), but there will in general be multiple possible fixes to
choose from.  We use a very simple cost heuristic to do so: the cost
of a fix is given by $U.n_u + C_s.n_s + {\sum_{i}}s_i$ where $n_u$ is
the number of crashing regions which we discarded because they started
and ended on different threads, $n_s$ is the total number of critical
sections, $s_i$ is the number of accesses in the $i$th critical
section, and $C_s$ and $U$ are constants reflecting the cost of
introducing a new empty critical section and of only partially fixing
the bug.  SLI then selects the candidate fix with the lowest cost.
Our prototype sets $U=1000$ and $C_s=10$, strongly preferring fixes
for which all unsafe states can be eliminated and weakly preferring
fixes with a smaller number of critical sections.

This simple heuristic has worked well in our experience to date
(\S\ref{sect:evaluation}), as there are generally only a small number
of possible fixes, all of which are correct and none of which would
obviously lead to pathological performance.

\subsection{Example}\editorial{This needs rewriting.}
\label{sect:final_example}

Our earlier example derived the state machine shown in figure
\ref{fig:state_machines_instr_a} for the program shown in figure
\ref{fig:broken_privatize}.  The list of relevant addresses for this
state machine will be \verb|global1|, \verb|fallback| and
\verb|variable1|.  Note that the load in instruction \verb|J| is
\emph{not} represented in this list: the value which it loads does not
affect whether or not the program crashes, and so it is not considered
relevant for these purposes.

\begin{table}
\begin{tabular}{ll}
 Store & Specialization predicts \\
       & crash before instruction \\
\verb|V.1 &struct1 -> variable1| & Yes\\
\verb|W.1 &variable1 -> global1| & No\\
\verb|X.1 0 -> global1| & No\\
\verb|Y.1 0 -> variable1| & No\\
\verb|V.2 &struct1 -> variable1| & Yes\\
\verb|W.2 &variable1 -> global1| & No\\
\verb|X.2 0 -> global1| & No\\
\verb|Y.2 0 -> variable1| & No\\
...
\end{tabular}
\caption{Relevant store log for example}
\label{tab:relevant_stores}
\end{table}

Assuming that the only stores to relevant addresses are those shown in
figure \ref{fig:broken_privatize}, the relevant store log will then be
as shown in table \ref{tab:relevant_stores}.  The state machine does
not depend on registers or the thread-local stack, and so
specialization will have no effect, and we proceed directly to
classifying the store log into crashing and non-crashing components.
In this particular case, the state machine will predict that no state
can crash, which is correct: if the loads in the state machine had
executed atomically, with respect to the stores present in the store
log, the program would not have crashed.  This suggests a potential
fix with five critical sections: one covering instructions \verb|A| to
\verb|G| in thread 1, and a single-instruction critical section for
each of instructions \verb|V|, \verb|W|, \verb|X|, and \verb|Y| in
thread 2.  This would fix the bug, and will be suggested by
SLI.\editorial{Not a minimal fix...}

This is not the only fix which will be suggested, however.  State
machine generation will also have produced machines for other
instructions in the crashing thread.  In particular, the machine
produced for instruction \verb|F| will be:

\begin{verbatim}
if BadAddr (load(load(rsp@F)@G)+48)
 then crash
 else no-crash
\end{verbatim}

\noindent
As this accesses both registers and the stack, it can be specialized,
producing two new machines:

\begin{verbatim}
if BadAddr (load(variable1@G)+48)
 then crash
 else no-crash
\end{verbatim}

and

\begin{verbatim}
if BadAddr (load(fallback@G)+48)
 then crash
 else no-crash
\end{verbatim}

\noindent
The captured execution shows no writes to \verb|fallback|, and so the
\verb|load| in the second machine is replaced with a constant and the
entire machine is subject to constant folding, producing the trivial
machine \verb|no-crash|.  It is therefore discarded.  The first
machine, however, predicts a crash whenever \verb|variable1| contains
something which is not a valid pointer, which occurs from \verb|Y.1|
to \verb|V.2| in the store log (and subsequently as thread 2 loops).
This suggests an alternative fix with two critical sections: one
single-instruction critical section covering instruction \verb|G| in
thread 1, and a second covering \verb|Y| to \verb|V| in thread 2 (the
second section will wrap around the loop, which somewhat complicates
the implementation of the binary patcher; see \S\ref{sect:binpatch}
for our approach to this problem).  This fix will also be suggested by
SLI, and would also fix the bug.  Furthermore, because it has fewer
critical sections, it will be preferred by the prioritisation
heuristic.

It could be argued, however, that this smaller fix is inferior to the
larger alternative, despite completely eliminating the crash and
potentially imposing lower overhead, as it is less ``sympathetic'' to
the existing structure of the program.  The author of thread 2 had
presumably intended to privatize the structure at instruction
\verb|X|, and so might reasonably have defined a ``correct'' fix to be
one which ensures correct privatization, a goal which is achieved by
the first fix but not by the second.  SLI, by contrast, has no notion
of intended behavior, or indeed any form of good software engineering
practice, and so selects its fix based on the more mundane concerns of
avoiding the crash and minimizing the impact on performance.  This is
both a strength and a weakness: a strength in that it increases the
likelihood that a low-overhead fix will be found, and a weakness in
that the fixes cannot be translated back to source-level patches and
applied unthinkingly by the application programmer.

Producing a long-term, maintainable fix for a bug is, in general, a
different problem to producing a short-term one which simply
eliminates its symptoms, and the techniques used by SLI are much more
applicable to the latter.  This will be true of any approach which
does not rely on programmer annotations (ignoring trivial systems
which just pattern-match the buggy code against a library of common
bugs and their standard fixes).

%; the extra flexibility gained by being applicable to arbitrary
%binaries makes this a reasonable trade-off.

\section{Evaluation}\editorial{This needs re-doing as well.}
\label{sect:evaluation}

\begin{table*}
\begin{tabular}{lllllll}
Name of test & Nature & Number & Time taken & Size of & Number of & Total number of state\\
 & & of fixes & (seconds) & logfile & state machines & machine states\\
\hline
toctou & Synthetic TOCTOU & 1 & $1.18 \pm 0.02$ & 28MiB & 8 & 20\\
%       & TOCTOU & & & \\
twovar & Synthetic two-variable & 2 & $1.89 \pm 0.03$ & 31MiB & 8 & 22\\
       & atomicity violation &&&\\
publish & Synthetic broken & 2 & $1.15 \pm 0.02$ & 31MiB & 5 & 16 \\
        & publish pattern & & & \\
privatize & Synthetic broken & 2 & $5.11 \pm 0.05$ & 43MiB & 5 & 16 \\
          & privatize pattern & & & \\
\hline
glibc & Kernel of a genuine & 6 & $8.15 \pm 0.03$ & 48MiB & 10 & 52\\
      & atomicity violation & & & \\
\hline
thunderbird & Genuine TOCTOU & 1 & $4740 \pm 6$ & 758MiB & 6 & 14
\end{tabular}
\caption{Summary of results obtained from running the fix generating
  tool on a single log file collected from each bug.  The ``Time taken''
  column gives the mean and standard deviation from five runs.}
\label{tab:perf_summary}
\end{table*}

As shown in table \ref{tab:perf_summary}, our prototype implementation
is able to fix a reasonable selection of artificial bugs within a few
seconds, given only the program binary and a log which shows the bug
reproducing, and is able to fix at least one real-world bug within an
hour and a half.  The data also shows that the prototype avoids state
machine explosion, generating only a small number of distinct state
machines each of which has only a small number of states (a little
over three on average, and in no case more than fourteen).  All
experiments were conducted on an Intel Q6600 with 8GiB of RAM running
64-bit Linux 2.6.28.

\begin{figure*}
\subfigure[Length of the phases, as fractions of the entire
  fix-generating process.]{ \includegraphics[trim=8mm 0 20mm
    0]{timing/timings.pdf}
  \label{fig:phasedistribution}
}\hspace{10mm} \subfigure[Absolute length of the phases, ignoring time
  spent in the replay engine.]{ \includegraphics[trim=8mm 0 10mm
    0]{timing/without_replay.pdf}
  \label{fig:timesignoringreplay}
}
\caption{Breakdown of time spent in various phases of the analysis
  process.  Results presented are mean and standard deviation of five
  runs of the fix-generating program applied to a single log file for
  each bug.}
\end{figure*}

Figure \ref{fig:phasedistribution} shows how the time taken is
distributed between the phases of the fix generation process.  Two
main conclusions can be drawn from the figure.  First, constructing
the state machines is very quick for all of these tests, and is barely
visible in the graph.  This is reassuring, and suggests that the
algorithm is able to discard parts of the program's execution which
are not relevant to the observed crash quickly, so should be able to
scale up to more complicated bugs in a reasonably straightforward
way\editorial{Not sure I believe that}.  Second, for the very
long-running \verb|thunderbird| test the running time is completely
dominated by the phases which involve replaying the log.  This
suggests that improvements to our replay engine would significantly
performance gains.

Figure \ref{fig:timesignoringreplay} shows how much time is taken by
the various phases ignoring the time taken to replay the log file.
One interesting observation on this graph is that \verb|thunderbird|
spends by far the least time generating fixes (0.2$\mu{}$s versus
hundreds of milliseconds to a few seconds for the other tests),
despite taking by far the most time overall (an hour and a half versus
less than ten seconds).  This is because the artificial test cases run
the buggy code in a tight loop, so the log contains many instances of
the buggy code and many stores to the relevant addresses, whereas
\verb|thunderbird| runs it only once.  The state machines must
therefore by evaluated in far fewer contexts in the artificial bugs,
which dramatically reduces the time taken by the analysis.  This is an
encouraging result: most bugs occur in code which is executed
infrequently, and so it would be reasonable to expect that most bugs
would have analysis time more similar to the \verb|thunderbird| bug
than to the artificial ones.

We also investigated how the analysis depends on the exact way in 
which a particular bug is reproduced, by running our tool
on five independent reproductions of the \verb|glibc| bug.  Every
reproduction produced the same set of state machines and suggested
fixes.  The time taken by the analysis process varied significantly,
however (from eight to thirteen seconds), mostly because the time
taken to reproduce the bug varied and hence produced differently sized
logs to be parsed. Similar results were obtained for the other
bugs.\editorial{Not sure this is all that interesting, or that I've
  phrased it very well...}

\subsection{Effects of backtracking further}
\label{sect:eval:backtrack}

One important parameter to the system is how far to backtrack through
the crashed thread, and hence how many state machines to generate,
before attempting to derive a fix.  For implementation reasons, our
prototype will always backtrack to a branch instruction, and for the
above tests we limited this backtracking to ten branches.  Figure
\ref{fig:eval:backtrack} shows the effect of changing this parameter
upon the time taken by the non-replay components of the
\verb|thunderbird| test (the replay components were unchanged).  It
can be seen that the time taken increases rapidly as the distance
which we backtrack increases, by a factor of more than 500 when going
from a single level of backtracking to fifty levels.  However, the
total time taken by the non-replay analysis is, even with a
backtracking depth of 50, still just 620ms, or 0.013\% of the total
time taken.  None of our tests depend on more than three levels of
backtracking to produce a correct fix (and the \verb|thunderbird| test
requires just one), and so this suggests that SLI should be able to
backtrack sufficiently to solve most bugs without requiring excessive
resources.

\begin{figure}
\includegraphics{clog/clog.pdf}
\caption{Time taken by the analysis phases of the thunderbird bug, in
  seconds, versus the level of backtracking applied to the crashed
  thread, in dynamic branches.  Mean and standard deviation of three
  runs.}
\label{fig:eval:backtrack}
\end{figure}


\subsection{Detailed discussion of test bugs}
\label{sect:bug_descr}

We now discuss our test bugs in more detail.

\verb|toctou| is a simple two-thread time-of-check, time-of-use race.
In this test, one thread loops incrementing a counter, while another
thread repeatedly issues pairs of loads of the counter and asserts
that the loads returned the same value.  Our prototype generates a
single suggested fix consisting of two critical sections, one
protecting the write-back of the incremented counter in the first
thread and the other protecting the two loads in the second thread.
This is a correct and minimal fix.

\verb|twovar| is a two-variable atomicity violation.  In this test,
there are two global variables, and one thread loops setting both to 5
and then setting both to 7 while another thread loops loading both and
asserting them to be equal.  SLI again produces a single correct fix
in this case.  The core of the second thread consists of two
instructions:

\begin{verbatim}
l1: mov (global1) -> %rax
l2: cmp %rax, (global2)
    jne __assert_fail
\end{verbatim}

The single-threaded state machine for \verb|l1| is

\begin{verbatim}
if load(global1@l1) != load(global2@l2)
 then crash
 else no-crash
\end{verbatim}

\noindent
This produces a single candidate fix, consisting of two critical
sections: one protecting instructions \verb|l1| and \verb|l2| in the
second thread, and four single-instruction sections each of which
protects a single store in the other thread.  This correctly
eliminates the bug.

\verb|l2| is more interesting.  The state machine generated is

\begin{verbatim}
if rax != load(global2@l2)
 then crash
 else no-crash
\end{verbatim}

\noindent
This will specialize in two ways:

\begin{verbatim}
if 5 != load(global2@l2)
 then crash
 else no-crash
\end{verbatim}

\noindent{}and

\begin{verbatim}
if 7 != load(global2@l2)
 then crash
 else no-crash
\end{verbatim}

\noindent
There are no points in the program's execution at which both machines
will predict \verb|no-crash|, and so the original unspecialized
machine is discarded and produces no suggested fixes.  If the
specialized predictions had not been recombined they would have
predicted that the relevant instruction is safe if \verb|global2| is,
respectively, \verb|5| or \verb|7|, and hence produced suggested fixes
which synchronized the load at \verb|l2| against the stores to
\verb|global2| independently of any accesses to \verb|global1|.
Neither of these fixes would be sufficient to fix the bug, and
combining them directly would have meant that \verb|l2| could only
occur if \verb|global2| was both \verb|5| and \verb|7| simultaneously.
This is impossible, and so \verb|l2| would never be able to run at all
and the program would have deadlocked.

\verb|publish| is a buggy implementation of the publish pattern.  In
this pattern, a structure is initialized by one thread and then
published by writing its address into a global pointer.  Other threads
then occasionally read this global pointer and, if it contains a
non-\verb|NULL| pointer, use the referenced object.  This is safe if
correctly implemented, but in this test the programmer published the
structure before finishing constructing it, which leads to the other
thread eventually crashing.  The test case consists of two threads,
one of which repeatedly publishes and un-publishes a structure and the
other of which repeatedly tests whether it has been published and, if
it has, attempts to use it in a way which leads to an immediate crash
if initialization is not complete.

Our tool produced two suggested fixes in this case.  One of these was
expected, consisting of two critical sections, one protecting the
consuming thread from the point at which it loaded the pointer to the
point at which it used its contents and the other protecting the
producing thread from the point at which it published the structure to
the point at which it finished initializing it.  This is a correct
fix.

The other suggestion was an artifact of our test harness, which
repeatedly published, initialized, unpublished, and then deinitialized
the same structure.  SLI was able to look through this pattern, and
determined that it was sufficient to prevent the consuming thread from
validating the published structure at any point between the
deinitialization in one iteration and the initialization in the
subsequent one.  It therefore suggested a fix which protected the load
which the consuming thread used to perform validation in one critical
section and the range of the publishing thread from the
deinitialization to the subsequent initialization in another,
completely ignoring the accesses related to publishing and
un-publishing the structure.  While somewhat surprising, this is also
a correct fix, completely preventing the observed bug, and, as it
produces slightly smaller critical sections, would be preferred by the
fix prioritisation heuristic.

\verb|privatize| is the converse of \verb|publish|: a thread is
attempting to make a structure private, and does it incorrectly.  It
is similar to the example program in figure
\ref{fig:broken_privatize}, which has already been extensively
discussed.

\verb|glibc| is a kernel of glibc bug 2644 \cite{glibc2644}, which
affected versions of glibc up to 2.5 and could lead to a crash if
multiple threads were shut down at the same time.  A simplified
version of the code involved is shown in figure \ref{fig:glibc}, where
\verb|forcedunwind| and \verb|done_init| are global variables.  Note
that the bug here depends on the compiler's optimizer, and is not
apparent at the source-code level\footnote{Unfortunately, only the
  32-bit x86 version of gcc optimizes the function like this, and our
  implementation of SLI assumes a 64-bit x86 program, and this
  prevented us from testing with the real bug.}.  SLI operates
entirely at the machine-code level, and so this does not present any
additional complexity.

\begin{figure*}
  \begin{subfloat}
    \begin{minipage}{57mm}
\begin{verbatim}
_Unwind_ForcedUnwind() {
    if (forcedunwind == NULL)
        pthread_cancel_init();
    forcedunwind();
}
pthread_cancel_init() {
    if (done_init) return;
    forcedunwind =
      _forcedunwind_impl;
    done_init = 1;
}
\end{verbatim}
    \end{minipage}
    \caption{Before optimizations}
  \end{subfloat}
  \begin{subfloat}
    \begin{minipage}{57mm}
\begin{verbatim}
  _Unwind_ForcedUnwind() {
1:  l = forcedunwind;
2:  if (l == NULL &&
3:      done_init) {
4:    forcedunwind = l =
5:         _forcedunwind_impl;
6:    done_init = 1;
7:  }
8:  l();
  }
\end{verbatim}
    \end{minipage}
    \caption{After optimizations}
  \end{subfloat}
  \begin{subfloat}
    \begin{minipage}{40mm}
\begin{verbatim}
    while (1) {
10:   pthread_barrier_wait();
11:   _Unwind_ForcedUnwind();
12:   pthread_barrier_wait();
13:   done_init = 0;
14:   forcedunwind = NULL;
    }
\end{verbatim}
    \end{minipage}
    \caption{Test harness}
  \end{subfloat}
  \label{fig:glibc}
  \caption{Source code for the glibc test case.}
\end{figure*}

SLI produced six suggested fixes when run on a log generated by
running this test.  The first of these had five critical sections: one
covering the load on line \verb|1| to the load of \verb|done_init| on
line \verb|3|, and one each for each of the stores on lines \verb|4|,
\verb|6|, \verb|13|, and \verb|14|.  The other suggestions were
supersets of this suggestion, extending it to include various accesses
in \verb|pthread_barrier_wait|.  This illustrates an important
weakness of the approach.  Because SLI does not know anything about
any OS-provided functionality, it cannot take advantage of any
existing synchronization present in the program (in this case, the
\verb|pthread_barrier_wait|s make the critical sections protecting
statements \verb|13| and \verb|14| redundant).  It also means that the
analysis must explore these standard functions, and can sometimes
attempt to ``fix'' the benign races inherent in synchronization
operations, which is unlikely to be productive.

\verb|thunderbird| is Mozilla bug number
391259\cite{thunderbird39125}, a simple time-of-check, time-of-use
race in the IMAP client component of Thunderbird, a popular
open-source e-mail client.  We modified Thunderbird to include some
additional debugging messages and used a custom scheduler in order to
make the bug reproduce more readily; the test is otherwise identical
to the behavior which a user might have encountered.  The relevant
parts of the program are as follows:

\begin{verbatim}
void nsImapProtocol::CloseStreams() {
  if (m_transport)
      m_transport = nsnull;
}
PRBool nsImapProtocol::ProcessCurrentURL() {
  if (m_transport)
    m_transport->SetTimeout(
      TIMEOUT_READ_WRITE, PR_UINT32_MAX);
}
\end{verbatim}

\noindent
If \verb|m_transport| is set to \verb|nsnull| by \verb|CloseStreams()|
in between the two accesses in \verb|ProcessCurrentURL| then the
program will crash.  This is essentially the same bug as
\verb|toctou|, but embedded in a much large program.  As such, the
final result is similar: a single suggested fix, with two critical
sections, one containing the two accesses in \verb|ProcessCurrentURL|
and one containing the assignment in \verb|CloseStreams|.  This fixes
the bug.

\section{Related work}\editorial{This is a bit of a bestiary.  Could do with a bit more analysis.}

There have been a number of previous systems which tackle similar
problems.  Most recently, Kivati\cite{Chew2010a} attempts to fix
single-variable atomicity violations automatically by combining a
static analysis pass with some runtime support.  The result is able to
prevent many common kinds of race-like bugs with low overhead.  There
are several important differences between their approach and ours:

\begin{itemize}
\item SLI is only activated once a bug has been observed, whereas
  Kivati runs at all times.  This means that it is more likely to
  ``fix'' perfectly benign races.  It also means that the fixes cannot
  easily be applied without also requiring the Kivati runtime,
  whereas, once generated, SLI fixes can stand alone without any of
  the rest of the SLI infrastructure.
\item Kivati requires access to the program's source code during the
  initial static analysis phase, whereas SLI only requires the binary.
\item SLI can be applied to a wider class of bugs than Kivati, such as
  the \verb|twovar| example described above.
\end{itemize}

Another approach, taken by systems such as
Isolator \cite{Ramalingam2009} and ToleRace\cite{Ratanaworabhan2008},
restricts the problem domain to asymmetric races, where one thread is
correctly following a locking discipline while some other thread is
not, and seeks to ensure that the correct thread continues to be
correct despite the misbehavior of the incorrect one.  This might,
for instance, be useful if the correct thread is controlled by an
application while the incorrect one is controlled by a library which
the application writer is unable to modify.  As with Kivati, they do
not target specific bugs.

Atom-Aid\cite{Lucia2009} is another approach to race bug
mitigation, in this case using hardware transactional memory support.
Their approach is to bundle sequences of memory accesses into
transactions according to some heuristics, effectively reducing the
number of permissible schedules and hence the scope for memory
ordering related bugs.  Provided the necessary hardware is available,
this is simple and reasonably efficient, and should also eliminate a
reasonable selection of non-trivial bugs.  The main downside of this
approach is that it requires non-standard (and presently non-existent)
hardware, which makes it less practically useful than it otherwise
would be.

There have also been a number of attempts to automatically fix heap
management bugs, such as buffer overflows and use-after-free errors,
including AutoPaG\cite{Lin2007} and Exterminator\cite{Novark2007}.
These systems both take an example of a buffer overflow bug (assumed
to be deterministic) and use various analyses to determine the root
cause of the bug, eventually using this to produce a potential fix.
In that, they are remarkably similar to the system currently under
discussion; the main difference being the type of bug targeted.

All of these systems attempt to fix bugs or otherwise prevent them
from happening.  An alternative strategy is to make errors less
serious when they do happen.  The most famous example of such a
strategy is probably failure obliviousness\cite{Rinard2004}, which
waits until the protected program makes an invalid memory reference
and then attempts to fix it from the resulting exception handler.
DieHard\cite{Berger2006} is conceptually similar, but works
pre-emptively rather than from a fault handler, by guessing where
memory errors are likely to occur and modifying the program's memory
map to make those errors as harmless as possible.  In this way
programs are able to continue executing in spite of the presence of
errors which would otherwise cripple them.  Failure obliviousness
cannot, however, completely remove any errors, and so can be seen as
complementary to those discussed here.

RX\cite{Qin2007} takes a third strategy.  Here, rather than
attempting to fix the bug, an attempt is made to determine which
subset of a program's functionality is bug-free, and then to restrict
the program's inputs to only exercise that functionality.  The result
is that inputs which might have triggered the bug continue to produce
incorrect output, but the damage is at least contained rather than
propagating throughout the program and potentially leading to a crash.
This is arguably safe, although not according to the definition used
in this paper, and can cover a wide variety of bugs with little
overhead.

All of these approaches are primarily dynamic in nature.  There have
also been many systems which attempt to detect races using static
analysis, such as \cite{Pratikakis2006} or \cite{Engler2003}, or via
model checking, such as \cite{Elmas06preciserace}.  These techniques
have the advantage that the bug to be fixed does not first have to be
exhibited (and, indeed, they are often used to discover bugs in code
which has never been run) and have precisely no runtime overhead, so
are attractive wherever they are applicable.  However, many programs
have sufficiently complicated structures that a sound static analysis
is impractical, and they cannot as easily compensate for this by
taking advantage of any exhibition which might be available or by
being directed towards fixing a specific bug.  Bugs which can be
exhibited are likely to be more important than those which have never
been seen, and so this is often a significant
limitation. \editorial{...}

\section{Future work}

There are a number of potential extensions of this work, beyond the
obvious ones of broadening the evaluation and improving performance.
At a high level, SLI must balance the use of static analysis, which
considers many possible executions and produces general fixes, and
dynamic analysis, which considers only the observed execution and
produces much more targeted fixes.  We do not claim to have found the
optimal combination of these two approaches, or even that a global
optimum exists; better characterizing the trade-offs involved is
likely to suggest useful improvements.

There is a similar balance to be struck between attempting to be
completely generic and using semantic knowledge, both of the program
and of its libraries.  At present, we make very little use of this
information, and so our implementation is generic across a wide range
of applications but struggles with more complicated bugs.
Incorporating more semantic information, or providing a generic way
for programmers to introduce their own semantic models, might improve
our ability to produce useful, performant fixes.  One particularly
intriguing approach would be to combine SLI with an invariant
inference scheme such as Daikon\cite{Ernst2007} or
DIDUCE\cite{Hangal2002}, which would allow us to obtain such semantic
information without compromising SLI's current ability to run on
almost arbitrary unmodified binaries.  We intend to investigate this
idea more fully in the future.

The current timeout-based mechanism for avoiding deadlocks is also a
weakness, and can lead to poor performance or incompletely fixed bugs.
This could be ameliorated to some extent by using further static
analysis to detect which patches are likely to lead to deadlocks and
to penalize them in the fix selection phase.  Alternatively, SLI could
be integrated with a deadlock immunity system such as
Dimmunix\cite{Jula2008}, which would detect and fix deadlocks when
they happen.  The system would then hopefully converge on a state
which is both deadlock and race free.

\section{Conclusions}

We have presented SLI, a system for automatically fixing specific
synchronisation bugs in shared-memory programs using only their
binaries, with minimal user intervention.  We have demonstrated that
it can be used to fix real-world bugs in at least some cases, and
discussed the compromises and trade-offs which are necessary in order
to produce a practically useful implementation.  While these
techniques do have a number of limitations and drawbacks, we feel that
they provide a useful basis for ongoing work to extend the set of
situations in which they are applicable.\editorial{Wibble wibble
  wibble}

\bibliographystyle{eurosys}

\bibliography{library}

\end{document}

