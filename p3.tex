\documentclass[10pt,twocolumn,preprint,natbib,authoryear]{sigplanconf}
\usepackage{verbatim}
\usepackage{color}
\usepackage{graphicx}
\bibpunct{[}{]}{,}{a}{}{;}

% force pdflatex to use A4 paper
\setlength{\pdfpagewidth}{210mm}
\setlength{\pdfpageheight}{297mm}

\usepackage{amsmath}
\usepackage{subfigure}

\newcommand{\editorial}[1]{\textcolor{red}{\footnote{\textcolor{red}{#1}}}}
\newcommand{\needCite}{\editorial{need cite}}
\newcommand{\smh}[1]{\editorial{SMH says: #1}}

\newbox\subfigbox             % Create a box to hold the subfigure.
\makeatletter
  \newenvironment{subfloat}% % Create the new environment.
    {\def\caption##1{\gdef\subcapsave{\relax##1}}%
     \let\subcapsave=\@empty % Save the subcaption text.
     \let\sf@oldlabel=\label
     \def\label##1{\xdef\sublabsave{\noexpand\label{##1}}}%
     \let\sublabsave\relax    % Save the label key.
     \setbox\subfigbox\hbox
       \bgroup}%              % Open the box...
      {\egroup                % ... close the box and call \subfigure.
     \let\label=\sf@oldlabel
     \subfigure[\subcapsave]{\box\subfigbox}}%
\makeatother

\begin{document}

\conferenceinfo{Eurosys 2011}{date, City.} 
\copyrightyear{2005} 
\copyrightdata{[to be supplied]} 

\titlebanner{Submitted to EuroSys'11}        % These are ignored unless
%\preprintfooter{short description of paper}   % 'preprint' option specified.

\title{Speculative Lock Insertion}
%\subtitle{Subtitle Text, if any}

% For double-blind reviewing:
\authorinfo{}{}{}
%\authorinfo{Name1}
%           {Affiliation1}
%           {Email1}
%\authorinfo{Name2\and Name3}
%           {Affiliation2/3}
%           {Email2/3}

\maketitle

\begin{abstract}

The increasing use of parallel hardware suggests that synchronization
bugs will be increasingly common, and hence that tools for diagnosing
and fixing such bugs would be useful.  In this paper, we propose
Speculative Lock Insertion, or SLI, as one possible such tool.  Using
a combination of static and dynamic analysis techniques, SLI is able
to automatically characterize and then fix a useful class of
synchronization bugs, starting from a reproduction of the bug and the
program binary.  We demonstrate the techniques effectiveness using
both artificial and real bugs, and discuss some of the trade-offs
necessary in order to implement it.

\end{abstract}

\category{CR-number}{subcategory}{third-level}

\terms
term1, term2

\keywords
keyword1, keyword2

\section{To do}

Need to update everything now that we specialise in several places,
including re-running all the timing tests.

\section{Introduction}

There is a well-established trend in software engineering to make
greater use of multiple threads, driven largely by the increasing
availability of multi-processor systems and multi-core processors.
While potentially paying large dividends in improved responsiveness,
throughput, and power consumption, multi-threaded programming has an
unfortunate tendency to lead to very subtle bugs.  Even worse, these
bugs are often highly dependent on the low-level details of the
hardware on which the software is being run, which can often lead to
bugs which only reproduce on some small subset of computers.  This
makes testing for these bugs extremely difficult, so they are more
likely than other kinds of bugs to remain undetected in shipped
software, and also complicates the process of developing a fix, and so
once detected they remain unfixed for much longer.

A number of techniques have been proposed for reducing the likelihood
of these multi-threading bugs, including transactional
memory\cite{Shavit1997} and automatic parallelization\cite{Bacon1994}.
These can be used to address these issues in new software, but there
remains a substantial body of existing programs using the legacy
shared-memory model.  There is therefore a need for techniques which
can ameliorate bugs found by end-users in programs developed with the
currently widely-used shared memory model of concurrency.

In this paper, we introduce SLI, or Speculative Lock Insertion, as one
potential approach to this problem.  SLI automatically fixes
synchronization bugs once they have been observed, given only the
program binary and a reproduction of the bug, generating a modified
binary whose behavior is identical to that of the original except that
it no longer suffers from the bug.  The fixes so generated are safe,
in the sense that any behavior which is possible with the fix applied
would also have been possible, if sometimes unlikely, without the fix.
Furthermore, the fixes will usually have very low performance
overhead, and the process of generating the fix itself takes only a
moderate amount of time (ranging from seconds in simple cases to a few
hours for more complicated bugs).  SLI does not depend on programmer
annotations or semantic knowledge of the underlying operating system
or libraries, but can make use of such information when it is
available.

Our approach consists of several key phases.  First, the bug must be
captured under a deterministic replay system.  The exact details of
how this is done do not matter, and so existing high-performance
replay systems such as PRES\cite{Park2009} could be used
straightforwardly.  The captured trace is then examined in conjunction
with the program binary so as to build a series of approximations of
the parts of the program's behavior which are most closely relevant to
the bug, in a process similar to program slicing\cite{Weiser1979}.
These approximations can be used to predict whether executing a
particular subset of a program's instructions atomically at a
particular point in its execution would have led to a crash, and this
can then be leveraged to determine what additional synchronization
would have prevented the crash from happening.  This synchronization
can then be added to the program automatically using a simple binary
rewriter, and hence fix the bug.

This analysis is, unfortunately, both unsound and incomplete, in the
sense that the ``fixed'' program will still sometimes crash, and the
fix will sometimes eliminate executions which would have been safe.
This is, to some extent, inevitable, as determining whether an
arbitrary program will crash is incomputable, and to some extent an
engineering trade-off: more powerful analyses could produce more
accurate results, at the expense of greater computational complexity
in deriving a fix.  We discuss this in more detail in later sections.

In spite of this inaccuracy, the fixes generated by SLI are safe
(ignoring bugs in the implementation), in the sense that any behavior
which is possible with a fix applied is also possible when the fix is
not applied, assuming a model of program execution in which
instructions can be arbitrarily delayed.  This corresponds to the
model presented to user-level applications by most non-realtime
operating systems, including Linux and Windows, and so this weak model
is likely to be sufficient for many pieces of widely used software.
Of course, possible is not always the same thing as desirable, and so,
for instance, it might be that a fix causes certain operations which
would otherwise always succeed to always time out, and this might
render the software unusable without being unsafe within this
definition.  It is in general extremely difficult to avoid this kind
of issue without detailed semantic knowledge of the desired behavior
of the application, and we do not attempt it here.

\section{Capturing the bug}

Before SLI starts, the bug to be fixed must first be captured using a
deterministic replay system (DRS).  This work does not attempt to
advance the state of the art in DRSes, but does depend on them in
order to be feasible, and so we discuss them briefly here.

The only requirement we place on the choice of DRS is that it must
capture an execution sufficiently precisely that the relevant fragment
of execution can later be replayed as many times as necessary at the
accuracy of individual memory accesses.  This captured execution does
not need to be precisely the same as the original crashing execution,
but the more different it is the more likely it is that SLI will fix
the wrong bug.  The most obvious way of capturing an execution, used
in our prototype, is to simply record every single memory access
issued by the program, which is effective but has extremely high
overhead.  This could be reduced by using a more intelligent recording
mechanism such as PRES\cite{Park2009} or ODR\cite{Altekar2009}, both
of which record only a few critical events and discover the rest only
when they are needed during replay.  This approach can reduce overhead
to a level where it is sensible to run with recording enabled by
default.  An extreme form of this approach is provided by
ESD\cite{Zamfir2010}, which logs nothing at all and instead attempts
to recreate the path to failure given just the state of the program at
the time of the failure.  In a slightly different context, an
automatic program exerciser such as CHESS\cite{Musuvathi2008} could be
used to detect completely new bugs, which could then be passed to SLI
to be automatically characterized and fixed.

\section{Deriving a single-threaded explanation of the bug}
\label{sect:build_state_machines}

The first phase of our algorithm is to derive an explanation of the
bug which considers only the behavior of the thread which crashed.
The result of this analysis is a series of acyclic state machines,
corresponding to instructions executed by the crashed thread towards
the end of its life, which can predict whether the thread will crash
starting from that instruction given a particular state of memory and
registers.

\subsection{Inaccuracies in the state machines}
\label{sect:inaccuracies}

These machines are approximations of the program's real behavior,
exhibiting both false positive and false negative errors, and can
predict a crash where none will actually occur or safe execution when
a crash is possible.  It would be possible to design an algorithm
which avoids either or both of these classes of errors, but doing so
would not necessarily be helpful.

Consider false positives first, or errors where a state machine
predicts a crash when none is possible.  This will cause the final fix
to eliminate some schedules which would have been permitted with a
perfect characterization, but, provided that there is always some
schedule available (see section \ref{sect:deadlocks}), this cannot
cause a correct program to become incorrect.  SLI can therefore
tolerate some level of false positives in the characterization without
producing incorrect fixes.

Likewise, the effect of a false negative is to only partially resolve
a bug, so that some possible manifestations remain possible.  This is
indistinguishable from there simply being several bugs, and so,
provided that the characterization is sufficiently accurate to predict
a crash for the captured execution, false negatives do not prevent SLI
from fulfilling its goal of fixing the observed crash.

As such, a perfect characterization is not only difficult, but also
unhelpful, and we do not attempt to produce one.  This allows us to
use much simpler analyses and to produce much simpler
characterizations, which makes it more likely that the system will be
able to generate a correct fix.

When we do make approximations in the characterization, we attempt, as
far as possible, to ensure that the captured execution remains
possible, and apply coarser approximation to executions which are very
different from the captured one.  The intuition behind this is that
the captured execution is the only one which is known to be relevant
to the bug, while all of the other paths discovered by static analysis
are in some sense speculative: we do now know if they can ever happen
at all, much less if they are relevant to the observed behavior.  It
therefore makes sense that, when an approximation must be made in
order to reduce execution time, or simply to make an analysis
feasible, it should be made on these speculative paths.

Similarly, we also attempt to make the machine more accurate at points
which are nearer to the crash, and approximate more aggressively at
points which occurred earlier in the execution.  There are two main
reasons for this.  First, details which occur shortly before the crash
are more likely to be directly relevant to it.  Second, the time taken
by some of the analysis steps involved in producing a state machine
grow more than linearly in the distance to the crash, and so more
aggressive simplification is necessary in order to keep the analysis
tractable.

\subsection{The proximal cause}
The first phase of our algorithm is to locate the first point in the
log at which something has definitely gone wrong, and hence to obtain
a proximal cause of the crash and to nominate one thread as being
directly responsible for it.  A naive approach would simply use the
point at which the program crashed.  In principle, this is always
correct, and for some simple bugs, such as \verb|NULL|-dereferences or
assertion failures, it works well.  However, for more complicated
classes of bugs, such as use-after-frees, there can be a significant
lag between the first definitely bad behavior (such as the use of
released memory) and the program crash, and this can cause later
phases to take an excessively long time.  This can be mitigated by
applying a dynamic analysis tool, such as
Valgrind\cite{Nethercote2007}, to the captured execution, which
provides a more accurate starting point for the rest of the analysis,
and hence significantly reducing the total time taken.  In our
prototype, we use a straightforward analysis to detect use-after-free
bugs at the first reference to released memory; combining this with
other forms of analysis or with application-specific knowledge would
be straightforward, and would allow other classes of bugs to be
detected.\editorial{I don't actually have any examples of bugs which
  depend on this, annoyingly.  Maybe I should kill it, or move it to
  future work?}

\begin{figure*}
 \begin{subfloat}
  \begin{minipage}{90mm}
\begin{verbatim}
A: mov (global1) -> %rax
B: mov %rax -> (%rsp)
C: cmp $0, %rax
D: jne F
E: mov &fallback_structure -> (%rsp)
F: mov (%rsp) -> %rcx
G: mov (%rcx) -> %rdx
H: add $48, %rdx
J: mov (%rdx) -> %rax
K: ret
\end{verbatim}
  \end{minipage}
  \caption{Thread 1}
 \end{subfloat}
 \begin{subfloat}
  \begin{minipage}{90mm}
\begin{verbatim}
V: mov &some_structure -> (some_variable)
W: mov &some_variable -> (global1)
...
X: mov $0 -> (global1)
Y: mov $0 -> (some_variable)
...
Z: jmp V
\end{verbatim}
  \end{minipage}
  \caption{Thread 2}
 \end{subfloat}
 \caption{A broken example of the privatize synchronization pattern.}
 \label{fig:broken_privatize}
\end{figure*}

The result of this initial analysis is generally a single-node state
machine which captures the reason for the crash using only information
which is available at the instruction on which the crash occurred.
For example, consider the program shown in figures
\ref{fig:broken_privatize}, which is intended to be a broken instance
of the common structure privatization pattern\needCite{} in an
x86-like assembly language.  Thread 2 initializes (\verb|V|) and
publishes (\verb|W|) a structure, does some unrelated work, and then
attempts to privatize (\verb|X|) and de-initialise (\verb|Y|) the
structure.  Meanwhile, thread 1 loads the pointer published by thread
2 (\verb|A|), checks whether it is valid (\verb|B|, \verb|C| and
\verb|D|), and, if it is not, loads a fallback version (\verb|E|),
before attempting to use it (\verb|F| through \verb|J|).  This will
lead to a crash if instructions \verb|X| and \verb|Y| occur between
instructions \verb|A| and \verb|H|, as in that case \verb|rdx| will
contain a bad pointer at instruction \verb|J|, which will cause an
immediate crash.  The proximal cause is then simply
\verb|if (BadAddr reg(rdx)) then crash else no-crash| (translating the
state machine into text in the obvious way), and is valid at the start
of instruction \verb|J|.

\subsection{Deriving earlier state machines}
This proximal cause is accurate but not, by itself, sufficient to
derive a fix, as by the time the crashing instruction is executed it
is generally too late to attempt to fix it.  It is therefore useful to
move the expression backwards through the captured execution, and
hence to determine an equivalent expression which can be evaluated
earlier in the execution.  This is straightforward for simple
arithmetic instructions.  The log captured in the initial
bug-recording phase allows us to determine, for any instruction, which
instruction preceded it, and hence to apply the instruction to the
state machine.  This transforms the machine to one which is valid
before the instruction was executed.

In the example, the preceding instruction is \verb|add $48, %rdx|.
This transforms \verb|rdx| into \verb|rdx+48|.  Applying this
transformation to the proximal cause of the crash produces

\begin{verbatim}
if (BadAddr (reg(rdx) + 48))
 then crash
 else no-crash
\end{verbatim}

This is valid at the start of instruction \verb|H|.  Other simple
register-to-register arithmetic instructions can be handled in the
same way, and hence the crash reason can be backtracked across any
sequence of such instructions.

\subsubsection{Memory accesses}

Load instructions also require special handling in this scheme, as the
state machine for a given instruction may need to reference a load
issued by an instruction which occurs after it, and the value of the
relevant memory location might have changed by the time it executes.
We solve this problem by labelling each load expression with the
instruction pointer and call stack at the point at which it is issued,
which allows state machines to refer to loads which have not yet
happened, and hence to capture the effects of future loads on the
thread's behavior.  Note that these labels can be ambiguous, if the
program's control flow loops or a single instruction issues multiple
memory accesses.  In the case of the x86 architecture, all common
instructions which perform multiple loads can be converted into loops,
and we do so; we discuss the handling of loops in section
\ref{sect:branch_instrs}.

In the running example\editorial{phrase}, the state machine
\begin{verbatim}
if (BadAddr (reg(rdx) + 48))
 then crash
 else no-crash
\end{verbatim}

at \verb|H| will be transformed to

\begin{verbatim}
if (BadAddr (load(reg(rcx)@G) + 48))
 then crash
 else no-crash
\end{verbatim}

at \verb|G|, and then to

\begin{verbatim}
if (BadAddr (load(load(reg(rsp)@F)@G) + 48))
 then crash
 else no-crash
\end{verbatim}

at \verb|F|.

The state machines must also model the effects of stores.  To do this,
each edge in the machine has a list of $\langle{}$address, value,
size$\rangle{}$ tuples, where address and value can be arbitrary
expressions, indicating what stores the program will issue when it
follows that edge.  Backtracking across a store instruction is then a
simple matter of adding another entry to this list.  Unfortunately,
the lists of stores associated with an edge in the state machine can
become quite large for even modest test cases, and the vast majority
of these stores will never be used.  We therefore ignore stores which
occur more than a certain distance from the point for which the state
machine is being derived, which both reduces the number of stores
which have to be recorded and, more importantly, allows many nodes in
the CFG to be merged\editorial{...}.

\subsubsection{Resolving accesses to the thread's local stack}
\label{sect:resolvestack}

Many load instructions will access a thread's local stack.  While it
is, in principle, possible for one of these accesses to be involved in
a concurrency bug, it is in practise highly unlikely, as it is unusual
for one thread to access another's stack.  It is therefore useful to
be able to match these loads to the stores which originally produced
the loaded value, and hence to eliminate them.  We use a simple
heuristic in order to do so.  When we encounter a store instruction,
we check if the instruction occurred in the captured execution, and if
it did, and it stored to the stack in that case, we traverse the log
to determine which instructions subsequently loaded the stored value.
If any of those loads appear in the current state machine then we
assume that they will load the value stored by this instruction,
effectively eliminating them and thus simplifying the machine.

This is obviously an unsound heuristic, and will occasionally produce
incorrect predictions, which will lead to an incorrect
characterisation of the program's behavior.\editorial{It kind of looks
  like this assumes a static data flow graph, but it actually
  sometimes works even when you don't have that.  It's also quite a
  bit stronger than just only resolving constant offsets from rsp, but
  explaining why is kind of time consuming.}

\subsubsection{Branch instructions}
\label{sect:branch_instrs}
Branch instructions require more care.  There are two main special
cases.  The easiest is a two-exit branch where both branches have
constant target addresses, both targets were executed in the captured
execution, and the untaken target occurred after the taken one in the
execution.  In that case, we will be able to derive state machines for
both targets and then produce a new state machine which consists of
both target state machines and a new node which branches to one or the
other depending on the branch condition.  If the untaken target
occurred earlier then the taken one then combing the machines like
this would risk introducing a cycle, which would complicate later
analyses, and so in that case we treat this branch as one where the
untaken target is never seen.

In that case, or if the untaken target was genuinely never observed in
the captured execution, we determine the branch's effects using a
simple static analysis.  The first stage of this analysis is to build
an approximation of the program's control flow graph starting from the
untaken target instruction, stopping when we encounter an instruction
for which we already have a state machine.  The state machines can
then be propagated backwards through the graph using the same
algorithm as we use to backtrack across dynamically-executed
instructions, and a state machine can hence be derived for the root of
the graph and the original branch instruction.

Indirect branches, and in general anywhere the target of the branch is
computed dynamically at runtime, pose an additional challenge here, as
it is often difficult to statically predict the target of the branch.
The most common case is return instructions, and we handle these by
inlining every function into its called
location\editorial{Conceptually, anyway.  What we actually do is
  include a backtrace in the name of the instruction, which has the
  same effect but is much harder to describe concisely.}, eliminating
most return instructions completely.  The remainder correspond to
functions which had started but not completed at the time of the
crash, and we assume that if any of those return then it indicates
that the bug has been avoided.

Other indirect branch instructions are more challenging.  We solve
this problem by using the captured trace as a simple oracle: if the
branch instruction exists in the dynamic trace, we assume that the
instruction will always branch to the same place (if the instruction
occurs several times then we use the last target).  If the instruction
did not occur, or if the exploration simply reaches its depth limit,
we place a special analysis-failed node in the graph.  Once the CFG is
complete, we eliminate all branches to these failed nodes; if that
causes some node to have no known successors, then that node is also
marked as analysis-failed, and the process iterates.  This removes a
minimal subgraph of the CFG which eliminates the unpredictable
instructions.

Loops also complicate this simple algorithm.  We solve this problem by
simply breaking them, removing some subset of the graph's edges so as
to eliminate the loop.  This has the useful side-effect of
disambiguating the labels used to refer to load instructions: in a
loop-free control flow graph, each instruction is executed at most
once, and so dynamic instructions can be referred to unambiguously by
their static location in the CFG.  We choose edges to remove based on
two heuristics.  First, we try not to remove any edges which are
represented in the captured execution.  Second, we try not to
partition the graph, so that as many instructions as possible, and
hence as much of the program's behavior as possible, are represented
in the final state machine.

The result is a DAG of instructions, rooted at the branch instruction
and with state machines at all of its leaves, which approximates the
part of the static CFG of the program which is most relevant to the
captured execution.  This approximation is often imperfect, but, as
discussed in section \ref{sect:inaccuracies}, such imperfections will
not always prevent SLI from generating at least a partial fix for the
bug, and hence can usually be tolerated in exchange for the
dramatically simpler analysis which they allow.

\begin{figure}
\includegraphics[width=83mm]{diagrams/eg_cfg_start.pdf}
\caption{CFG for instruction D}
\label{fig:eg_cfg}
\end{figure}

In the example, the next instruction which must be assigned a state
machine is \verb|D: je F|.  It is followed by instruction \verb|F|,
which already has a machine, and \verb|E|, which does not.  \verb|E|
is itself followed by \verb|F|.  The CFG is therefore as shown in
figure \ref{fig:eg_cfg}.  The only node which initially does not have
a state machine but which has state machines for all of its successors
is \verb|E|, and so we will start by attempting to derive a state
machine for it.  In this case, the instruction is a simple store to a
stack location.  Assuming that this store was ever executed in the
captured execution, local stack resolution will predict that the load
at \verb|F| will load the stored value, and so the state machine
assigned to \verb|E| will be

\begin{verbatim}
if (BadAddr (load(fallback_structure@G) + 48))
 then crash
 else no-crash
\end{verbatim}

Instruction \verb|D| now has all of its successors, and so we can
now derive a state machine for it.  This will be:

\begin{verbatim}
if !CondEq(rflags)
then
 if (BadAddr (load(load(reg(rsp)@F)@G) + 48))
  then crash
  else no-crash
else
 if (BadAddr (load(fallback_structure@G) + 48))
  then crash
  else no-crash
\end{verbatim}

Backtracking further will eventually produce this state machine, valid
at \verb|A|:

\begin{verbatim}
if load(global1@A) != 0
then
 if (BadAddr (load(load(global1@A)@G) + 48))
  then crash
  else no-crash
else
 if (BadAddr (load(fallback_structure@G) + 48))
  then crash
  else no-crash
\end{verbatim}

(It should be emphasised that the actual programs produced are state
machines, and do not have to be block-structured programs; the
block-structured form is simply a more convenient notation.  This
means that is not actually necessary to duplicate the branches like
this in all cases, which can ameliorate an otherwise exponential
increase in the complexity of the state machines.)

It is informative to consider what would have happened if the branch
had not been taken but the program had crashed anyway (which will
happen if the fallback structure also contains an invalid pointer).
The state machine assigned to instructions \verb|E| will be the same
as before, except that it will be derived based on the actual dynamic
execution rather than one hypothecated based on static analysis, and
so the state machine for instruction \verb|D| will also be unchanged.
This is important, as it gives the approach some tolerance for changes
in the details of how a bug is reproduced.\editorial{Kind of needs
  rephrasing.  It's a pretty important point, as well.}

\section{Investigating the multi-threaded behavior of the program}
\label{sect:multi_threading}

Once a single-threaded characterization of the bug has been produced,
it is possible to investigate the crashed thread's interactions with
other threads in the system.  Our basic approach here is to replay the
program's execution and discover points at which the state machine
would have returned \verb|no-crash| if it had executed atomically.
From these, it is possible to infer which parts of the program's
execution should be synchronized against each other, and hence to
suggest some potentially useful synchronizations.  In principle, this
stage can run immediately as soon as the first state machine has been
derived, but it is possible to derive a significant performance
advantage by grouping machines into small batches and hence reducing
the number of times which the log file has to be
replayed.\editorial{Evidence?  Also, so what?}

Our implementation of this strategy has several stages.  First, we
determine which memory locations are relevant to the state machines in
the current batch, by replaying the log from the beginning and
evaluating the state machines wherever they are applicable, and
recording the memory locations which were loaded.  The log can then be
replayed again collecting all of the instructions which store to those
locations, along with the values which are stored, and so produce an
additional log showing all changes to the relevant addresses.

Applicability in this context means that the instruction for which the
state machine was derived is sufficiently similar to the current point
in execution that evaluating the machine is likely to produce
meaningful results.  This is complicated by the way in which the state
machines combine both static and dynamic information, and so matching
either the specific dynamic instruction or the static instruction
pointer for which the machine was derived is likely to be
insufficient\editorial{Justification?}.  Our approach is to consider
two points to match if both the instruction pointer and the call stack
match.  This is equivalent to saying that the instructions match if
they would have had the same instruction pointer had every function on
the stack been inlined into its caller, which meshes
nicely\editorial{don't like that phrasing} with our approach of
inlining every encountered function during CFG construction.

Next, the state machines are specialized to particular points in the
log.  This involves replaying the log a third time and, whenever the
state machine is applicable, constructing a new state machine which
has appropriate constants substituted in for the values of registers
and accesses to the local stack\footnote{This may result in the
  construction of duplicate machines, which are eliminated in the
  obvious way.}.  This effectively factors out of the effects of
thread-local computation, converting each state machine into a set of
state machines which individually depend only upon the content of
memory locations which had previously been flagged as relevant.

These specialized state machines are then each individually used to
partition the relevant address log into crashing and non-crashing
regions\editorial{How?  Kind of obvious, but might be worth
  explaining.}. The specialized partitions are then used to derive an
equivalent partition for the non-specialized machines:

\begin{itemize}
\item If a specialized machine always predicts a crash or always
  predicts no crash, it is discarded.
\item If every specialized machine for a given non-specialized one
  predicted \verb|no-crash|, the non-specialized prediction is
  \verb|no-crash|.
\item Likewise, if every specialized machine predicted \verb|crash|,
  the non-specialized prediction is also \verb|crash|.
\item If the specialized machines disagree, or if one of the machines
  attempts to reference an inaccessible memory location, the region is
  marked as unknown in the non-specialized partition.
\end{itemize}\editorial{...}

If the resulting schedule does not contain any \verb|crash| regions,
or does not contain any \verb|no-crash| regions, the original
unspecialized state machine is discarded as unhelpful.

\subsection{Generating candidate fixes}
\label{sect:gen_fix}

At the end of this stage, we have, for each (unspecialized) state machine:

\begin{itemize}
\item A list of all memory accesses which the state machine depends
  on.
\item A list of all instructions which stored to one of the addresses
  which the machine depended on in the captured execution (i.e. all of
  the instructions which, when interleaved with the state machine,
  might have prevented it from executing atomically).
\item A set of sub-ranges of the execution in which the state machine
  could have executed atomically without predicting a crash.
\end{itemize}

Assuming that the unsafe regions all end on the same thread as they
started, this information can be encoded into a set of critical
sections as follows:

\begin{itemize}
\item There is one critical section which covers all of the accesses
  made by the state machine itself.
\item Every region in which a crash is predicted has a critical
  section, starting at the first access in the unsafe region and
  ending at the final access.
\item Every possibly-interfering store is wrapped in a single-access
  critical section, if it is not already contained in one of the
  unsafe regions.
\end{itemize}

Crashing regions which cross threads cannot be protected in this way.
We re-designate those areas of the log as having an unknown crash
prediction, which causes SLI to give up trying to protect them and to
penalize the resulting fix when selecting which fix to actually apply
(see section \ref{sect:selectfix}).

Our fix then consists of ensuring that the first critical section
cannot execute at the same time as any of the second two kinds.  In
our current implementation, this is done by introducing a new global
lock which is acquired before the first instruction of any of these
critical sections and then released after the last one (see section
\ref{sect:binpatch} for more details).  This is moderately
pessimistic, as it prohibits multiple threads from running sections of
the first type in parallel and prohibits sections of the second and
third type from running in parallel with each other, which would have
been allowed by the intended fix.  We made this choice purely in order
to simplify the implementation; a more intelligent implementation
could retain greater concurrency, which might lead to lower overhead,
at the expense of slightly greater implementation complexity.

\subsection{Selecting a fix}
\label{sect:selectfix}

This process might produce multiple possible fixes if multiple state
machines are available, and it is then necessary to select an
appropriate one to instantiate into a binary patch.  We use a very
simple cost heuristic to do so: the cost of a fix is given by $U.n_u +
C_s.n_s + {\sum_{i}}s_i$ where $n_u$ is the number of points in the
log where we are unable to produce a crash prediction\editorial{Less
  well-defined than it sounds...}, $n_s$ is the total number of
critical sections, $s_i$ is the number of accesses in the $i$th
critical section, and $C_s$ and $U$ are constants reflecting the cost
of introducing a new empty critical section and of only partially
fixing the bug, respectively.  Our prototype sets $U=1000$ and
$C_s=10$, strongly preferring fixes for which all unsafe states can be
eliminated and weakly preferring fixes with a smaller number of
critical sections.

In our evaluation, there are generally only a small number of possible
fixes, all of which are correct and none of which would obviously lead
to pathological performance, and so the exact choice of prioritisation
heuristic does not appear to be critical.

\subsection{Example}

Our earlier example derived the state machine:

\begin{verbatim}
if load(global1@A) != 0
then
 if (BadAddr (load(load(global1@A)@G) + 48))
  then crash
  else no-crash
else
 if (BadAddr (load(fallback_structure@G) + 48))
  then crash
  else no-crash
\end{verbatim}

The list of relevant addresses will contain \verb|global1|,
\verb|fallback_structure|, and whatever \verb|global1| points at,
which, in this example, will be \verb|some_variable|.  Note that the
load in instruction \verb|J| is \emph{not} represented in this list:
the value which it loads does not affect whether or not the program
crashes, and so it is not considered relevant for these purposes.

Assuming that the only stores to relevant addresses are those
indicated in figure \ref{fig:broken_privatize}, the relevant store log
will then consist a sequence of entries similar to these:

\begin{verbatim}
V.1 &some_structure -> some_variable
W.1 &some_variable -> global1
X.1 0 -> global1
Y.1 0 -> some_variable
V.2 &some_structure -> some_variable
W.2 &some_variable -> global1
X.2 0 -> global1
Y.2 0 -> some_variable
...
\end{verbatim}

This will repeat for the entirety of the captured execution.

The state machine does not depend on registers or the thread-local
stack, and so specialization will have no effect.  We therefore
proceed to classify the store log into crashing and non-crashing
components.  In this particular case, the state machine will predict
that no state can crash, which is correct: if the loads in the state
machine had executed atomically, with respect to the stores present in
the store log, the program would not have crashed.  This suggests a
potential fix with five critical sections:

\begin{itemize}
\item One covering instructions \verb|A| to \verb|G| in thread 1.
\item One single-instruction critical section for each of instructions
  \verb|V|, \verb|W|, \verb|X|, and \verb|Y| in thread 2.
\end{itemize}

This would fix the bug, and will be suggested by SLI.

This is not the complete story, however\editorial{Don't like that
  phrasing}, as state machine generation will also have produced
machines for other instructions in the crashing thread.  In particular,
the machine for instruction \verb|F| will look like this:

\begin{verbatim}
if (BadAddr (load(load(reg(rsp)@F)@G) + 48))
 then crash
 else no-crash
\end{verbatim}

As this accesses both registers and the stack, it can be specialized,
producing two new machines:

\begin{verbatim}
if (BadAddr (load(some_variable@G) + 48))
 then crash
 else no-crash
\end{verbatim}

and

\begin{verbatim}
if (BadAddr (load(fallback_structure@G) + 48))
 then crash
 else no-crash
\end{verbatim}

The second one will always predict \verb|no-crash|, and so is
discarded.  The first machine, however, predicts a crash whenever
\verb|some_variable| contains something which is not a valid pointer,
which occurs from \verb|Y.1| to \verb|V.2| in the store log.  This
suggests an alternative fix with two critical sections:

\begin{itemize}
\item One single-instruction critical section covering instruction
  \verb|G| in thread 1.
\item A second critical section covering instructions \verb|Y| to
  \verb|V| in thread 2.  Note that this section will wrap around the
  loop, which somewhat complicates the implementation of the binary
  patcher; see section \ref{sect:binpatch} for our approach to this
  problem.
\end{itemize}

This fix will also be suggested by SLI, and would also fix the bug.
Furthermore, because it has fewer critical sections, it will be
preferred by the prioritisation heuristic.

It could be argued, however, that this smaller fix is inferior to the
larger alternative, despite completely eliminating the crash and
imposing lower overhead, as it is less ``sympathetic'' to the existing
structure of the program.  The author of thread 2 had presumably
intended to privatize the structure at instruction \verb|X|, and so
might reasonably have defined a ``correct'' fix to be one which
ensures correct privatization, a goal which is achieved by the first
fix but not by the second.  SLI, by contrast, has no notion of
intended behavior, or indeed any form of software engineering
construct, and so selects its fix based on the more mundane concerns
of avoiding the crash and minimizing the impact on performance.  This
is both a strength and a weakness: a strength in that it increases the
likelihood that a low-overhead fix will be found, and a weakness in
that the fixes cannot be translated back to source-level patches and
applied unthinkingly by the application programmer.

To put it another way: producing a long-term, maintainable fix for a
bug is a different problem to producing a short-term one which simply
eliminates its symptoms, and the techniques used by SLI are much more
applicable to the latter.  This will be true of any approach which
does not rely on programmer annotations (ignoring trivial systems
which just pattern-match the buggy code against a library of common
bugs and their standard fixes).  The extra flexibility gained by being
applicable to arbitrary binaries makes this a reasonable
trade-off.\editorial{Could make more of this.}

\subsection{Implementation details of the binary patcher}
\label{sect:binpatch}

Once an appropriate dynamic critical section has been discovered, it
must be converted to a static one.  Mapping the dynamic points into
particular instructions is generally straightforward, but mapping
ranges can be more difficult if they cross control flow branches.

We simplify the problem by detecting if the start and end of a
critical section are in different functions (as delimited by
\verb|call| and \verb|ret| instructions) and, if they are,
backtracking up the call stack to their most recent common stack
frame.  Besides simplifying the binary patching problem, this has the
(sometimes) useful side-effect of expanding the critical section, and
generally moving it to boundaries which are more likely to correspond
to the original programmers' ideas about where critical section
boundaries ``should be''\editorial{Rephrase}.

Once we have obtained start and end points in the same function frame,
we examine the program's machine code starting from the start point,
exploring its control flow graph until we encounter the end point or
an indirect branch (the exploration process is sufficiently naive that
indirect branches cannot be sensibly predicted, and so exploration has
to stop at that point).  The CFG thus obtained is then trimmed to only
contain paths starting at the start node and ending at the end node.
The desired synchronisation can then be added to this CFG in a
straightforward way (being careful to always release any needed locks
when leaving the patch), and the result recompiled into a fragment of
position-independent machine code.  This is combined with a stub
loader and built into an ELF shared library, which can be loaded into
the target program using \verb|LD_PRELOAD| (or an equivalent runtime
mechanism using).  The stub loader is then responsible for actually
applying the patch to the program.  We use two main strategies for
doing so:

\begin{itemize}
\item The entrypoint instruction can be replaced with a direct jump to
  the patch fragment.  This is the most efficient way of gaining
  control, but is only safe if the entrypoint instruction is large
  enough to contain the jump instruction.  Otherwise, we would also
  have to change the next instruction, which is dangerous without
  performing sufficient static analysis to be confident that there are
  no undiscovered jumps to it.  Doing that kind of static analysis on
  arbitrary binary programs is challenging and we do not attempt it.

\item Alternatively, we can use the processor's debug facilities to
  gain control, where available.  These can usually be used to insert
  breakpoints on arbitrary instructions, whether via the debug
  registers\cite{DebugRegisters} or by simply patching in a debug
  instruction, and hence can be used to gain control at any point in
  the program.  Unfortunately, they are much slower than a simple
  direct branch, as they require an expensive trap to the operating
  system kernel and, on Unix-like systems, the delivery of a signal.
\end{itemize}

We use direct jumps wherever possible and the debug facilities
otherwise.\editorial{Discussion of how often these things actually
  work?}

One potentially useful property of these patches is that they can be
straightforwardly applied to running programs, and so once a fix has
been discovered it could be applied to running applications without
any downtime or loss of data.\editorial{Application communities?}

\section{Deadlocks}
\label{sect:deadlocks}

There is a risk that introducing additional synchronisation into the
program will itself introduce a deadlock.  We mitigate the issue
slightly by using a timeout on our introduced locks, so that deadlocks
at least resolve themselves in bounded time, but this can lead to
extremely poor performance or incomplete fixing of bugs.  This could
be avoided in some cases by performing static analysis to select
critical sections which are less likely to lead to deadlocks, at the
expense of potentially not being able to find any safe fix at all.

One possible approach would be to integrate with a deadlock immunity
system such as Dimmunix\cite{Jula2008}, detecting and fixing deadlocks
as they happen.  The system would then hopefully eventually converge
on a state which is both deadlock and race free.  It should also be
possible in many cases to simulate the effect which SLI lock insertion
would have on Dimmunix, and hence to determine that Dimmunix
ultimately would insert a healing lock before it needs to do so, which
would eliminate the need to reproduce the deadlock before fixing it.
Of course, the Dimmunix lock order graph is itself only an
approximation, and so this would not be guaranteed to be effective in
every case, but it seems likely that it would be sufficient in most
situations.

We have not implemented this in our current prototype.

\section{Evaluation}

\begin{table*}
\begin{tabular}{lllllll}
Name of test & Nature & Number & Time taken & Size of & Number of & Total number of state\\
 & & of fixes & (seconds) & logfile & state machines & machine states\\
\hline
toctou & Synthetic simple & 1 & $1.18 \pm 0.02$ & 28MiB & 8 & 20\\
       & TOCTOU & & & \\
twovar & Synthetic two-variable & 2 & $1.89 \pm 0.03$ & 31MiB & 8 & 22\\
       & atomicity violation &&&\\
publish & Synthetic broken & 2 & $1.15 \pm 0.02$ & 31MiB & 5 & 16 \\
        & publish pattern & & & \\
privatize & Synthetic broken & 2 & $5.11 \pm 0.05$ & 43MiB & 5 & 16 \\
          & privatize pattern & & & \\
\hline
glibc & Kernel of a genuine & 6 & $8.15 \pm 0.03$ & 48MiB & 10 & 52\\
      & atomicity violation & & & \\
\hline
thunderbird & Genuine TOCTOU & 1 & $4740 \pm 6$ & 758MiB & 6 & 14
\end{tabular}
\caption{Summary of results obtained from running the fix generating
  tool on a single log file collected from each bug.  Timing
  information is mean and standard deviation from five runs.}
\label{tab:perf_summary}
\end{table*}

As shown in table \ref{tab:perf_summary}, our prototype implementation
is able to fix a reasonable selection of artificial bugs within a few
seconds, given only the program binary and a log of the bug
reproducing, and is able to fix at least one real-world bug within an
hour and a half.  This data also shows that the prototype avoids state
machine explosion, generating only a small number of distinct state
machines, each of which has only a small number of states (a little
over three on average, and in no case more than fourteen).
Furthermore, this time is dominated by the time spent replaying the
collected log files (especially for the most realistic bug,
\verb|thunderbird|), suggesting that improvements to our presently
very na\"ive replay engine would yield significant overall performance
gains.

\begin{figure*}
\includegraphics{timing/timings.pdf}
\caption{Breakdown of how long the various phases take, as fractions
  of the entire fix-generating process.  Mean and standard deviation
  from five runs on a single log file for each bug.}
\label{fig:phasedistribution}
\end{figure*}

Figure \ref{fig:phasedistribution} shows how the time taken is
distributed between the phases of the fix generation process.  These
phases are, in brief:

\begin{itemize}
\item Reading an initial snapshot of the program's memory.  For most
  of these tests, this snapshot is the program's initial state,
  immediately after it is created by the kernel.  For
  \verb|thunderbird|, the snapshot was taken after the test program
  had completed its initialization phase, so as to reduce the size of
  the generated log file.
\item Determining the aliasing pattern for stack resolution.  This
  involves walking over the log file, recording all of the stack
  accesses by the crashed thread and using this to determine which
  stores provide data for which loads.  This is used as input to the
  local stack resolution heuristic, described in section
  \ref{sect:resolvestack}.
\item Building the initial state machines, using the backtracking
  algorithm described in section \ref{sect:build_state_machines}.
\item Discovering relevant addresses, building logs of those
  addresses, and specializing the state machines, as described in
  section \ref{sect:multi_threading}.
\item Finally, combining the specialized machines and address logs to
  produce a set of potential fixes, using the algorithm described in
  section \ref{sect:gen_fix}.
\end{itemize}\editorial{This doesn't really belong here; maybe move into one of the implementation sections.}

Two main observations can be drawn from the figure.  First,
constructing the state machines is very quick for all of these tests,
and is barely visible in the graph.  This is reassuring, and suggests
that the algorithm is able to discard parts of the program's execution
which are not relevant to the observed crash quickly, so should be
able to scale up to more complicated bugs in a reasonably
straightforward way\editorial{Not sure I believe that}.  Second, for
the very long-running \verb|thunderbird| test the runtime is
completely dominated by the phases which involve replaying the log.
This is unsurprising, as it has by far the largest logfile, reflecting
the greater complexity of the buggy program.

\begin{figure*}
\includegraphics{timing/without_replay.pdf}
\caption{Break down of how long the phases take, ignoring time spent
  in the replay engine.  Mean and standard deviation from five runs on
  a single log file for each bug.}
\label{fig:timesignoringreplay}
\end{figure*}

Figure \ref{fig:timesignoringreplay} shows how much time is taken by
the various phases ignoring the time taken to replay the log file.
\editorial{More}

\begin{figure*}
\includegraphics{timing/r4.pdf}
\caption{Breakdown of the phases from running the fixer on five instances
  of the glibc test bug.}
\label{fig:r4}
\end{figure*}

One important parameter to the system is how far to backtrack through
the crashed thread.  For implementation reasons, our prototype will
always backtrack to a branch instruction, and for the purposes of this
evaluation we limited this backtracking to ten branches.  We
investigate the effect of changing this parameter in section
\ref{sect:eval:backtrack}.\editorial{Moo}

\subsection{Semantic knowledge}

For these tests, our only semantic knowledge is:

-- Calling \verb|__assert_fail| always leads to a crash

-- The \verb|sleep| function is a semantic no-op.  We occasionally use
this to make races reproduce more easily.

\subsection{Description of test bugs}

\verb|toctou|, a simple two-thread time-of-check, time-of-use race.
In this test, one thread loops incrementing a counter, while another
thread repeatedly issues pairs of loads of the counter and asserts
that the loads returned the same value.  Our prototype generates a
single suggested fix, which consists of two critical sections.  One of
these sections protects the write-back of the incremented counter in
the first thread, while the other protects the two loads in the second
thread.  This is a correct and minimal fix.

\verb|twovar|, a two-variable atomicity violation.  In this test,
there are two global variables, and one thread loops setting both to
five and then setting both to seven while another thread loops loading
both and asserting them to be equal.  SLI produces a single suggested
fixes in this case.  The fix contains five critical sections, one
protecting the two loads in the second thread and four singleton
instructions each of which protects a single store in the other
thread.  This correctly eliminates the bug.

This test is illustrated the effect of state machine specialization.
For the instructions between the two loads, the initial
single-threaded state machine generation process will produce a state
machine similar to this:

\begin{verbatim}
if reg(rax) != load(global2@l2)
 then crash
 else no-crash
\end{verbatim}

Where \verb|l2| is the load of the second global variable.  This
will specialize in two ways:

\begin{verbatim}
if 5 != load(global2@l2)
 then crash
 else no-crash
\end{verbatim}

\begin{verbatim}
if 7 != load(global2@l2)
 then crash
 else no-crash
\end{verbatim}

There are no points in the program's execution at which both machines
will predict \verb|no-crash|, and so the original unspecialized
machine is discarded as uninteresting.\editorial{Not sure where I'm
  going with this one...}

\verb|publish|, a broken implementation of the publish pattern.  In
this pattern, a structure is initialised by one thread and then
published by writing its address into a global pointer.  Other threads
then occasionally read this global pointer and, if it contains a
non-\verb|NULL| pointer, use the referenced object.\editorial{I'm
  convinced that this is a standard pattern, and that I didn't invent
  the term, but I can't find a reference.}  This is safe if correctly
implemented, but in this test the programmer published the structure
before finishing constructing it, which leads to the other thread
eventually crashing.  The test case consists of two threads, one of
which repeatedly publishes and un-publishes a structure and the other
of which repeatedly tests whether it has been published and, if it
has, attempts to use it in a way which leads to an immediate crash if
initialisation is not complete.

Our tool produced two suggested fixes in this case.  One of these was
expected, consisting of two critical sections, one of which contained
just the load of the global pointer in the consuming thread and the
other spanning the actions of the producing thread from the point at
which it published the structure to the point at which it finished
initialising it.  This is a correct fix.

The other suggestion was an artifact of our test harness, which
repeatedly published, initialised, unpublished, and then deinitialised
the same structure.  SLI was able to look through this pattern, and
determined that it was sufficient to prevent the consuming thread from
validating the published structure at any point between the
deinitialisation in one iteration and the initialisation in the
subsequent one.  It therefore suggested a fix which protected the load
which the consuming thread used to perform validation in one critical
section and the range of the publishing thread from the
deinitialisation to the subsequent initialisation in another,
completely ignoring the accesses related to publishing and
unpublishing the structure.  While somewhat surprising, this is also a
correct fix, completely preventing the observed bug, and, as it
produces slightly smaller critical sections, would be preferred by the
fix prioritisation heuristic.\smh{good example of a bad fix which is
  actually good.}

\verb|privatise|.  This is the converse of \verb|publish|: a thread is
attempting to make a structure private, and does it incorrectly.  It
is the same as the example program in figure
\ref{fig:broken_privatize}, which has already been extensively
discussed.

\verb|glibc| This is a kernel of glibc bug 2644 \cite{glibc2644},
which affected versions of glibc up to 2.5 and could lead to a crash
if multiple threads were shut down at the same time.  Somewhat
simplified, the code looked like this:

\begin{verbatim}
_Unwind_ForcedUnwind()
{
    if (libgcc_s_forcedunwind == NULL)
        pthread_cancel_init();
    libgcc_s_forcedunwind();
}

pthread_cancel_init()
{
    if (done_init)
        return;
    libgcc_s_forcedunwind = _forcedunwind_impl;
    done_init = 1;
}
\end{verbatim}

Where \verb|libgcc_s_forcedunwind| and \verb|done_init| are global
variables.  The compiler's optimizer transformed this such that the
code actually executed corresponded to\footnote{Unfortunately, only
  the 32-bit x86 version of gcc optimizes the function like this, and
  our implementation of SLI assumes a 64-bit x86 program, and this
  prevented us from testing with the real bug.}:

\begin{verbatim}
  _Unwind_ForcedUnwind()
  {
1:  l = libgcc_s_forcedunwind;
2:  if (l == NULL) {
3:      if (done_init) {
4:          libgcc_s_forcedunwind = l =
                _forcedunwind_impl;
5:          done_init = 1;
6:      }
7:  }
8:  l();
  }
\end{verbatim}

Our test is then to have two threads loop executing this:

\begin{verbatim}
    while (1) {
10:     pthread_barrier_wait();
11:     _Unwind_ForcedUnwind();
12:     pthread_barrier_wait();
13:     done_init = 0;
14:     libgcc_s_forcedunwind = NULL;
    }
\end{verbatim}

SLI produced six suggested fixes when run on a log generated by
running this test.

The first of these had five critical sections: one covering the load
on line 1 to the load of \verb|done_init| on line 3, and one each for
each of the stores on lines 4, 5, 13, and 14.  The other suggestions
were supersets of this suggestion, extending it to include various
accesses in \verb|pthread_barrier_wait|.

This illustrates two important weaknesses of the approach.  First,
because SLI does not know anything about any operating system-provided
functionality, it cannot take advantage of any existing
synchronization present in the program (in this case, the
\verb|pthread_barrier_wait|s make the critical sections protecting
statements 13 and 14 redundant).  It also means that the analysis must
explore these standard functions, and can sometimes attempt to ``fix''
the benign races inherent in synchronisation operations, which is
unlikely to be productive.

Second, SLI can only fix the bug which it observes.  The original
developers of this code had intended that only one thread would assign
to \verb|libgcc_s_forcedunwind|, essentially implementing a singleton
pattern.  The fix which SLI produces does not enforce the intended
constraint.  It happens that in this particular case the weaker
correctness property discovered by SLI is sufficient, but in a more
complicated example the loss of the singleton property might be a more
serious bug, and so SLI's fix might actually transform a fail-stop
crashing bug into one which causes silent data corruption.  This is
largely unavoidable without greater semantic knowledge of the
program's intended behavior, and is an inherent risk in any system
which attempts to modify a program automatically without any
programmer-provided assistance.

\verb|thunderbird| is Mozilla bug number 391259\editorial{Cite bug
  tracker?}, a simple time-of-check, time-of-use race in the IMAP
client component of Thunderbird, an e-mail client.  We modified
Thunderbird to include some additional debugging messages and used a
custom scheduler in order to make the bug reproduce more readily; this
test is otherwise as it would have been encountered in the
wild\editorial{...}.  The race is between
\verb|nsImapProtocol::CloseStreams()|, which runs on the UI thread,
and \verb|nsImapProtocol::ProcessCurrentURL()|, which runs in an IMAP
worker thread.  The relevant parts of the program are as follows:

\begin{verbatim}
void nsImapProtocol::CloseStreams()
{
  ...
  if (m_transport)
  {
      m_transport->Close(NS_ERROR_ABORT);
      m_transport = nsnull;
  }
  ...
}
\end{verbatim}

\begin{verbatim}
PRBool nsImapProtocol::ProcessCurrentURL()
{
  ...
  if (m_transport)
    m_transport->SetTimeout(
      nsISocketTransport::TIMEOUT_READ_WRITE,
      PR_UINT32_MAX);
  ...
}
\end{verbatim}

If \verb|m_transport| is set to \verb|nsnull| by \verb|CloseStreams()|
in between the two accesses in \verb|ProcessCurrentURL| then the
program will crash.  This is essentially the same bug as
\verb|toctou|, but embedded in a much large program.  As such, the
final result is similar: a single suggested fix, with two critical
sections, one containing the two accesses in \verb|ProcessCurrentURL|
and one containing the assignment in \verb|CloseStreams|.  However,
the process of generating a fix takes much longer: nearly eighty
minutes, rather than a few seconds.  The vast bulk (more than 99\%) of
this time is spent in the replay engine, reflecting the greater
complexity of the target program and the fact that the bug simply took
longer to reproduce, both of which lead to much larger log files.  It
seems likely that a more intelligent replay strategy could
significantly reduce this cost.

One interesting result, illustrated in figure
\ref{fig:timesignoringreplay}, is that even though this bug took by
far the longest to fix of any of the test cases, the time spent
performing analysis was by far the smallest.  This is because all of
the other tests execute the faulty code in a tight loop until it
crashes, which means that there are many non-crashing executions of
the code in the log, and in particular there are many stores to memory
locations involved in the state machines, and the state machines must
be evaluated against all of these stores in order to determine the
boundaries of critical sections outside of the crashed thread.  By
contrast, the \verb|thunderbird| test crashed the first time the buggy
code was run, and there are very few stores to relevant addresses.
This means that deriving these critical sections is very quick, and
the total analysis time is very small.

\subsection{Performance results}

As can be seen from table \ref{tab:perf_summary}, the time taken to
produce a fix is generally reasonable, ranging between a few seconds
in the simplest cases to an hour and half to produce suggested fixes.
The time taken by the core analysis phases is generally much less than
this, with the remainder of the time taken by loading an initial
snapshot of the program's memory and replaying the log
files.\editorial{...}

\subsection{Variability across multiple reproductions}

Figure \ref{fig:r4} shows the effect of different reproductions of a
bug upon the time taken to fix it.  In this experiment, the
\verb|glibc| bug was reproduced and logged five times, and each log
file was then used as input to the fix generation process.  Each run
reproduced the bug after a different number of iterations, and this is
reflected in the different amounts of time taken by the ``constructing
memory trace'' phase, whose time is dominated by replaying the log
file.  The other phases take roughly constant time across the five
reproductions, which again suggests that the algorithm is correctly
identifying the important parts of the execution\editorial{...}.

\subsection{Effects of backtracking further}
\label{sect:eval:backtrack}

\editorial{Do the experiments, and then write them up.}

\section{Related work}\editorial{This is a bit of a bestiary.  Could do with a bit more analysis.}

There have been a number of previous systems which tackle similar
problems.  Most recently, Kivati\cite{Chew2010a} attempts to fix
single-variable atomicity violations automatically by combining a
static analysis pass with some runtime support.  The result is able to
prevent many common kinds of race-like bugs with low overhead.  There
are a couple of important differences between their approach and ours:

\begin{itemize}
\item SLI is only activated once a bug has been observed, whereas
  Kivati runs at all times.  This means that it is more likely to
  ``fix'' perfectly benign races.  It also means that the fixes cannot
  easily be applied without also requiring the Kivati runtime,
  whereas, once generated, SLI fixes can stand alone without any of
  the rest of the SLI infrastructure, which may sometimes improve
  performance.

\item Kivati requires access to the program's source code during the
  initial static analysis phase, whereas SLI only requires the binary.

\item SLI can be applied to a wider class of bugs than Kivati, such as
  the \verb|twovar| example described above.
\end{itemize}

Another approach, taken by systems such as
Isolator\cite{Ramalingam2009} and ToleRace\cite{Kirovski2007},
restricts the problem domain to asymmetric races, where one thread is
correctly following a locking discipline while some other thread is
not, and seeks to ensure that the correct thread continues to be
correct despite the misbehavior of the incorrect one.  This might,
for instance, be useful if the correct thread is controlled by an
application while the incorrect one is controlled by a library which
the application writer is unable to modify.  As with Kivati, they do
not target specific bugs.

Atom-Aid\cite{Lucia2009} is another approach to race bug
mitigation, in this case using hardware transactional memory support.
Their approach is to bundle sequences of memory accesses into
transactions according to some heuristics, effectively reducing the
number of permissible schedules and hence the scope for memory
ordering related bugs.  Provided the necessary hardware is available,
this is simple and reasonably efficient, and should also eliminate a
reasonable selection of non-trivial bugs.  The main downside of this
approach is that it requires non-standard (and presently non-existent)
hardware, which makes it less practically useful than it otherwise
would be.  There is also a philosophical argument that, as there is no
indication that a bug has been fixed, if this approach were ever to
become widely used it would lead to a kind of moral hazard, where
programmers respond to the more accommodating hardware by becoming
more sloppy, and so overall system reliability would not increase by
as much as might otherwise have been expected.\editorial{Do I really
  want this here?}

There have also been a number of attempts to automatically fix heap
management bugs, such as buffer overflows and use-after-free errors,
most recently AutoPaG\cite{Lin2007} and Exterminator\cite{Novark2007}.
These systems both take an example of a buffer overflow bug (assumed
to be deterministic) and use various analyses to determine the root
cause of the bug, eventually using this to produce a potential fix.
In that, they are remarkably similar to the system currently under
discussion; the main difference being the type of bug targeted.

All of these systems attempt to fix bugs or otherwise prevent them
from happening.  An alternative strategy is to make bugs less serious
when they do happen.  The most famous example of such a strategy is
probably failure obliviousness\cite{Rinard2004}, which waits until the
protected program makes an invalid memory reference and then attempts
to fix things up from the resulting exception handler using a number
of heuristics.  DieHard\cite{Berger2006} is conceptually similar, but
works pre-emptively rather than from a fault handler, by guessing
where memory errors are likely to occur and modifying the program's
memory map to make those errors as harmless as possible.  In this way
programs are able to continue executing in spite of the presence of
errors which would otherwise cripple them.  Failure obliviousness
cannot, however, ever fix a bug, but instead merely lessens its
effect\editorial{That's far too glib.}.  As such, these techniques can
be seen as complementary to those discussed here.

RX\cite{Qin2007} takes a third strategy.  Here, rather than
attempting to fix the bug, an attempt is made to determine which
subset of a program's functionality is bug-free, and then to restrict
the program's inputs to only exercise that functionality.  The result
is that inputs which might have triggered the bug continue to produce
incorrect output, but the damage is at least contained rather than
propagating throughout the program and potentially leading to a crash.
This is arguably safe, although not according to the definition used
in this paper, and can cover a wide variety of bugs with little
overhead.

\section{Future work}

One major weakness of this approach is that the program to be fixed
must be first be observed to crash, and so SLI, as presented here,
cannot be applied to synchronisation bugs which lead to incorrect
behavior other than a crash.  Even when the bug does lead to a crash,
we rely on it leading to a crash quickly\editorial{Quantify?}, as
otherwise the analysis required becomes prohibitively expensive.  This
could be ameliorated somewhat using programmer- or user-provided
correctness specifications, which would allow a richer class of bugs
to be fixed, but these are likely to be difficult to obtain.
Alternatively, a scheme such as Daikon\cite{Ernst2007} or
DIDUCE\cite{Hangal2002} could be used to derive these specifications
automatically by observing the program's execution.  If we then
observed an inferred invariant shortly before SLI is invoked then that
would provide some potentially useful hints as to the nature and cause
of the error, allowing the system to be applied in many more
situations.  We intend to investigate this idea more fully in future.

\editorial{Optimizations, use of semantic knowledge, balancing use of
  dynamic oracle against static analysis.  Maybe mention deadlocks
  again?}

\section{Conclusions}

We have presented SLI, a system for automatically fixing specific
synchronisation bugs in shared-memory programs using only their
binaries, with minimal user intervention.  We have demonstrated that
it can be used to fix real-world bugs in at least some cases, and
discussed the compromises and trade-offs which are necessary in order
to produce a practically useful implementation.  While these
techniques do have a number of limitations and drawbacks, we feel that
they provide a useful basis for ongoing work to extend the set of
situations in which they are applicable.\editorial{Wibble wibble
  wibble}

\acks

\editorial{The implementation makes quite heavy use of libVEX, which I
  haven't mentioned so far.  Need to fix that somewhere.}

\bibliographystyle{eurosys}

\bibliography{library}

\end{document}

