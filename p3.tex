\documentclass[10pt,twocolumn,preprint,natbib,authoryear]{sigplanconf}
\usepackage{verbatim}
\usepackage{color}
\usepackage{graphicx}
\bibpunct{[}{]}{,}{a}{}{;}

% force pdflatex to use A4 paper
\setlength{\pdfpagewidth}{210mm}
\setlength{\pdfpageheight}{297mm}

\usepackage{amsmath}

\newcommand{\editorial}[1]{\textcolor{red}{\footnote{\textcolor{red}{#1}}}}
\newcommand{\needCite}{\editorial{need cite}}

\begin{document}

\conferenceinfo{Eurosys 2011}{date, City.} 
\copyrightyear{2005} 
\copyrightdata{[to be supplied]} 

\titlebanner{Submitted to EuroSys'11}        % These are ignored unless
%\preprintfooter{short description of paper}   % 'preprint' option specified.

\title{Speculative Lock Insertion}
%\subtitle{Subtitle Text, if any}

% For double-blind reviewing:
\authorinfo{}{}{}
%\authorinfo{Name1}
%           {Affiliation1}
%           {Email1}
%\authorinfo{Name2\and Name3}
%           {Affiliation2/3}
%           {Email2/3}

\maketitle

\begin{abstract}

The increasing use of parallel hardware suggests that synchronisation
bugs will be increasingly common, and hence that tools for diagnosing
and fixing such bugs would be useful.  In this paper, we propose
Speculative Lock Insertion, or SLI, as one possible such tool.  Using
a combination of static and dynamic analysis techniques, SLI is able
to automatically characterise and then fix a useful class of
synchronisation bugs, starting from a reproduction of the bug and the
program binary.  We demonstrate the techniques effectiveness using
both artificial and real bugs, and discuss some of the trade-offs
necessary in order to implement it.

\end{abstract}

\category{CR-number}{subcategory}{third-level}

\terms
term1, term2

\keywords
keyword1, keyword2

\section{Introduction}

There is a well-established trend in software engineering to make
greater use of multiple threads, driven largely by the increasing
availability of multi-processor systems and multi-core processors.
While potentially paying large dividends in improved responsiveness,
throughput, and power consumption, multi-threaded programming has an
unfortunate tendency to lead to very subtle bugs.  Even worse, these
bugs are often highly dependent on the low-level details of the
hardware on which the software is being run, which can often lead to
bugs which only reproduce on some small subset of computers.  This
makes testing for these bugs extremely difficult, so they are more
likely than other kinds of bugs to remain undetected in shipped
software, and also complicates the process of developing a fix, and so
once detected they remain unfixed for much longer.

A number of techniques have been proposed for reducing the likelihood
of these multi-threading bugs, including transactional
memory\cite{Shavit1997} and automatic parallelization\cite{Bacon1994}.
While extremely useful, none of these have, thus far, seen widespread
deployment.  The reasons for this are not always entirely clear, but
include concerns such as performance, a constrained problem domain, or
a lack of a widely available and widely trusted implementation.  It
seems unlikely that this situation will change in the immediate
future, and there is therefore a need for techniques which can
ameliorate bugs found by end-users in programs developed with the
currently widely-used shared memory model of concurrency.

In this paper, we introduce SLI, or Speculative Lock Insertion, as one
potential approach to this problem.  It is able to automatically fix
synchronisation bugs once they have been observed, given only the
program binary and a reproduction of the bug, generating a modified
binary whose behaviour is identical to that of the original except
that it no longer suffers from the bug.  The fixes so generated are
safe, in the sense that any behaviour which is possible with the fix
applied would also have been possible, if sometimes unlikely, without
the fix.  Furthermore, the fixes will usually have very low
performance overhead, and the process of generating the fix itself
takes only a moderate amount of time (ranging from seconds in simple
cases to a few hours for more complicated bugs).

Our approach consists of several key phases.  First, the bug must be
captured under a deterministic replay system.  The exact details of
how this is done do not matter, and so existing high-performance
replay systems such as PRES\needCite{} could be used
straightforwardly.  The captured trace is then examined in conjunction
with the program binary so as to build a series of approximations of
the parts of the program's behaviour which are most closely relevant
to the bug, in a process similar to program slicing\needCite{}.  These
approximations can be used to predict whether executing a particular
subset of a program's instructions atomically at a particular point in
its execution would have lead to a crash, and this can then be
leveraged to determine what additional synchronisation would have
prevented the crash from happening.  This synchronisation can then be
added to the program automatically using a simple binary rewriter, and
hence fix the bug.

This analysis is, unfortunately, both unsound and incomplete, in the
sense that the ``fixed'' program will still sometimes crash, and the
fix will sometimes eliminate executions which would have been safe.
This is, to some extent, inevitable, as determining whether an
arbitrary program will crash is incomputable, and to some extent an
engineering trade-off: more powerful analyses could produce more
accurate results, at the expense of greater computational complexity
in deriving a fix.  We discuss this in more detail in later sections.

In spite of this inaccuracy, the fixes generated by SLI are safe
(ignoring bugs in the implementation), in the sense that any behaviour
which is possible with a fix applied is also possible when the fix is
not applied, assuming a model of program execution in which
instructions can be arbitrarily delayed.  This corresponds to the
model presented to user-level applications by most non-realtime
operating systems, including Linux and Windows, and so this weak model
is likely to be sufficient for many pieces of widely used software.
Of course, possible is not always the same thing as desirable, and so,
for instance, it might be that a fix causes certain operations which
would otherwise always succeed to always time out, and this might
render the software unusable without being unsafe within this
definition.  It is in general extremely difficult to avoid this kind
of issue without detailed semantic knowledge of the desired behaviour
of the application, and we do not attempt it here.

\section{Capturing the bug}

Before SLI starts, the bug to be fixed must first be captured using a
deterministic replay system (DRS).  This work does not attempt to
advance the state of the art in DRSes, but does depend on them in
order to be feasible, and so we discuss them briefly here.

The only requirement we place on the choice of DRS is that it must
capture an execution sufficiently precisely that the relevant fragment
of execution can later be replayed as many times as necessary at the
accuracy of individual memory accesses.  This captured execution does
not need to be precisely the same as the original crashing execution,
but the more different it is the more likely it is that SLI will fix
the wrong bug.  The most obvious way of capturing an execution, used
in our prototype, is to simply record every single memory access
issued by the program, which is effective but has extremely high
overhead.  This could be reduced by using a more intelligent recording
mechanism such as PRES\cite{Park2009} or ODR\cite{Altekar2009}, both
of which record only a few critical events and discover the rest only
when they are needed during replay.  This approach can reduce overhead
to a level where it is sensible to run with recording enabled by
default.  An extreme form of this approach is provided by
ESD\cite{Zamfir2010}, which logs nothing at all and instead attempts
to recreate the path to failure given just the state of the program at
the time of the failure.  In a slightly different context, an
automatic program exerciser such as CHESS\cite{Musuvathi2008} could be
used to detect completely new bugs, which could then be passed to SLI
to be automatically characterised and fixed.

\section{Deriving a single-threaded explanation of the bug}

The first phase of our algorithm is to derive an explanation of the
bug which considers only the behaviour of the thread which crashed.
The result of this analysis is a series of acyclic state machines,
corresponding to instructions executed by the crashed thread towards
the end of its life, which can predict whether the thread will crash
starting from that instruction given a particular state of memory and
registers.

\subsection{Inaccuracies in the state machines}

These machines are approximations of the program's real behaviour,
exhibiting both false positive and false negative errors, and can
predict a crash where none will actually occur or safe execution when
a crash is possible.  It would be possible to design an algorithm
which avoids either or both of these classes of errors; however, doing
so would not be helpful, as it would not allow the system as a whole
to provide any stronger guarantees.

Consider false positives first, or errors where a state machine
predicts a crash when none is possible.  This will cause the final fix
to eliminate some schedules which would have been permitted with a
perfect characterisation, and so it will not be possible to guarantee
to only eliminate dangerous schedules.  However, making such a
guarantee would also require that the later stages of the system could
also guarantee to transform an arbitrary characterisation into a fix
which did not eliminate any additional schedules.  Define a schedule
to be a linearisation of the non-stack-local memory accesses produced
by a program.  The schedule produced by a parallel program can then be
regarded as one of its outputs, and determining whether a program
adheres to a given synchronisation property is then equivalent to
deciding a non-trivial property on the output of a Turing machine.  By
Rice's theorem, this is incomputable.  It seems likely that precisely
imposing a synchronisation policy is harder then checking whether a
program already follows the policy, and so this strongly suggests that
imposing such a policy is, in the general case, impossible.
Eliminating all false positives would therefore be unlikely to be
helpful.\editorial{Do I really need all of this?  More to the point,
  is it actually correct?}

Likewise, the effect of a false negative is to only partially resolve
a bug, so that some possible manifestations remain possible.  Provided
the approximation is sufficiently accurate that it predicts the
observed execution to crash, none of the unfixed manifestations will
have been observed in the crashing execution, and so guaranteeing to
fix them would require extensive static analysis of the original
binary.  Even determining whether a given instruction can be executed
is incomputable in the general case, and so this kind of analysis
seems to be far too much to hope for, and so eliminating false
negatives in the characterisation would not actually eliminate any
potential errors in the generated fixes.

As such, a perfect characterisation is not only difficult, but also
unhelpful, and we do not attempt to produce one.  This allows us to
use much simpler analyses and to produce much simpler
characterisations, which makes it more likely that the system will be
able to generate a correct fix.\editorial{Not sure I've really argued
  that very convincingingly, but nevermind.}

When we do make approximations in the characterisation, we attempt, as
far as possible, to ensure that the captured execution remains
possible, and apply coarser approximation to executions which are very
different from the captured one.  The intuition behind this is that
the captured execution is the only one which is known to be relevant
to the bug, while all of the other paths discovered by static analysis
are in some sense speculative: we do now know if they can ever happen
at all, much less if they are relevant to the observed behaviour.  It
therefore makes sense that, when an approximation must be made in
order to reduce execution time, or simply to make an analysis
feasible, it should be made on these speculative paths.

We also attempt to make the machine more accurate at points which are
nearer to the crash, and approximate more aggressively at points which
occurred earlier in the execution.\editorial{A good idea because older
  instructions require more analysis, so to keep it plausibly quick
  you need to approximate whether you want to or not.  Also, stuff
  which happened shortly before the crash is more likely to be
  interesting, anyway.}

\subsection{The proximal cause}
The first phase of our algorithm is to locate the first point in the
log at which something has definitely gone wrong, and hence to obtain
a proximal cause of the crash and to nominate one thread as being
directly responsible for it.  A naive approach would simply use the
point at which the program crashed.  In principle, this is always
correct, and for some simple bugs, such as \verb|NULL|-dereferences or
assertion failures, it works well.  However, for more complicated
classes of bugs, such as use-after-frees, there can be a significant
lag between the first definitely bad behaviour (such as the use of
released memory) and the program crash, and this can cause later
phases to take an excessively long time.  This can be mitigated by
applying a dynamic analysis tool, such as Valgrind\needCite{}, to the
captured execution, which provides a more accurate starting point for
the rest of the analysis, and hence significantly reducing the total
time taken.  In our prototype, we use a straightforward analysis to
detect use-after-free bugs at the first reference to released memory;
combining this with other forms of analysis or with
application-specific knowledge would be straightforward, and would
allow other classes of bugs to be detected.\editorial{I don't actually
  have any examples of bugs which depend on this, annoyingly.  Maybe I
  should kill it, or move it to future work?}

The result of this initial analysis is generally a single-node state
machine which captures the reason for the crash using only information
which is available at the instruction on which the crash occurred.
For instance, if the program crashed due to executing the instruction
\verb|mov (%rax), %rdx| when \verb|%rax| did not point at a valid
memory location then the machine will be
\verb|if BadAddr(reg(rax)) then crash else no-crash| (translating the
state machine into textual form using an obvious notation).

\subsection{Deriving earlier state machines}
This proximal cause is an accurate summary of why the crash occurred,
but is not, by itself, sufficient to derive a fix, as by the time the
crashing instruction is executed it is generally too late to attempt
to fix it.  It is therefore useful to move the expression backwards
through the captured execution, and hence to determine an equivalent
expression which can be evaluated earlier in the execution.  This is
straightforward for simple arithmetic instructions.  The log captured
in the initial bug-recording phase allows us to determine, for any
instruction, which instruction preceded it, and hence to apply the
instruction to the state machine.  This transforms the machine to one
which is valid before the instruction was executed.

For instance, suppose that we have encountered the instruction
\verb|add $4, %rax|, and, as above, the direct cause was
\verb|if BadAddr(reg(rax)) then crash else no-crash|.  Writing
\verb|rax0| for the value of \verb|rax| after the \verb|add|
instruction and \verb|rax1| for the value before it, we know that
\verb|rax0|$=$\verb|rax1|$+4$, and so the state machine becomes
\verb|if BadAddr(reg(rax)+4) then crash else no-crash|.  If the next
preceding instruction were \verb|mov %rcx, %rax| then the state
machine would be rewritten to
\verb|if BadAddr(reg(rcx)+4) then crash else no-crash|, and so forth.

\subsubsection{Branch instructions}
This technique allows the state machine to be transformed backwards
across most simple instructions.  Branch instructions require slightly
more care, however.  There are a few special cases.  The easiest is a
two-exit branch where both branches have constant target addresses,
and both targets were executed in the captured execution, and the
untaken target occurred after the taken one in the execution.  In that
case, we will be able to derive state machines for both targets and
then produce a new state machine which consists of both target state
machines and a new node which branches to one or the other depending
on the branch condition.  If the untaken target occurred earlier then
the taken one then combing the machines like this would risk
introducing a cycle, which would complicate later analyses, and so in
that case we treat this branch as one where the untaken target is
never seen.

In that case, or if the untaken target was genuinely never observed in
the captured execution, we determine the branch's effects using a
simple static analysis.  The first stage of this analysis is to build
an approximation of the program's control flow graph starting from the
untaken target instruction, stopping when we encounter an instruction
for which we already have a state machine.  Function calls are handled
by duplicating the called function into each possible call site.

Occasionally, this analysis will fail, either because of an indirect
branch whose target we cannot predict or because we hit a depth limit,
and in this case we place a special failed node in the graph at that
point.  Once the CFG is complete, edges which lead to these failed
nodes are removed, so that there is no path from the starting
instruction to any failed instruction; this effectively constrains the
analysis to only consider executions which have a control flow which
is sufficiently similar to that observed when the bug was captured.
This should be sufficient to derive at least a partial
fix.\editorial{...}

The next step is to reduce the CFG to an acyclic approximation of
itself, in effect assuming that loops are executed at most once.  This
assumption is, of course, unsound, and will in the majority of cases
be false, but is sufficient to provide us with a representative sketch
of the program's behaviour, and hence to produce reasonable fixes.  We
choose edges to remove based on two heuristics.  First, we try not to
remove any edges which are represented in the captured execution.
Second, we try not to partition the graph, which minimises the number
of paths which are discarded.  This ensures that the DAG is at least
plausible, even when it is not completely accurate.\editorial{...}

The result of this is a DAG of instructions, rooted at the untaken
target of the original branch instruction whose leaves already have
state machines.  It is then straightforward to propagate the state
machines backwards from the leaves to the root using the same
rewriting algorithm as we employ to backtrack state machines across
dynamically executed instructions.  The result of this is that we are
able to assign a state machine to the root instruction, and hence to
assign a state machine to the original branch instruction.

Indirect branches, and in general anywhere the target of the branch is
computed dynamically at runtime, pose an additional challenge here, as
it is often difficult to statically predict the target of the branch.
The most common case is return instructions, and we handle these by,
in effect, inlining every function into its called location, up to our
exploration depth, eliminating the return instruction completely.
Other indirect branch instructions are more challenging.  We solve
this problem by using the captured trace as a simple oracle: if the
branch instruction exists in the dynamic trace, we assume that the
instruction will always branch to the same place.  If the instruction
occurs several times then we use the last target.  This is unsound,
but is generally reasonably accurate at least near to the point of the
crash\editorial{Do I have any evidence of that?}, and is hence
sufficient for our purposes.

\subsubsection{Memory accesses}

Load instructions also require special handling in this scheme, as the
state machine for a given instruction may need to reference a load
issued by an instruction which occurs after it, and the value of the
relevant memory location might have changed by the time it executes.
We solve this problem by labelling each load expression with the
instruction pointer and call stack at the point at which it is issued,
which allows state machines to refer to loads which have not yet
happened, and hence to capture the effects of future loads on the
thread's behaviour.

These labels are ambiguous, in that multiple dynamic loads might be
referred to by a single label if the program's control flow loops.
However, as mentioned above, our analysis in effect only considers an
acyclic subgraph of the program's full control flow graph, which is
sufficient to disambiguate the labels.

The labels can also be ambiguous if a single instruction issues
multiple loads.  In the x86 instruction set, which we have targeted in
our initial prototype, the only common instructions which have this
property are the string instructions, which issue a simple instruction
in a loop.  In keeping with our strategy elsewhere, we handle this by
breaking the loop, and assuming that the simple instruction executes a
single time.  These simple instructions themselves issue at most one
load, and so the ambiguity is avoided.

The state machines must also model the effects of stores.  To do this,
each edge in the machine has a list of <address, value, size> tuples,
where address and value can be arbitrary expressions, indicating what
stores the program will issue when it follows that edge.  Backtracking
across a store instruction is then a simple matter of adding another
entry to this list.  Unfortunately, the lists of stores associated
with an edge in the state machine can become quite large for even
modest test cases, and the vast majority of these stores will never be
used.  We therefore ignore stores which occur more than a certain
distance from the point for which the state machine is being derived,
which both reduces the number of stores which have to be recorded and,
more importantly, allows many nodes in the CFG to be merged; see
section \ref{sect:validassumpt} for a discussion on the effects this
has upon performance and correctness.

\subsubsection{Resolving accesses to the thread's local stack}
\label{sect:resolvestack}

Many load instructions will access a thread's local stack.  While it
is, in principle, possible for one of these accesses to be involved in
a concurrency bug, it is in practise highly unlikely, as it is unusual
for one thread to access another's stack (see section
\ref{sect:validassumpt}).  It is therefore useful to be able to
resolve these loads, by finding the instruction which produced the
data which is loaded, without performing more expensive analysis
steps.  We use a simple heuristic in order to do this.  When we
encounter a store instruction, we check if the instruction occurred in
the captured execution.  If it did, and if it stored to the stack in
that case, we check through the log to determine which instructions
subsequently loaded the stored value.  We then check if any of those
loads appear in the current state machine, and, if they do, we assume
that they will always load the value stored by the current
instruction.  This allows the load to be eliminated, simplifying the
machines.  This is obviously an unsound heuristic, and will
occasionally produce incorrect predictions, which will lead to an
incorrect characterisation of the program's behaviour; see section
\ref{sect:validassumpt} for a discussion of the effects of these
errors upon the final result, and an estimate of the frequency of
these errors.\editorial{Whole paragraph would benefit from rewriting.}

\subsubsection{Example}\editorial{Re-do this as an inline running example.}

As an example, consider this simple program in x86 assembly language:

\begin{verbatim}
1: mov %rax, 8(%rsp)
2: je 4
3: mov %rdx, 8(%rsp)
4: mov 8(%rsp), %rax
5: mov (%rax), %rax
\end{verbatim}

Assume that we crash on statement 5, that all of the instructions are
represented somewhere in the dynamically captured execution, and that
the branch on statement 2 was taken immediately before the crash (so
that statement 3 was not executed this time).  The proximal cause of
the crash will be
\verb|if BadAddr(reg(rax)) then crash else no-crash|.  This will then
be backtracked to statement 4, producing the state machine
\verb|if BadAddr(load(reg(rsp)+8)@4) then crash else no-crash|.  The
dynamically previous instruction is statement 2, which is a branch,
and so we will attempt to derive a CFG starting at statement 2.  In
this case, the CFG is simple, and is shown in figure\editorial{...}.
Initially, only statement 3 has state machines for all of its
successor instructions, and so we will attempt to derive its state
machine first.  The stack resolution heuristic will provide a correct
solution in this case, allowing a state machine of
\verb|if BadAddr(reg(rdx)) then crash else no-crash| to be derived for
statement 3.  Statement 2's state machine can then be derived, and
becomes:

\begin{verbatim}
if CondEq
then
   if BadAddr(load(reg(rsp)+8)@4)
   then
      crash
   else
      no-crash
else
   if BadAddr(reg(rdx))
   then
      crash
   else
      no-crash
\end{verbatim}

This completes statement 2's state machine, and so we attempt to
derive statement 1's machine.  As before, the stack resolution
heuristic applies, and so the load can be resolved to match with
the current store, and so the final state machine is:

\begin{verbatim}
if CondEq
then
   if BadAddr(reg(rax))
   then
      crash
   else
      no-crash
else
   if BadAddr(reg(rdx))
   then
      crash
   else
      no-crash
\end{verbatim}

(It should be emphasised that the actual programs produced are state
machines, and do not have to be block-structured programs; the
block-structured form is simply a more convenient notation.  This
means that is not actually necessary to duplicate the branches like
this in all cases, which can ameliorate an otherwise exponential
increase in the complexity of the state machines.)

If the branch had not been taken, so statement 3 did execute, then the
a similar final result will be obtained.  In that case, we will
backtrack from statement 4 to statement 3, again using the stack load
resolution heuristic, and so statement 3's state machine is
\verb|if BadAddr(reg(rdx)) then crash else no-crash|, as before.  We
then backtrack to statement 2.  In this case, both branches already
have state machines assigned to them, and so the new state machine can
be produced directly, and is identical to that shown in
figure\editorial{...}.  From here, statement 1's state machine can be
derived in the same way as before, producing an identical answer.

\section{Investigating the multi-threaded behaviour of the program}

Once a single-threaded characterisation of the bug has been produced,
it is possible to investigate the crashed thread's interactions with
other threads in the system.  Our basic approach here is to replay the
program's execution and discover points at which the state machine
would have returned \verb|no-crash| if it had executed atomically.
From these, it is possible to infer which parts of the program's
execution should be synchronised against each other, and hence to
suggest some potentially useful synchronisations.  In principle, this
stage can run immediately as soon as the first state machine has been
derived, but it is possible to derive a significant performance
advantage by grouping machines into small batches and hence reducing
the number of times which the log file has to be
replayed.\editorial{Evidence?  Also, so what?}

The first stage is to find the last point in the captured execution at
which the state machine could have been evalated (i.e. the last point
at which the crashed thread's instruction and call stack match those
for which the state machine was derived).  We use the values of the
crashed thread's registers to specialise the state machine to this
point (we cannot do this earlier as that would break the backtracking
algorithm), so that it only depends on the content of memory.  The
state machine is then evaluated to determine which addresses it
accesses, and the captured log replayed evaluating the expression as
if atomically whenever one of these addresses changes.  This allows us
to classify the various possible states of the actual global memory as
either crash-prone or safe, such that evaluating the state machine
atomically in a safe state would not have led to a crash.

At the end of this stage, we have, for each state machine:

\begin{itemize}
\item A list of all memory accesses which the state machine depends
  on.
\item A list of all instructions which stored to one of the addresses
  which the machine depended on in the captured execution (i.e. all of
  the instructions which, when interleaved with the state machine,
  might have prevented it from executing atomically).
\item A set of sub-ranges of the execution in which the state machine
  could have executed atomically without predicting a crash.
\end{itemize}

Assuming that the unsafe regions all end on the same thread as they
started, this information can be encoded into a set of critical
sections as follows:

\begin{itemize}
\item There is one critical section which covers all of the accesses
  made by the state machine itself.
\item Every unsafe region has a critical section, starting at the
  first access in the unsafe region and ending at the final acess.
\item Every possibly-interfering store is wrapped in a single-access
  critical section, if it is not already contained in one of the
  unsafe regions.
\end{itemize}

Unsafe regions which cross threads cannot be protected in this way,
and we ignore them during fix generation, and penalise the resulting
fix when selecting which fix to actually apply (see section
\ref{sect:selecyfix}).

Our fix then consists of ensuring that the first critical section
cannot execute at the same time as any of the second two kinds.  In
our current implementation, this is done by introducing a new global
lock which is acquired before the first instruction of any of these
critical sections and then released after the last one (see section
\ref{sect:binpatch} for more details).  This is moderately
pessimistic, as it prohibits multiple threads from running sections of
the first type in parallel and prohibits sections of the second and
third type from running in parallel with each other, which would have
been allowed by the intended fix.  We made this choice purely in order
to simplify the implementation; a more intelligent implementation
could retain greater concurrency, which might lead to lower overhead,
at the expense of slightly greater implementation complexity.

\subsection{Selecting a fix}
\label{sect:selectfix}

This process might produce multiple possible fixes if multiple state
machines are available, and it is then necessary to select an
appropriate one to instantiate into a binary patch.  We use a very
simple cost heuristic to do so: the cost of a fix is given by $U.n_u +
C_s.n_s + {\sigma{}{i}}s_i$ where $n_u$ is the number of cross-thread
critical sections which we failed to encode, $n_s$ is the total number
of critical sections, $s_i$ is the number of accesses in the $i$th
critical section, $C_s$ is a constant reflecting the cost of
introducing a new empty critical section, and $U$ is a much larger
constant which reflects the logical cost of a partial fix.  Our
prototype sets $U=10000$ and $C_s=10$, strongly preferring fixes for
which all unsafe states can be eliminated and weakly preferring fixes
with a smaller number of critical sections.

In our evaluation, there are generally only a small number of possible
fixes, all of which are correct and none would obviously lead to
pathological performance, and so the exact choice of prioritisation
heuristic does not appear to be critical.

\subsection{Example}
\label{sect:ex_privatise}

Thread 1:

\begin{verbatim}
A: mov global1, %rax
B: cmp $0, %rax
C: je H
D: mov (%rax), %rcx
E: cmp $5, %rcx
F: je H
G: call __assert_fail
H: ret
\end{verbatim}

\begin{verbatim}
V: mov $5, (some_variable)
W: mov &some_variable, (global1)
...
X: mov $0, (global1)
Y: mov $0, (some_variable)
...
Z: jmp V
\end{verbatim}

This is intended to model the broken privatization bug
pattern\editorial{I thought this was standard terminology, but Google
  doesn't seem to know about it, so I guess I must have made it
  up. The privatization pattern is apparently real, though, although
  there aren't many hits on it.}, where one thread is attempting to
make a data structure private in order to clean it up but fails to do
so, leading to incorrect behaviour.  The first thread first loads a
pointer to the structure from a global variable, and then, if the
pointer is non-NULL, dereferences it and asserts that the result is
equal to five.  Meanwhile, the second thread is constantly
initialising a data structure (\verb|V|), publishing it (\verb|W|),
doing some work (\verb|...|), and then attempting to clean up
(\verb|X| and \verb|Y|).  Unfortunately, there is insufficient
synchronisation here, as the first thread might cache the pointer in
\verb|rax| after \verb|global1| has been cleared by thread 2 at
\verb|X|, and hence see the incorrect value stored at \verb|Y|,
leading to a crash.

When SLI runs, it will be presented with a log showing that the
program crashed.  Using semantic knowledge of the system's standard
library, the initial analysis will determine that executing
instruction \verb|G| will definitely lead to a crash, and so the
proximal cause will be simply \verb|crash| at \verb|G|.  This is then
backtracked to instruction \verb|F|, and static analysis will then
determine that the function would have returned if it had taken the
other branch.  We assume that making the function which crashed in the
observed reproduction return is sufficient to avoid the bug, and so
the state machine at \verb|F| is set to
\verb|if CondEq no-crash else crash|.  This can be backtracked
straightforwardly to produce a state machine for \verb|D| of

\begin{verbatim}
if 5 != (load %rax at D)
then
    crash
else
    no-crash
\end{verbatim}

and one for \verb|A| of

\begin{verbatim}
if 0 != (load global1 at A)
then
    if 5 != (load (load global1 at A) at D)
    then
         crash
    else
         no-crash
else
    no-crash
\end{verbatim}

Backtracking will then continue through the log until sufficient state
machines are available to form a useful batch for the next phase.
None of those machines will be interesting in this case, and so we
ignore them here.

We then go and build the interesting address list, which in this case
will simply contain \verb|global1| and \verb|some_variable|.

We then build the memory log, which will look like this:

\begin{verbatim}
V.1 some_variable = 5
W.1 global1 = &some_variable
X.1 global1 = 0
Y.1 some_variable = 0
V.2 some_variable = 5
W.2 global1 = &some_variable
X.2 global1 = 0
Y.2 some_variable = 0
...
\end{verbatim}

The state machine for \verb|A| will then report that a crash is never
likely if it executes atomically, and so we will propose a fix which
places one critical section from \verb|A| to \verb|D|, and
single-instruction critical sections at each of \verb|V|, \verb|W|,
\verb|X|, and \verb|Y|.  This is a correct fix, and prevents the bug
from occurring.

The state machine for \verb|D| will also be evaluated.  In this case,
it will discover that the state machine is only unsafe when executed
between \verb|Y.1| and \verb|V.2|, and so will propose a fix which
consists of a single-instruction critical section on \verb|D| and
another critical section from \verb|V| to \verb|Y|, which is again a
correct fix.

In this case, the prioritisation heuristic will prefer the second
patch, as it introduces a smaller number of additional critical
sections, and the first patch will only be used if the binary patcher
fails to instatiate the second.


\subsection{Implementation details of the binary patcher}
\label{sect:binpatch}

Once an appropriate dynamic critical section has been discovered, it
must be converted to a static one.  Mapping the dynamic points into
particular instructions is generally straightforward, but mapping
ranges can be more difficult if they cross control flow branches.

We simplify the problem by detecting if the start and end of a
critical section are in different functions (as delimited by
\verb|call| and \verb|ret| instructions) and, if they are,
backtracking up the call stack to their most recent common stack
frame.  Besides simplifying the binary patching problem, this has the
(sometimes) useful side-effect of expanding the critical section, and
generally moving it to boundaries which are more likely to correspond
to the original programmers' ideas about where critical section
boundaries ``should be''\editorial{Rephrase}.

Once we have obtained start and end points in the same function frame,
we examine the program's machine code starting from the start point,
exploring its control flow graph until we encounter the end point or
an indirect branch (the exploration process is sufficiently naive that
indirect branches cannot be sensibly predicted, and so exploration has
to stop at that point).  The CFG thus obtained is then trimmed to only
contain paths starting at the start node and ending at the end node.
The desired synchronisation can then be added to this CFG in a
straightforward way (being careful to always release any needed locks
when leaving the patch), and the result recompiled into a fragment of
position-independent machine code.  This is combined with a stub
loader and built into an ELF shared library, which can be loaded into
the target program using \verb|LD_PRELOAD| (or an equivalent runtime
mechanism using).  The stub loader is then responsible for actually
applying the patch to the program.  We use two main strategies for
doing so:

\begin{itemize}
\item The entrypoint instruction can be replaced with a direct jump to
  the patch fragment.  This is the most efficient way of gaining
  control, but is only safe if the entrypoint instruction is large
  enough to contain the jump instruction.  Otherwise, we would also
  have to change the next instruction, which is dangerous without
  performing sufficient static analysis to be confident that there are
  no undiscovered jumps to it.  Doing that kind of static analysis on
  arbitrary binary programs is challenging and we do not attempt it.

\item Alternatively, we can use the processor's debug facilities to
  gain control, where available.  These can usually be used to insert
  breakpoints on arbitrary instructions, whether via the debug
  registers\needCite{} or by simply patching in a debug instruction,
  and hence can be used to gain control at any point in the program.
  Unfortunately, they are much slower than a simple direct branch, as
  they require an expensive trap to the operating system kernel and,
  on Unix-like systems, the delivery of a signal.
\end{itemize}

We use direct jumps wherever possible and the debug facilities
otherwise.\editorial{Discussion of how often these things actually
  work?}

\section{Deadlocks}

There is a risk that introducing additional synchronisation into the
program will itself introduce a deadlock.  We mitigate the issue
slightly by using a timeout on our introduced locks, so that deadlocks
at least resolve themselves in bounded time, but this can lead to
extremely poor performance or incomplete fixing of bugs.  This could
be avoided in some cases by performing static analysis to select
critical sections which are less likely to lead to deadlocks, at the
expense of potentially not being able to find any safe fix at all.

One possible approach would be to integrate with a deadlock immunity
system such as Dimmunix\cite{Jula2008}, detecting and fixing deadlocks
as they happen.  The system would then hopefully eventually converge
on a state which is both deadlock and race free.  It should also be
possible in many cases to simulate the effect which SLI lock insertion
would have on Dimmunix, and hence to determine that Dimmunix
ultimately would insert a healing lock before it needs to do so, which
would eliminate the need to reproduce the deadlock before fixing it.
Of course, the Dimmunix lock order graph is itself only an
approximation, and so this would not be guaranteed to be effective in
every case, but it seems likely that it would be sufficient in most
situations.

We have not implemented this in our current prototype.

\section{Validation of assumptions}
\label{sect:validassumpt}

Main assumptions which we make:

-- the CFG acyclicisation thing.  Not really an assumption, although
we could maybe eval it by trying a couple of loop unrolling passes.
Probably don't have time now.  Also have the problem that it wouldn't
make any difference for any of our test bugs.

We assume in our analysis that a thread's stack will never be modified
by another thread.  We validated this assumption by writing a custom
Valgrind\needCite{} tool which counts the number of cross-thread stack
writes by a program, and demonstrated that a number of commonly-used
programs make very few such accesses (the results are in table
\ref{tab:xthreadfreq}).  These experiments are more than a bit
noddy\editorial{...}, and are not intended to tell anyone anything
which they don't already know, but are sufficient to suggest that the
assumption that stacks are thread private is unlikely to be a serious
source of inaccuracy in our characterisations.

\begin{table}
\begin{tabular}{lll}
Program & How exercised & Number of cross-thread stack modifications \\
Firefox & Started, used to load a simple page, and shut down again & 18 \\
The Gimp & Started, used to open a JPEG file, and then shut down again & 6 \\
Thunderbird & Started, used to retrieve email from an IMAP server, and shut down again & 5\\
Amarok & Started and shut down again & 12
\end{tabular}
\caption{Frequency of cross-thread stack stores for some common applications}
\label{tab:xthreadfreq}
\end{table}

Another key assumption is the stack satisfaction heuristic, used to
match loads and stores to stack addresses, described in section
\ref{sect:resolvestack}.  To validate this assumption, we implemented
another Valgrind skin which logged all stack accesses made by a
process, and then used an offline analysis to first determine what
predictions the heuristic would have made, and when they would have
been correct.  We used this tool to run part of the coreutils test
suite\editorial{version? which part?}.  The heuristic made 3067407
predictions, of which 53305 were incorrect, or roughly 1.7\%.  This is
likely to be an over-estimate of the inaccuracy introduced by the use
of the heuristic, as in many cases even an incorrect prediction will
provide a ``reasonable'' answer, and so the characterisation derived
will often still be sufficiently good to produce a fix.  As such,
these errors, while introducing some inaccuracy, do not completely
prevent the overall system from working.\editorial{Really want some
  estimate of how much we win by accepting this badness.}

-- Dropping deep loads.  Just show a graph of how likely loads are to
ever get used with respect to depth and how much we save by dropping
them -- do that on the Saturday when I get back.

-- Dropping deep branches.  Not sure about this one.  We can certainly
show how much we save by dropping; not sure whether we can show how
much it costs us -- Saturday again.

\section{Evaluation}

\begin{table*}
\begin{tabular}{lllllll}
Name of test & Nature & Number & Time taken & Size of & Number of & Number of state\\
 & & of fixes & (seconds) & logfile & state machines & machine nodes\\
\hline
toctou & Synthetic simple & 1 & $1.18 \pm 0.02$ & 28MiB & 8 & 20\\
       & TOCTOU & & & \\
twovar & Synthetic two-variable & 2 & $1.89 \pm 0.03$ & 31MiB & 8 & 22\\
       & atomicity violation &&&\\
publish & Synthetic broken & 2 & $1.15 \pm 0.02$ & 31MiB & 5 & 16 \\
        & publish pattern & & & \\
privatize & Synthetic broken & 2 & $5.11 \pm 0.05$ & 43MiB & 5 & 16 \\
          & privatize pattern & & & \\
\hline
glibc & Kernel of a genuine & 6 & $8.15 \pm 0.03$ & 48MiB & 10 & 52\\
      & atomicity violation & & & \\
\hline
thunderbird & Genuine TOCTOU & 1 & $4739 \pm 6.19$ & 758MiB & 6 & 14
\end{tabular}
\caption{Summary of results obtained from running the bug fixing
  program five times on a single log file collected from each bug.}
\label{tab:perf_summary}
\end{table*}

\begin{figure*}
\includegraphics{timing/timings.pdf}
\caption{Breakdown of how long the various phases take, as fractions
  of the entire fix-generating process.  Mean and standard deviation
  from five runs on a single log file.}
\label{fig:phasedistribution}
\end{figure*}

\begin{figure*}
\includegraphics{timing/without_replay.pdf}
\caption{Break down of how long the phases take, ignoring time spent
  in the replay engine.  Mean and standard deviation from five runs on
  a single log file for each bug.}
\label{fig:timesignoringreplay}
\end{figure*}

\begin{figure*}
\includegraphics{timing/r4.pdf}
\caption{Breakdown of the phases from running the fixer on five instances
  of the glibc test bug.}
\label{fig:r4}
\end{figure*}

Things to look at:

-- Maybe look at how much memory we need?  Tricky because of the
garbage collector.  Could maybe do a graph of memory used versus time
taken?  It's going to be very implementation-specific, though.

One important parameter to the system is how far to backtrack through
the crashed thread.  For implementation reasons, our prototype will
always backtrack to a branch instruction, and for the purposes of this
evaluation we limited this backtracking to ten branches.  We
investigate the effect of changing this parameter in section
\ref{sect:eval:backtrack}.

\subsection{Description of test bugs}

\verb|toctou|, a simple two-thread time-of-check, time-of-use race.
In this test, one thread loops incrementing a counter, while another
thread repeatedly issues pairs of loads of the counter and asserts
that the loads returned the same value.  Our prototype generates a
single suggested fix, which consists of two critical sections.  One of
these sections protects the write-back of the incremented counter in
the first thread, while the other protects the two loads in the second
thread.  This is a correct and minimal fix.

\verb|twovar|, a two-variable atomicity violation.  In this test,
there are two global variables, and one thread loops setting both to
five and then setting both to seven while another thread loops loading
both and asserting them to be equal.

\verb|publish|, a broken implementation of the publish pattern.  In
this pattern, a structure is initialised by one thread and then
published by writing its address into a global pointer.  Other threads
then occasionally read this global pointer and, if it contains a
non-\verb|NULL| pointer, use the referenced object.\editorial{I'm
  convinced that this is a standard pattern, and that I didn't invent
  the term, but I can't find a reference.}  This is safe if correctly
implemented, but in this test the programmer published the structure
before finishing constructing it, which leads to the other thread
eventually crashing.  The test case consists of two threads, one of
which repeatedly publishes and un-publishes a structure and the other
of which repeatedly tests whether it has been published and, if it
has, attempts to use it in a way which leads to an immediate crash if
initialisation is not complete.

Our tool produced two suggested fixes in this case.  One of these was
expected, consisting of two critical sections, one of which contained
just the load of the global pointer in the consuming thread and the
other spanning the actions of the producing thread from the point at
which it published the structure to the point at which it finished
initialising it. \editorial{...}  This is a correct fix.

The other suggestion was an artifact of our test harness, which
repeatedly published, initialised, unpublished, and then deinitialised
the same structure.  SLI was able to look through this pattern, and
determined that it was sufficient to prevent the consuming thread from
validating the published structure at any point between the
deinitialisation in one iteration and the initialisation in the
subsequent one.  It therefore suggested a fix which protected the load
which the consuming thread used to perform validation in one critical
section and the range of the publishing thread from the
deinitialisation to the subsequent initialisation in another,
completely ignoring the accesses related to publishing and
unpublishing the structure.  While somewhat surprising, this is also a
correct fix, completely preventing the observed bug, and, as it
produces slightly smaller critical sections, would be preferred by the
fix prioritisation heuristic.

\verb|privatise|.  This is the converse of \verb|publish|: a thread is
attempting to make a structure private, and does it incorrectly.  It
has already been extensively discussed in section
\ref{sect:ex_privatise}, including a description of the fixes
suggested by SLI.

\verb|glibc| This is a kernel of glibc bug 2644\editorial{cite bug
  tracker}, which affected versions of glibc from \editorial{...}  to
\editorial{...} and could lead to a crash if multiple threads were
shut down at the same time.  Somewhat simplified, the code looked like
this:

\begin{verbatim}
_Unwind_ForcedUnwind() {
    if (libgcc_s_forcedunwind == NULL)
        pthread_cancel_init();
    libgcc_s_forcedunwind();
}

pthread_cancel_init()
{
    if (done_init)
        return;
    libgcc_s_forcedunwind = _forcedunwind_impl;
    done_init = 1;
}
\end{verbatim}

Where \verb|libgcc_s_forcedunwind| and \verb|done_init| are global
variables.  Due to compiler optimisations, the code actually executed
was closer to this\footnote{Unfortunately, modern versions of gcc no
  longer optimise the function in this way, and this prevented us from
  testing the real bug.}:

\begin{verbatim}
_Unwind_ForcedUnwind() {
1:  l = libgcc_s_forcedunwind;
2:  if (l == NULL) {
3:      if (done_init) {
4:          libgcc_s_forcedunwind = l =
                _forcedunwind_impl;
5:          done_init = 1;
6:      }
7:  }
8:  l();
}
\end{verbatim}

Our test is then to have two threads loop executing this:

\begin{verbatim}
    while (1) {
10:     pthread_barrier_wait();
11:     _Unwind_ForcedUnwind();
12:     pthread_barrier_wait();
13:     done_init = 0;
14:     libgcc_s_forcedunwind = NULL;
    }
\end{verbatim}

SLI produced six suggested fixes when run on a log generated by
running this test.

The first of these had five critical sections: one covering the load
on line 1 to the load of \verb|done_init| on line 3, and one each for
each of the stores on lines 4, 5, 13, and 14.  The other suggestions
were supersets of this suggestion, extending it to include various
accesses in \verb|pthread_barrier_wait|.

This illustrates two important weaknesses of the approach.  First,
because SLI does not know anything about any operating-system.  This
means that it cannot take advantage of any existing synchronisation
present in the program (in this case, the \verb|pthread_barrier_wait|s
make the critical sections protecting statements 13 and 14 redundant).
It also means that the analysis must explore these standard functions,
and can sometimes attempt to ``fix'' the benign races inherent in
synchronisation operations, which is unlikely to be productive.

Second, SLI can only fix the bug which it observes.  The original
developers of this code had intended that only one thread would assign
to \verb|libgcc_s_forcedunwind|, essentially implementing a singleton
pattern.  The fix which SLI produces does not enforce the intended
constraint.  It happens that in this particular case the weaker
correctness property discovered by SLI is sufficient, but in a more
complicated example the loss of the singleton property might be a more
serious bug, and so SLI's fix might actually transform a fail-stop
crashing bug into one which causes silent data corruption.  This is
largely unavoidable without greater semantic knowledge of the
program's intended behaviour, and is an inherent risk in any system
which attempts to modify a program automatically without any
programmer-provided assistance.

\verb|thunderbird| is Mozilla bug number 391259\editorial{Cite bug
  tracker?}, a simple time-of-check, time-of-use race in the IMAP
client component of Thunderbird, an e-mail client.  The race is
between \verb|nsImapProtocol::CloseStreams()|, which runs on the UI
thread, and \verb|nsImapProtocol::ProcessCurrentURL()|, which runs in
an IMAP worker thread.  The relevant parts of the program are as
follows:

\begin{verbatim}
void nsImapProtocol::CloseStreams()
{
  ...
  if (m_transport)
  {
      // make sure the transport closes (even if someone is still indirectly
      // referencing it).
      m_transport->Close(NS_ERROR_ABORT);
      m_transport = nsnull;
  }
  ...
}
\end{verbatim}

\begin{verbatim}
PRBool nsImapProtocol::ProcessCurrentURL()
{
  ...
  // disable timeouts before caching connection.
  if (m_transport)
    m_transport->SetTimeout(nsISocketTransport::TIMEOUT_READ_WRITE, PR_UINT32_MAX);
  ...
}
\end{verbatim}

If \verb|m_transport| is set to \verb|nsnull| by \verb|CloseStreams()|
in between the two accesses in \verb|ProcessCurrentURL| then the
program will crash.  This is essentially the same bug as
\verb|toctou|, but embedded in a much large program.  As such, the
final result is similar: a single suggested fix, with two critical
sections, one containing the two accesses in \verb|ProcessCurrentURL|
and one containing the assignment in \verb|CloseStreams|.  However,
the process of generating a fix takes much longer: nearly eighty
minutes, rather than a few seconds.  The vast bulk (more than 99\%) of
this time is spent in the replay engine, reflecting the greater
complexity of the target program and the fact that the bug simply took
longer to reproduce, both of which lead to much larger log files.  It
seems likely that a more intelligent replay strategy could
significantly reduce this cost.

One interesting result, illustrated in figure
\ref{fig:timesignoringreplay}, is that even though this bug took by
far the longest to fix of any of the test cases, the time spent
performing analysis was by far the smallest.  This is because all of
the other tests execute the faulty code in a tight loop until it
crashes, which means that there are many non-crashing executions of
the code in the log, and in particular there are many stores to memory
locations involved in the state machines, and the state machines must
be evaluated against all of these stores in order to determine the
boundaries of critical sections outside of the crashed thread.  By
contrast, the \verb|thunderbird| test crashed the first time the buggy
code was run, and there are very few stores to relevant addresses.
This means that deriving these critical sections is very quick, and
the total analysis time is very small.

\subsection{Performance results}

As can be seen from table \ref{tab:perf_summary}, the time taken to
produce a fix is generally reasonable, ranging between a few seconds
in the simplest cases to an hour and half to produce suggested fixes.
The time taken by the core analysis phases is generally much less than
this, with the remainder of the time taken by loading an initial
snapshot of the program's memory and replaying the log
files.\editorial{...}

\subsection{Variability across multiple reproductions}

Figure \ref{fig:r4} shows the effect of different reproductions of a
bug upon the time taken to fix it.  In this experiment, the
\verb|glibc| bug was reproduced and logged five times, and each log
file was then used as input to the fix generation process.  Each run
reproduced the bug after a different number of iterations, and this is
reflected in the different amounts of time taken by the ``constructing
memory trace'' phase, whose time is dominated by replaying the log
file.  The other phases take roughly constant time across the five
reproductions, which again suggests that the algorithm is correctly
identifying the important parts of the execution\editorial{...}.

\subsection{Effects of backtracking further}
\label{sect:eval:backtrack}

\editorial{Do the experiments, and then write them up.}

\section{Related work}\editorial{This is a bit of a bestiary.  Could do with a bit more analysis.}

There have been a number of previous systems which tackle similar
problems.  Most recently, Kivati\cite{Chew2010a} attempts to fix
single-variable atomicity violations automatically by combining a
static analysis pass with some runtime support.  The result is able to
prevent many common kinds of race-like bugs with low overhead.  There
are a couple of important differences between their approach and ours:

\begin{itemize}
\item SLI is only activated once a bug has been observed, whereas
  Kivati runs at all times.  This means that it is more likely to
  ``fix'' perfectly benign races.  It also means that the fixes cannot
  easily be applied without also requiring the Kivati runtime,
  whereas, once generated, SLI fixes can stand alone without any of
  the rest of the SLI infrastructure, which may sometimes improve
  performance.

\item Kivati requires access to the program's source code during the
  initial static analysis phase, whereas SLI only requires the binary.

\item In theory, SLI can be applied to a wider class of bugs than
  Kivati, although in practise the complexity of the analysis and the
  difficulty of generating a fix for more complicated bugs means that
  this is not a particularly useful ability.
\end{itemize}

Another approach, taken by systems such as
Isolator\cite{Ramalingam2009} and ToleRace\cite{Kirovski2007},
restricts the problem domain to asymmetric races, where one thread is
correctly following a locking discipline while some other thread is
not, and seeks to ensure that the correct thread continues to be
correct despite the misbehaviour of the incorrect one.  This might,
for instance, be useful if the correct thread is controlled by an
application while the incorrect one is controlled by a library which
the application writer is unable to modify.  As with Kivati, they do
not target specific bugs.

Atom-Aid\cite{Lucia2009} is another approach to race bug
mitigation, in this case using hardware transactional memory support.
Their approach is to bundle sequences of memory accesses into
transactions according to some heuristics, effectively reducing the
number of permissible schedules and hence the scope for memory
ordering related bugs.  Provided the necessary hardware is available,
this is simple and reasonably efficient, and should also eliminate a
reasonable selection of non-trivial bugs.  The main downside of this
approach is that it requires non-standard (and presently non-existent)
hardware, which makes it less practically useful than it otherwise
would be.  There is also a philosophical argument that, as there is no
indication that a bug has been fixed, if this approach were ever to
become widely used it would lead to a kind of moral hazard, where
programmers respond to the more accommodating hardware by becoming
more sloppy, and so overall system reliability would not increase by
as much as might otherwise have been expected.\editorial{Do I really
  want this here?}

There have also been a number of attempts to automatically fix heap
management bugs, such as buffer overflows and use-after-free errors,
most recently AutoPaG\cite{Lin2007} and Exterminator\cite{Novark2007}.
These systems both take an example of a buffer overflow bug (assumed
to be deterministic) and use various analyses to determine the root
cause of the bug, eventually using this to produce a potential fix.
In that, they are remarkably similar to the system currently under
discussion; the main difference being the type of bug targeted.

All of these systems attempt to fix bugs or otherwise prevent them
from happening.  An alternative strategy is to make bugs less serious
when they do happen.  The most famous example of such a strategy is
probably failure obliviousness\cite{Rinard2004}, which waits until the
protected program makes an invalid memory reference and then attempts
to fix things up from the resulting exception handler using a number
of heuristics.  DieHard\cite{Berger2006} is conceptually similar, but
works pre-emptively rather than from a fault handler, by guessing
where memory errors are likely to occur and modifying the program's
memory map to make those errors as harmless as possible.  In this way
programs are able to continue executing in spite of the presence of
errors which would otherwise cripple them.  Failure obliviousness
cannot, however, ever fix a bug, but instead merely lessens its
effect\editorial{That's far too glib.}.  As such, these techniques can
be seen as complementary to those discussed here.

RX\cite{Qin2007} takes a third strategy.  Here, rather than
attempting to fix the bug, an attempt is made to determine which
subset of a program's functionality is bug-free, and then to restrict
the program's inputs to only exercise that functionality.  The result
is that inputs which might have triggered the bug continue to produce
incorrect output, but the damage is at least contained rather than
propagating throughout the program and potentially leading to a crash.
This is arguably safe, although not according to the definition used
in this paper, and can cover a wide variety of bugs with little
overhead.

\section{Future work}

One major weakness of this approach is that the program to be fixed
must be first be observed to crash, and so SLI, as presented here,
cannot be applied to synchronisation bugs which lead to incorrect
behaviour other than a crash.  Even when the bug does lead to a crash,
we rely on it leading to a crash quickly\editorial{Quantify?}, as
otherwise the analysis required becomes prohibitively expensive.  This
could be ameliorated somewhat using programmer- or user-provided
correctness specifications, which would allow a richer class of bugs
to be fixed, but these are likely to be difficult to obtain.
Alternatively, a scheme such as Daikon\needCite{} or DIDUCE\needCite{}
could be used to derive these specifications automatically by
observing the program's execution.  If we then observed an inferred
invariant shortly before SLI is invoked then that would provide some
potentially useful hints as to the nature and cause of the error,
allowing the system to be applied in many more situations.  We intend
to investigate this idea more fully in future.

\section{Conclusions}

We have presented SLI, a system for automatically fixing specific
synchronisation bugs in shared-memory programs using only their
binaries, with minimal user intervention.  We have demonstrated that
it can be used to fix real-world bugs in at least some cases, and
discussed the compromises and trade-offs which are necessary in order
to produce a practically useful implementation.  While these
techniques do have a number of limitations and drawbacks, we feel that
they provide a useful basis for ongoing work to extend the set of
situations in which they are applicable.\editorial{Wibble wibble
  wibble}

\acks

\editorial{The implementation makes quite heavy use of libVEX, which I
  haven't mentioned so far.  Need to fix that somewhere.}

\bibliographystyle{eurosys}

\bibliography{eurosys-sample-bib}    

\end{document}

