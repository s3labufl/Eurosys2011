\documentclass[10pt,twocolumn,preprint,natbib,authoryear]{sigplanconf}
\usepackage{verbatim}
\usepackage{color}
\usepackage{graphicx}
\bibpunct{[}{]}{,}{a}{}{;}

% force pdflatex to use A4 paper
\setlength{\pdfpagewidth}{210mm}
\setlength{\pdfpageheight}{297mm}

\usepackage{amsmath}
\usepackage{subfigure}

%\newcommand{\editorial}[1]{\textcolor{red}{\footnote{\textcolor{red}{#1}}}}
\newcommand{\editorial}[1]{}
\newcommand{\needCite}{\editorial{need cite}}
\newcommand{\smh}[1]{\editorial{SMH says: #1}}

\newbox\subfigbox             % Create a box to hold the subfigure.
\makeatletter
  \newenvironment{subfloat}% % Create the new environment.
    {\def\caption##1{\gdef\subcapsave{\relax##1}}%
     \let\subcapsave=\@empty % Save the subcaption text.
     \let\sf@oldlabel=\label
     \def\label##1{\xdef\sublabsave{\noexpand\label{##1}}}%
     \let\sublabsave\relax    % Save the label key.
     \setbox\subfigbox\hbox
       \bgroup}%              % Open the box...
      {\egroup                % ... close the box and call \subfigure.
     \let\label=\sf@oldlabel
     \subfigure[\subcapsave]{\box\subfigbox}}%
\makeatother

\begin{document}

\conferenceinfo{Eurosys 2011}{date, City.} 
\copyrightyear{2005} 
\copyrightdata{[to be supplied]} 

\titlebanner{Submitted to EuroSys'11}        % These are ignored unless
%\preprintfooter{short description of paper}   % 'preprint' option specified.

\title{Speculative Lock Insertion}
%\subtitle{Subtitle Text, if any}

% For double-blind reviewing:
\authorinfo{}{}{}
%\authorinfo{Name1}
%           {Affiliation1}
%           {Email1}
%\authorinfo{Name2\and Name3}
%           {Affiliation2/3}
%           {Email2/3}

\maketitle

\begin{abstract}

The increasing use of parallel hardware suggests that synchronization
bugs will be increasingly common, and hence that tools for diagnosing
and fixing such bugs would be useful.  In this paper, we propose
Speculative Lock Insertion, or SLI, as one possible such tool.  Using
a combination of static and dynamic analysis techniques, SLI is able
to automatically characterize and then fix a useful class of
synchronization bugs, starting from a reproduction of the bug and the
program binary.  We demonstrate the technique's effectiveness using
both real and artificial bugs, and discuss some of the trade-offs
necessary in order to implement it.

\end{abstract}

\category{D.2.5}{Testing and Debugging}{Debugging aids}

\terms
Reliability

\keywords
Synchronization, automated bug-fixing

\section{Introduction}

The increasing availability of multi-core and multi-processor systems
is driving a trend towards software with a greater degree of
parallelism, but, while potentially paying dividends in improved
responsiveness, throughput, and power consumption, multi-threaded
programming has an unfortunate tendency to lead to very subtle bugs.
Even worse, it is often difficult to trigger these bugs reliably,
which means that they are less likely to be discovered by testing and
harder to fix once they have been discovered.  A number of techniques
have been proposed for reducing the likelihood of such errors,
including transactional memory\cite{Shavit1997} and automatic
parallelization\cite{Bacon1994}, but, while potentially greatly
reducing the incidence of synchronization mistakes in new software,
they cannot be directly applied to the large body of existing
concurrent software.  There is therefore a need for techniques which
can assist in fixing bugs in programs written using the currently
widely-used shared memory model of concurrency.  In this paper, we
introduce SLI, or Speculative Lock Insertion, as one potential
approach to this problem.  SLI automatically fixes observed
synchronization bugs, given only the program binary and a reproduction
of the bug, generating a modified binary whose behavior is identical
to that of the original except that it no longer suffers from the bug.
Furthermore, the fixes will usually have very low performance
overhead, and the process of generating the fix itself takes only a
moderate amount of time (ranging from seconds in simple cases to a few
hours in more complicated ones).  SLI does not depend on programmer
annotations or semantic knowledge of the program's intended behavior,
but can make use of such information when it is available.

Our approach consists of several key phases.  First, the bug must be
captured under a deterministic replay system such as
PRES\cite{Park2009} or ReVirt\cite{Dunlap2002}.  The captured trace is
then examined in conjunction with the program binary, building a
series of approximations of the parts of the program's behavior which
are most closely relevant to the bug in a process similar to program
slicing\cite{Weiser1979}.  These approximations can be used to predict
whether executing a particular subset of a program's instructions
atomically would have led to a crash, and this can be leveraged to
determine what additional synchronization would have prevented the
crash from happening.  This synchronization can then be added to the
program automatically using a simple binary rewriter, fixing the
observed bug.

The fixes generated by SLI are safe, in the sense that any behavior
which is possible with a fix applied is also possible when the fix is
not applied, assuming a model of program execution in which
instructions can be arbitrarily delayed.  This corresponds to the
model presented to user-level applications by most non-realtime
operating systems, including Linux and Windows, and so is likely to be
sufficient for many pieces of widely used software.

Of course, possible is not always the same as desirable.  For example,
it might be that a fix causes certain operations which would otherwise
succeed to always time out, and this might render the software
unusable without being unsafe within this definition.  Identifying
such time-dependent correctness constraints is difficult without
semantic knowledge of the program's intended behavior, and
automatically determining whether a fix causes some to be violated is
even more challenging, and so it seems likely that this weakness will
be inherent in any scheme which fixes bugs without reference to a
manually-generated specification of the fixed program.\editorial{Not
  very happy with that phrasing.}

\section{Capturing the bug}

Before SLI starts, the bug to be fixed must first be captured using a
deterministic replay system (DRS).  This work does not attempt to
advance the state of the art in DRSes, but does depend on them in
order to be feasible, and so we discuss them briefly here.  The only
requirement we place on the choice of DRS is that it must allow us to
replay the relevant fragment of execution as many times as necessary
and produce the same sequence of memory accesses each time.  This
captured execution does not need to be precisely the same as the
original crashing execution (although excessive errors here could lead
to SLI fixing the wrong bug).  The most obvious way of capturing an
execution, used in our prototype, is to simply record every single
memory access issued by the program, which is effective but has
extremely high overhead.  This could be reduced by using a more
intelligent recording mechanism such as PRES or ODR\cite{Altekar2009},
both of which record only a few critical events and discover the rest
only when they are needed during replay.  This can reduce overhead to
a level where it is sensible to run with recording enabled by default.
ESD\cite{Zamfir2010} is an extreme form of this approach, and logs
nothing at all but instead attempts to recreate the path to failure
given just the state of the program at the time of the crash.  In a
slightly different context, an automatic program exerciser such as
CHESS\cite{Musuvathi2008} could be used to detect unknown bugs, which
could then be passed to SLI to be automatically characterized and
fixed.\editorial{I want to use the phrase closed-loop here}

\section{Deriving a single-threaded explanation of the bug}
\label{sect:build_state_machines}

The first phase of our algorithm is to derive an explanation of the
bug considering only the behavior of the thread which crashed.  The
result of this analysis is a series of acyclic state machines,
corresponding to instructions executed by the crashed thread towards
the end of its life, which predict whether the thread will crash
starting from that instruction given a particular state of memory and
registers.  These machines are approximations of the program's real
behavior, exhibiting both false positive and false negative errors,
and can predict a crash where none will actually occur or safe
execution when a crash is possible.  It would be possible to design an
algorithm which avoids either or both of these classes of errors, but
doing so would not necessarily be helpful.

Consider false positives, where a state machine predicts a crash when
none is possible, first.  These will cause the final fix to eliminate
some schedules which would have been permitted with a perfect
characterization, but, provided that there is always some schedule
available (see section \ref{sect:deadlocks}), this cannot cause a
correct program to become incorrect.  SLI can therefore tolerate some
level of false positives in the characterization without producing
incorrect fixes.  Likewise, the effect of a false negative is to only
partially resolve a bug, so that some possible manifestations remain
possible.  This is indistinguishable from there simply being several
bugs, and so, provided that the characterization is sufficiently
accurate to predict a crash for the captured execution, false
negatives do not prevent SLI from fulfilling its goal of fixing the
observed crash.\editorial{Feels glib.}

As such, a perfect characterization is not only difficult, but also
unhelpful, and we do not attempt to produce one.  This allows us to
use much simpler analyses and to produce much simpler
characterizations, which makes it more likely that the system will be
able to generate a correct fix.  When we do make approximations in the
characterization, we attempt to ensure that the captured execution
remains possible, and apply coarser approximation to executions which
are very different from the captured one.  The intuition behind this
is that the captured execution is the only one which is known to be
relevant to the bug, while all of the other paths discovered by static
analysis are speculative: we do not know if they can ever happen at
all, much less if they are relevant to the observed behavior.  It
therefore makes sense that, when an approximation must be made in
order to reduce execution time, or simply to make an analysis
feasible, it should be made on these speculative paths.

%% Similarly, we also attempt to make the machine more accurate at
%% points which are nearer to the crash, and approximate more
%% aggressively at points which occurred earlier in the execution.
%% There are two main reasons for this.  First, details which occur
%% shortly before the crash are more likely to be directly relevant to
%% it.  Second, the time taken by some of the analysis steps involved
%% in producing a state machine grow more than linearly in the
%% distance to the crash, and so more aggressive simplification is
%% necessary in order to keep the analysis tractable.\editorial{Not
%% well explained}

\subsection{The proximal cause}
\label{sect:prox_cause}
The first phase of our algorithm is to locate the first point in the
log at which something has definitely gone wrong, and hence to obtain
a proximal cause of the crash and to nominate one thread as being
directly responsible for it.  A naive approach would simply use the
point at which the program crashed.  In principle, this is always
correct, and for some simple bugs, such as \verb|NULL|-dereferences or
assertion failures, it works well.  However, for more complicated
classes of bugs, such as use-after-frees, there can be a significant
lag between the first definitely bad behavior (such as the use of
released memory) and the program crash, and this can complicated later
phases.  This can be mitigated by applying a dynamic analysis tool,
such as Valgrind\cite{Nethercote2007}, to the captured execution,
which provides a more accurate starting point for the rest of the
analysis.  We have implemented a a straightforward analysis to detect
use-after-free bugs at the first reference to released memory as part
of our prototype; combining this with other forms of analysis or with
application-specific knowledge would be straightforward, and would
allow other classes of bugs to be detected.

\begin{figure*}
 \begin{subfloat}
  \begin{minipage}{90mm}
\begin{verbatim}
A: mov (global1) -> %rax
B: mov %rax -> (%rsp)
C: cmp $0, %rax
D: jne F
E: mov &fallback -> (%rsp)
F: mov (%rsp) -> %rcx
G: mov (%rcx) -> %rdx
H: add $48, %rdx
J: mov (%rdx) -> %rax
K: ret
\end{verbatim}
  \end{minipage}
  \caption{Thread 1}
 \end{subfloat}
 \begin{subfloat}
  \begin{minipage}{90mm}
\begin{verbatim}
V: mov &struct1 -> (variable1)
W: mov &variable1 -> (global1)
...
X: mov $0 -> (global1)
Y: mov $0 -> (variable1)
...
Z: jmp V
\end{verbatim}
  \end{minipage}
  \caption{Thread 2}
 \end{subfloat}
 \caption{A buggy example of the privatize synchronization pattern.}
 \label{fig:broken_privatize}
\end{figure*}

The result of this initial analysis is generally a single-node state
machine which captures the reason for the crash using only information
which is available at the instruction on which the crash occurred.
For example, consider the program shown in figure
\ref{fig:broken_privatize}, which is intended to be a buggy instance
of the common structure privatization pattern\needCite{} in an
x86-like assembly language.  Thread 2 initializes (\verb|V|) and
publishes (\verb|W|) a structure, does some unrelated work, and then
attempts to privatize (\verb|X|) and de-initialise (\verb|Y|) the
structure.  Meanwhile, thread 1 loads the pointer published by thread
2 (\verb|A|), checks whether it is valid (\verb|B|, \verb|C| and
\verb|D|), and, if it is not, loads a fallback version (\verb|E|),
before attempting to use it (\verb|F| through \verb|J|).  This will
lead to a crash if instructions \verb|X| and \verb|Y| occur between
instructions \verb|A| and \verb|G|, as in that case \verb|rdx| will
contain a bad pointer at instruction \verb|J|, which will cause an
immediate crash.  The proximal cause is then simply
\verb|if BadAddr rdx then crash else no-crash| (translating the state
machine into text in the obvious way), and is valid at the start of
instruction \verb|J|.

\subsection{Deriving earlier state machines}
This proximal cause is accurate but not, by itself, sufficient to
derive a fix, as by the time the crashing instruction is executed it
is generally too late to attempt to fix it.  It is therefore useful to
move the expression backwards through the captured execution, and
hence to determine an equivalent expression which can be evaluated
earlier in the execution.  This is straightforward for simple
arithmetic instructions.  The log captured in the initial
bug-recording phase allows us to determine, for any instruction, which
instruction preceded it, and hence to apply the instruction to the
state machine.  This transforms the machine to one which is valid
before the instruction was executed.

In the example, the preceding instruction is \verb|add $48, %rdx|.
This transforms \verb|rdx| into \verb|rdx+48|.  Applying this
transformation to the proximal cause of the crash produces
\verb|if BadAddr (rdx+48) then crash else no-crash|.  This is valid at
the start of instruction \verb|H|.  Other simple register-to-register
arithmetic instructions can be handled in the same way, and hence the
crash reason can be backtracked across any sequence of such
instructions.

\editorial{Our implementation uses libVEX to decode x86 instructions
  into a sequence of micro-operations which can be used as input to
  this process.} 

\subsubsection{Memory accesses}

Load instructions require special handling in this scheme, as the
state machine for a given instruction may need to reference a load
issued by an instruction which occurs after it, and the value of the
relevant memory location might have changed by the time it executes.
We solve this problem by labelling each load expression with the
instruction pointer and call stack at the point at which it is issued,
which allows state machines to refer to loads which have not yet
happened, and hence to capture the effects of future loads on the
thread's behavior.  This means that the state machine for instruction
\verb|H| of the example can be backtracked to the start of instruction
\verb|G| to produce a state machine

\begin{verbatim}
if BadAddr (load(rcx@G) + 48)
 then crash
 else no-crash
\end{verbatim}

This can in turn be backtracked to the start of \verb|F|, producing

\begin{verbatim}
if BadAddr (load(load(rsp@F)@G) + 48)
 then crash
 else no-crash
\end{verbatim}

The state machines must also model the effects of stores.  To do this,
each edge in the machine has a list of $\langle{}$address, value,
size$\rangle{}$ tuples, where address and value can be arbitrary
expressions, indicating what stores the program will issue when it
follows that edge.  Backtracking across a store instruction is then a
simple matter of adding another entry to this list.\editorial{I used
  to have a bit about dropping deep loads, but having run the
  experiments, it turns out that really doesn't matter.  Which is odd,
  because it used to be a major optimization, but I guess some of the
  improvements to the alias resolution stuff must have obviated it.}

Many load instructions access a thread's local stack, and while it is
in principle possible for one of these accesses to be involved in a
concurrency bug, it is in practise highly unlikely, as it is unusual
for one thread to access another's stack.  It is therefore useful to
be able to match these loads to the stores which originally produced
the loaded value and hence eliminate them.  We use a simple stack
resolution heuristic to do so.  When we encounter a store instruction,
we check if the instruction occurred in the captured execution, and if
it did, and it stored to the stack in that case, we traverse the log
to determine which instructions subsequently loaded the stored value.
If any of those loads appear in the current state machine then we
assume that they will load the value stored by this instruction,
eliminating them and thus simplifying the machine.\editorial{Would
  also benefit from some eval.}

\subsubsection{Branch instructions}
\label{sect:branch_instrs}
Branch instructions also require care, as they may involve parts of
the program which were not used in the captured execution, for which
no state machines will be available.  We determine the effects of
unexecuted code using a simple static analysis.  The first stage of
this analysis is to build an approximation of the program's control
flow graph starting from the branch instruction and stopping when we
encounter an instruction for which we already have a state machine.
The state machines can then be propagated backwards through the graph
using the same algorithm as we use to backtrack across
dynamically-executed instructions, and a state machine can hence be
derived for the root of the graph and the original branch instruction.

Indirect branches, and any other branches which compute their target
dynamically, pose an additional challenge here, as it is often
difficult to statically predict the target of the branch.  The most
common case is return instructions, and we handle these by inlining
called functions, eliminating most return instructions completely.
The remainder correspond to functions which had started but not
completed at the time of the crash, and we assume that if any of those
return then the bug has been avoided.

Other indirect branch instructions are more challenging.  We solve
this problem by using the captured trace as a simple oracle: if the
branch instruction exists in the dynamic trace, we assume that the
instruction will always branch to the same place (if it occurs several
times then we use the last target).  If the instruction did not occur,
or if the exploration simply reaches its depth limit, we place a
special analysis-failed node in the graph.  Once the CFG is complete,
we eliminate all branches to these failed nodes; if that causes some
node to have no known successors then that node is also marked as
analysis-failed, and the process iterates until all failed nodes are
removed.  Branches taken in the captured execution will always be
preserved at this stage, as the oracle will always be able to provide
at least some prediction of their target, and, as they are on the
captured trace, they cannot be beyond the depth limit\editorial{Not
  sure that's very clear}.  As such, this step can be seen as pruning
the set of paths considered to be only those which are sufficiently
similar to the captured execution.

Loops also complicate this simple algorithm.  We avoid the problem by
breaking them, removing a subset of the graph's edges so as to
eliminate the loop.  We choose edges to remove based on two
heuristics.  First, we try not to remove any edges which are present
in the captured execution.  Second, we try not to partition the graph,
so as many instructions as possible, and hence as much of the
program's behavior as possible, are represented in the final state
machine.

Breaking loops has the useful side-effect of disambiguating the labels
used to refer to load instructions: in a loop-free control flow graph,
each instruction is executed at most once, and so dynamic instructions
can be referred to unambiguously by their static location in the CFG.
In the case of the x86 architecture, all common instructions which
perform multiple loads can be converted into loops, which can then be
broken in the usual way, and so this is sufficient to ensure that any
static instruction issues at most one dynamic load and hence that load
labels refer to at most one load.

The result is a DAG of instructions, rooted at the branch instruction
and with state machines at all of its leaves, which approximates the
part of the static CFG of the program which is most relevant to the
captured execution.  This approximation is often imperfect, but, as
discussed above, such imperfections will not always prevent SLI from
generating at least a partial fix for the bug, and hence can usually
be tolerated in exchange for the dramatically simpler analysis which
they allow.

In the example, the next instruction which must be assigned a state
machine is \verb|D: je F|, as that preceded instruction \verb|F| in
the captured trace.  It is followed by instruction \verb|F|, which
already has a state machine, and \verb|E|, which does not, and
\verb|E| is followed by \verb|F|.  The CFG therefore contains just
three nodes, representing \verb|D|, \verb|E|, and \verb|F|, with edges
from \verb|D| to \verb|E| and \verb|F| and one from \verb|E| to
\verb|F|.  We then proceed to derive a state machine for \verb|E|,
which is a simple store to a stack location.  Assuming that this store
was ever executed in the captured execution, the stack resolution
heuristic will predict that the load at \verb|F| will load the stored
value.  The load will therefore be eliminated, and so the state
machine for instruction \verb|E| will be

\begin{verbatim}
if BadAddr (load(fallback@G)+48)
 then crash
 else no-crash
\end{verbatim}

It is now possible to combine the machines for \verb|E| and \verb|F|
to produce one for \verb|D|.  This is illustrated in figure
\ref{fig:state_machines_instr_d}.  Backtracking further to instruction
\verb|A| will then produce the state machine illustrated in figure
\ref{fig:state_machines_instr_a}.

\begin{figure*}
\subfigure[Instruction D]{\includegraphics[scale=0.35,trim=0 60mm 0 40mm]{diagrams/statementD.pdf}
  \label{fig:state_machines_instr_d}}
\subfigure[Instruction A]{\includegraphics[scale=0.35,trim=0 60mm 0 40mm]{diagrams/statementA.pdf}
  \label{fig:state_machines_instr_a}}
\caption{State machines produced for the example program}
\end{figure*}

Note that identical state machines would have been derived if the
program had not taken the branch immediately before crashing (which
might happen if the \verb|fallback| structure was itself invalid); the
only difference is that \verb|E|'s state machine will be derived from
the captured execution rather than a hypothetical execution generated
by static analysis.  This is useful: by eliminating uninteresting
aspects of the observed behavior, SLI is able to generalize from one
crash to closely related ones, and hence fix them at the same time,
without eliminating an excessive number of safe schedules.  This
example also illustrates that the stack resolution heuristic is not
equivalent to assuming a completely static data flow graph, as it is
interleaved with control flow discovery and hence respects simple
control-flow dependencies.  Separating the two processes into
independent phases would lose this property, and result in far less
accurate characterizations.\editorial{ref phase order problem?}

\section{Investigating the multi-threaded behavior of the program}
\label{sect:multi_threading}

Once a single-threaded characterization of the bug has been produced,
SLI begins to investigate the crashed thread's interactions with other
threads in the system.  Our basic approach here is to replay the
program's execution and discover points at which the state machine
would have returned \verb|no-crash| if it had executed atomically.
From these, it is possible to infer which parts of the program's
execution should be synchronized against each other, and hence to
suggest potentially useful synchronizations.  In principle, this stage
can run as soon as the first state machine has been derived, but it is
possible to derive a significant performance advantage by grouping
machines into small batches and hence reducing the number of times
which the log file has to be replayed.  As we show in section
\ref{sect:evaluation}, replaying the log file contributes a large
proportion of the entire cost of generating a fix, and so this is a
very worthwhile optimization.

Our implementation of this strategy has several stages.  First, we
determine which memory locations are relevant to the state machines in
the current batch, by replaying the log from the beginning and
evaluating the state machines wherever they are applicable and
recording the memory locations which they load.  The log can then be
replayed again collecting all of the instructions which store to those
locations, along with the values which are stored, and so produce an
additional log containing only stores to the relevant addresses.

Applicability in this context means that the instruction for which the
state machine was derived is sufficiently similar to the current point
in execution that evaluating the machine is likely to produce
meaningful results.  This is complicated by the way in which the state
machines combine both static and dynamic information, and so matching
either the specific dynamic instruction or the static instruction
pointer for which the machine was derived is likely to be inadequate.
Our approach is to consider two points to match if both the
instruction pointer and the call stack match.  This is equivalent to
saying that the instructions match if they would have had the same
instruction pointer had every function on the stack been inlined into
its caller, which reflects our approach of inlining every encountered
function during CFG construction.

Next, the state machines are specialized to particular points in the
log.  This involves replaying the log a third time and, whenever the
state machine is applicable, constructing a new state machine which
has appropriate constants substituted in for the values of registers
and accesses to the local stack\footnote{This may result in the
  construction of duplicate machines, which are eliminated in the
  obvious way.}.  This effectively factors out the effects of
thread-local computation, converting each state machine into a set of
state machines which individually depend only on the content of shared
memory.  State machines which reduce to a constant are discarded at
this stage.

These specialized state machines are then evaluated at each store to a
relevant address, partitioning the log into regions which crash (if
the machine evaluates to \verb|crash| or loads an inaccessible memory
location) or do not crash (if it evaluates to \verb|no-crash|).  The
specialized partitionings are then combined to produce a partitioning
for the original unspecialized state machine: wherever all of the
specialized partitionings make the same prediction, the unspecialized
partition will have the same prediction, and wherever they differ the
unspecialized partition will make no prediction at all.  See section
\ref{sect:final_example} for a situation in which specialization
allows us to derive an additional potential fix, and the discussion of
the \verb|twovar| test case in section \ref{sect:bug_descr} for one in
which the specialized predictions would have produced an incorrect fix
if they had been used without the recombination step.\editorial{Need
  more explanation of why we're doing this.}

\subsection{Generating candidate fixes}
\label{sect:gen_fix}
%% This section references the next one without using LaTeX xrefs; do
%% not move it.

At the end of this stage, we have, for each state machine:

\begin{itemize}
\item A list of all loads which the state machine depends on.
\item A list of all instructions which stored to one of the addresses
  which the machine depended on in the captured execution (i.e. all of
  the instructions which, when interleaved with the state machine,
  might have prevented it from executing atomically).
\item A set of sub-ranges of the execution in which the state machine
  would predict a crash if executed atomically.
\end{itemize}

To fix the bug, it is then sufficient to ensure that the loads in the
first list do not overlap with any of the stores in the second or any
of the ranges in the third.  These lists transform naturally into a
set of critical sections:

\begin{itemize}
\item There is one critical section which covers all of the accesses
  made by the state machine itself.
\item Every region in which a crash is predicted has a critical
  section, starting at the first access in the unsafe region and
  ending at the final access.
\item Every possibly-interfering store is wrapped in a single-access
  critical section, if it is not already contained in one of the
  unsafe regions.
\end{itemize}

The task is then to ensure that the first type of critical section
cannot overlap with any of the second or third types.  In our current
implementation, this is done by introducing a new global lock which is
acquired before the first instruction of any of these critical
sections and then released after the last one (see section
\ref{sect:binpatch} for more details).  This is moderately
pessimistic, as it prohibits multiple threads from running sections of
the first type in parallel and prohibits sections of the second and
third type from running in parallel with each other; a more
intelligent implementation could retain greater concurrency at the
expense of slightly greater implementation complexity.

Crashing regions which cross threads cannot be protected in this way.
We re-designate those areas of the log as having an unknown crash
prediction, which causes SLI to give up trying to protect them and to
penalize the resulting fix when selecting which to actually apply; see
the next section for details.

%% Note the non-LaTeX reference from the previous section to the next
%% one!

\subsection{Selecting a fix}
\label{sect:selectfix}

This process might produce multiple possible fixes if multiple state
machines are available, and it is then necessary to select an
appropriate one to instantiate into a binary patch.  Some can be
discarded by very simple heuristics (for instance, fixes in which
every critical section is a single access can be immediately
eliminated), but there will in general be multiple possible fixes to
choose from.  We use a very simple cost heuristic to do so: the cost
of a fix is given by $U.n_u + C_s.n_s + {\sum_{i}}s_i$ where $n_u$ is
the number of points in the log where we are unable to produce a crash
prediction, $n_s$ is the total number of critical sections, $s_i$ is
the number of accesses in the $i$th critical section, and $C_s$ and
$U$ are constants reflecting the cost of introducing a new empty
critical section and of only partially fixing the bug.  SLI then
selects the candidate fix with the lowest cost.  Our prototype sets
$U=1000$ and $C_s=10$, strongly preferring fixes for which all unsafe
states can be eliminated and weakly preferring fixes with a smaller
number of critical sections.

In our evaluation, there are generally only a small number of possible
fixes, all of which are correct and none of which would obviously lead
to pathological performance, and so the exact choice of prioritisation
heuristic does not appear to be critical.

\subsection{Example}
\label{sect:final_example}

Our earlier example derived the state machine shown in figure
\ref{fig:state_machines_instr_a} for the program shown in figure
\ref{fig:broken_privatize}.  The list of relevant addresses for this
state machine will be \verb|global1|, \verb|fallback| and
\verb|variable1|.  Note that the load in instruction \verb|J| is
\emph{not} represented in this list: the value which it loads does not
affect whether or not the program crashes, and so it is not considered
relevant for these purposes.

\begin{table}
\begin{tabular}{ll}
 Store & Specialization predicts \\
       & crash before instruction \\
\verb|V.1 &struct1 -> variable1| & Yes\\
\verb|W.1 &variable1 -> global1| & No\\
\verb|X.1 0 -> global1| & No\\
\verb|Y.1 0 -> variable1| & No\\
\verb|V.2 &struct1 -> variable1| & Yes\\
\verb|W.2 &variable1 -> global1| & No\\
\verb|X.2 0 -> global1| & No\\
\verb|Y.2 0 -> variable1| & No\\
...
\end{tabular}
\caption{Relevant store log for example}
\label{tab:relevant_stores}
\end{table}

Assuming that the only stores to relevant addresses are those shown in
figure \ref{fig:broken_privatize}, the relevant store log will then be
as shown in table \ref{tab:relevant_stores}.  The state machine does
not depend on registers or the thread-local stack, and so
specialization will have no effect, and we proceed directly to
classifying the store log into crashing and non-crashing components.
In this particular case, the state machine will predict that no state
can crash, which is correct: if the loads in the state machine had
executed atomically, with respect to the stores present in the store
log, the program would not have crashed.  This suggests a potential
fix with five critical sections: one covering instructions \verb|A| to
\verb|G| in thread 1, and a single-instruction critical section for
each of instructions \verb|V|, \verb|W|, \verb|X|, and \verb|Y| in
thread 2.  This would fix the bug, and will be suggested by
SLI.\editorial{Not a minimal fix...}

This is not the only fix which will be suggested, however.  State
machine generation will also have produced machines for other
instructions in the crashing thread.  In particular, the machine
produced for instruction \verb|F| will be:

\begin{verbatim}
if BadAddr (load(load(rsp@F)@G)+48)
 then crash
 else no-crash
\end{verbatim}

As this accesses both registers and the stack, it can be specialized,
producing two new machines:

\begin{verbatim}
if BadAddr (load(variable1@G)+48)
 then crash
 else no-crash
\end{verbatim}

and

\begin{verbatim}
if BadAddr (load(fallback@G)+48)
 then crash
 else no-crash
\end{verbatim}

The captured execution shows no writes to \verb|fallback|, and so the
\verb|load| in the second machine is replaced with a constant and the
entire machine is subject to constant folding, producing the trivial
machine \verb|no-crash|.  It is therefore discarded.  The first
machine, however, predicts a crash whenever \verb|variable1| contains
something which is not a valid pointer, which occurs from \verb|Y.1|
to \verb|V.2| in the store log (and subsequently as thread 2 loops).
This suggests an alternative fix with two critical sections: one
single-instruction critical section covering instruction \verb|G| in
thread 1, and a second covering \verb|Y| to \verb|V| in thread 2 (the
second section will wrap around the loop, which somewhat complicates
the implementation of the binary patcher; see section
\ref{sect:binpatch} for our approach to this problem).  This fix will
also be suggested by SLI, and would also fix the bug.  Furthermore,
because it has fewer critical sections, it will be preferred by the
prioritisation heuristic.

It could be argued, however, that this smaller fix is inferior to the
larger alternative, despite completely eliminating the crash and
potentially imposing lower overhead, as it is less ``sympathetic'' to
the existing structure of the program.  The author of thread 2 had
presumably intended to privatize the structure at instruction
\verb|X|, and so might reasonably have defined a ``correct'' fix to be
one which ensures correct privatization, a goal which is achieved by
the first fix but not by the second.  SLI, by contrast, has no notion
of intended behavior, or indeed any form of good software engineering
practice, and so selects its fix based on the more mundane concerns of
avoiding the crash and minimizing the impact on performance.  This is
both a strength and a weakness: a strength in that it increases the
likelihood that a low-overhead fix will be found, and a weakness in
that the fixes cannot be translated back to source-level patches and
applied unthinkingly by the application programmer.

Producing a long-term, maintainable fix for a bug is, in general, a
different problem to producing a short-term one which simply
eliminates its symptoms, and the techniques used by SLI are much more
applicable to the latter.  This will be true of any approach which
does not rely on programmer annotations (ignoring trivial systems
which just pattern-match the buggy code against a library of common
bugs and their standard fixes); the extra flexibility gained by being
applicable to arbitrary binaries makes this a reasonable trade-off.

\subsection{Creating a binary patch}
\label{sect:binpatch}

Once an appropriate set of critical sections has been discovered, they
must be instantiated into a binary patch to produce an actual fix.  We
simplify the problem by detecting if the start and end of a critical
section are in different functions (as delimited by \verb|call| and
\verb|ret| instructions) and, if they are, backtracking up the call
stack to their most recent common stack frame.  Besides simplifying
the binary patching problem, this has the (sometimes) useful
side-effect of expanding the critical section, and generally moving it
to boundaries which are more likely to correspond to the original
programmers' ideas about where critical section boundaries ``should
be''\editorial{Rephrase}.

Once we have obtained start and end points in the same function frame,
we again examine the program's control flow graph, starting at the
first instruction in the critical section.  This time, however, we do
not break cycles, or make any unsafe approximations, so that the CFG
precisely captures the program's behavior over the instructions where
it is valid; indirect branches are replaced with special stub nodes
which branch back to the original program text.  The CFG thus obtained
is then trimmed to only contain paths starting at the first
instruction in the critical section and ending at the last one.  For
example, the second potential fix discussed in section
\ref{sect:final_example} requires a critical section from instructions
\verb|Y| to \verb|V|.  The CFG obtained in this case will contain
nodes for \verb|Y|, \verb|Z|, and \verb|V|, linearly in that order,
followed by a stub node which branches back \verb|W| in the original
program.  It is then straightforward to place a lock-acquire
instruction immediately before the first node in the CFG and a
lock-release one immediately before every stub node, which guarantees
that the lock will be released precisely once for every time which it
is acquired.  The CFG can then be recompiled into a fragment of
position-independent machine code which is combined with a stub loader
and built into an ELF shared library.  This can be loaded into the
target program using \verb|LD_PRELOAD| (or an equivalent mechanism).
The stub loader is then responsible for actually applying the patch to
the program, either by patching a jump into the entrypoint instruction
or using the processor's debug facilities.

\section{Semantic knowledge}
\label{sect:semanticknowledge}
SLI needs only very limited semantic knowledge of the intended
behavior of the program.  In the default configuration, the only
assumptions made about the program are that calling
\verb|__assert_fail| or exiting due to an unhandled signal always
indicates a bug.  If the use-after-free analysis mentioned in section
\ref{sect:prox_cause} is used then we also assume that the program
will never deliberately use memory after passing it to the \verb|free|
function.  There exist programs for which some or all of these
assumptions will be false, but they appear to be reasonably rare, and
so these assumptions should not significantly limit the approach's
applicability.  The current implementation provides some facilities
for programmers to extend this knowledge with additional assumptions,
such as flagging functions other than \verb|__assert_fail| as
indicating bugs or applying other dynamic analyses when deriving the
proximal cause.  We intend to expand these further in
future.\editorial{Wording doesn't really work very well.}

\section{Deadlocks}
\label{sect:deadlocks}

There is a risk that introducing additional synchronisation into the
program will itself introduce a deadlock.  We mitigate the issue
slightly by using a timeout on our introduced locks, so that deadlocks
at least resolve themselves in bounded time, but this can lead to poor
performance or incomplete fixing of bugs.  This could be avoided in
some cases by performing additional static analysis to select critical
sections which are less likely to lead to deadlocks, at the expense of
potentially not being able to find any safe fix at all.

Another possible approach would be to integrate with a deadlock
immunity system such as Dimmunix\cite{Jula2008}, detecting and fixing
deadlocks as they happen.  The system would then hopefully eventually
converge on a state which is both deadlock and race free.  It should
also be possible to simulate the effect which SLI lock insertion would
have on Dimmunix lock order graph, and hence to determine that
Dimmunix ultimately would insert a healing lock before it needs to do
so, eliminating the need to reproduce the deadlock before fixing it.
Of course, the Dimmunix graph is itself only an approximation, and so
this would not be guaranteed to be effective in every case, but it
seems likely that it would be sufficient in most situations.

We have not implemented this in our current prototype.

\section{Evaluation}
\label{sect:evaluation}

\begin{table*}
\begin{tabular}{lllllll}
Name of test & Nature & Number & Time taken & Size of & Number of & Total number of state\\
 & & of fixes & (seconds) & logfile & state machines & machine states\\
\hline
toctou & Synthetic simple & 1 & $1.18 \pm 0.02$ & 28MiB & 8 & 20\\
       & TOCTOU & & & \\
twovar & Synthetic two-variable & 2 & $1.89 \pm 0.03$ & 31MiB & 8 & 22\\
       & atomicity violation &&&\\
publish & Synthetic broken & 2 & $1.15 \pm 0.02$ & 31MiB & 5 & 16 \\
        & publish pattern & & & \\
privatize & Synthetic broken & 2 & $5.11 \pm 0.05$ & 43MiB & 5 & 16 \\
          & privatize pattern & & & \\
\hline
glibc & Kernel of a genuine & 6 & $8.15 \pm 0.03$ & 48MiB & 10 & 52\\
      & atomicity violation & & & \\
\hline
thunderbird & Genuine TOCTOU & 1 & $4740 \pm 6$ & 758MiB & 6 & 14
\end{tabular}
\caption{Summary of results obtained from running the fix generating
  tool on a single log file collected from each bug.  Timing
  information is mean and standard deviation from five runs.}
\label{tab:perf_summary}
\end{table*}

As shown in table \ref{tab:perf_summary}, our prototype implementation
is able to fix a reasonable selection of artificial bugs within a few
seconds, given only the program binary and a log of the bug
reproducing, and is able to fix at least one real-world bug within an
hour and a half.  This data also shows that the prototype avoids state
machine explosion, generating only a small number of distinct state
machines, each of which has only a small number of states (a little
over three on average, and in no case more than fourteen).
Furthermore, this time is dominated by the time spent replaying the
collected log files (especially for the most realistic bug,
\verb|thunderbird|), suggesting that improvements to our presently
very na\"ive replay engine would yield significant overall performance
gains.

\begin{figure*}
\subfigure[Length of the phases, as fractions of the entire
  fix-generating process.]{ \includegraphics[trim=8mm 0 20mm
    0]{timing/timings.pdf}
  \label{fig:phasedistribution}
}\hspace{10mm} \subfigure[Absolute length of the phases, ignoring time
  spent in the replay engine.]{ \includegraphics[trim=8mm 0 10mm
    0]{timing/without_replay.pdf}
  \label{fig:timesignoringreplay}
}
\caption{Breakdown of time spent in various phases of the analysis
  process.  Results presented are mean and standard deviation of five
  runs of the fix-generating program applied to a single log file for
  each bug.  Experiments were conducted on an Intel Q6600 with 8GiB of
  RAM running 64-bit Linux 2.6.28, and the minimal amount of semantic
  knowledge was used (see section \ref{sect:semanticknowledge}).}
\end{figure*}

Figure \ref{fig:phasedistribution} shows how the time taken is
distributed between the phases of the fix generation process.  Two
main observations can be drawn from the figure.  First, constructing
the state machines is very quick for all of these tests, and is barely
visible in the graph.  This is reassuring, and suggests that the
algorithm is able to discard parts of the program's execution which
are not relevant to the observed crash quickly, so should be able to
scale up to more complicated bugs in a reasonably straightforward
way\editorial{Not sure I believe that}.  Second, for the very
long-running \verb|thunderbird| test the runtime is completely
dominated by the phases which involve replaying the log.  This is
unsurprising, as it has by far the largest logfile, reflecting the
greater complexity of the buggy program.

Figure \ref{fig:timesignoringreplay} shows how much time is taken by
the various phases ignoring the time taken to replay the log file.
One interesting observation on this graph is that \verb|thunderbird|
spends by far the least time generating fixes (0.2$\mu{}$s versus
hundreds of milliseconds to a few seconds for the other tests),
despite taking by far the most time overall (an hour and a half versus
less than ten seconds).  This is because in the \verb|thunderbird|
test the buggy code is run only once whereas the other tests run the
buggy code in a tight loop until it crashes, and so the logs contain
many instances of both the critical code and stores to the relevant
memory locations.  The state machines must therefore by evaluated in
many more contexts in the artificial bugs, which dramatically
increases the time taken by the analysis.  This is an encouraging
result: most bugs occur in code which is executed infrequently, and so
it would be reasonable to expect that most bugs would have analysis
time more similar to the \verb|thunderbird| bug than to the artificial
ones.

We also investigate how the analysis depends on the exact details of
the way in which a particular bug is reproduced, by running our tool
on five independent reproductions of the \verb|glibc| bug.  Every
reproduction produced the same set of state machines and suggested
fixes.  The time taken by the analysis process varied significantly,
however (from eight to thirteen seconds), mostly because the time
taken to reproduce the bug varied and so the size of the log which had
to be parsed also varied.  A similar pattern was observed of the other
bugs; we omit the full results due to space constraints\editorial{Not
  sure this is all that interesting, or that I've phrased it very
  well...}.

\subsection{Description of test bugs}
\label{sect:bug_descr}

We now describe our test bugs in more detail.

\verb|toctou|, a simple two-thread time-of-check, time-of-use race.
In this test, one thread loops incrementing a counter, while another
thread repeatedly issues pairs of loads of the counter and asserts
that the loads returned the same value.  Our prototype generates a
single suggested fix consisting of two critical sections.  One of
these sections protects the write-back of the incremented counter in
the first thread, while the other protects the two loads in the second
thread.  This is a correct and minimal fix.

\verb|twovar|, a two-variable atomicity violation.  In this test,
there are two global variables, and one thread loops setting both to
five and then setting both to seven while another thread loops loading
both and asserting them to be equal.  SLI produces a single suggested
fixes in this case.  The fix contains five critical sections, one
protecting the two loads in the second thread and four singleton
instructions each of which protects a single store in the other
thread.  This correctly eliminates the bug.

This test illustrates the effect of state machine specialization.  For
the instructions between the two loads, the initial single-threaded
state machine generation process will produce a state machine similar
to this:

\begin{verbatim}
if rax != load(global2@l2)
 then crash
 else no-crash
\end{verbatim}

Where \verb|l2| is the load of the second global variable.  This
will specialize in two ways:

\begin{verbatim}
if 5 != load(global2@l2)
 then crash
 else no-crash
\end{verbatim}

and

\begin{verbatim}
if 7 != load(global2@l2)
 then crash
 else no-crash
\end{verbatim}

There are no points in the program's execution at which both machines
will predict \verb|no-crash|, and so the original unspecialized
machine is discarded as uninteresting.  If the specialized predictions
had not been recombined they would have predicted that the relevant
instruction is safe if \verb|global2| is, respectively, \verb|5| or
\verb|7|, and hence produced suggested fixes which synchronized the
load at \verb|l2| against the stores to \verb|global2| independently
of any accesses to \verb|global1|.  Neither of these fixes would be
sufficient to fix the bug, and combining them directly would have
meant that \verb|l2| could not occur at any point in the program's
execution, so the second thread would not be able to make any progress
at all.

\verb|publish|, a broken implementation of the publish pattern.  In
this pattern, a structure is initialised by one thread and then
published by writing its address into a global pointer.  Other threads
then occasionally read this global pointer and, if it contains a
non-\verb|NULL| pointer, use the referenced object.\editorial{I'm
  convinced that this is a standard pattern, and that I didn't invent
  the term, but I can't find a reference.}  This is safe if correctly
implemented, but in this test the programmer published the structure
before finishing constructing it, which leads to the other thread
eventually crashing.  The test case consists of two threads, one of
which repeatedly publishes and un-publishes a structure and the other
of which repeatedly tests whether it has been published and, if it
has, attempts to use it in a way which leads to an immediate crash if
initialisation is not complete.

Our tool produced two suggested fixes in this case.  One of these was
expected, consisting of two critical sections, one of which spanning
the consuming thread from the point at which it loaded the pointer to
the point at which it used its contents while the other spanned the
actions of the producing thread from the point at which it published
the structure to the point at which it finished initializing it.  This
is a correct fix.

The other suggestion was an artifact of our test harness, which
repeatedly published, initialised, unpublished, and then deinitialised
the same structure.  SLI was able to look through this pattern, and
determined that it was sufficient to prevent the consuming thread from
validating the published structure at any point between the
deinitialisation in one iteration and the initialisation in the
subsequent one.  It therefore suggested a fix which protected the load
which the consuming thread used to perform validation in one critical
section and the range of the publishing thread from the
deinitialisation to the subsequent initialisation in another,
completely ignoring the accesses related to publishing and
unpublishing the structure.  While somewhat surprising, this is also a
correct fix, completely preventing the observed bug, and, as it
produces slightly smaller critical sections, would be preferred by the
fix prioritisation heuristic.\smh{good example of a bad fix which is
  actually good.}\editorial{ref earlier discussion of privatize
  example?}

\verb|privatize|.  This is the converse of \verb|publish|: a thread is
attempting to make a structure private, and does it incorrectly.  It
is similar to the example program in figure
\ref{fig:broken_privatize}, which has already been extensively
discussed.

\verb|glibc| This is a kernel of glibc bug 2644 \cite{glibc2644},
which affected versions of glibc up to 2.5 and could lead to a crash
if multiple threads were shut down at the same time.  Somewhat
simplified, the code looked like this:

\begin{verbatim}
_Unwind_ForcedUnwind() {
    if (libgcc_s_forcedunwind == NULL)
        pthread_cancel_init();
    libgcc_s_forcedunwind();
}
pthread_cancel_init() {
    if (done_init) return;
    libgcc_s_forcedunwind = _forcedunwind_impl;
    done_init = 1;
}
\end{verbatim}

Where \verb|libgcc_s_forcedunwind| and \verb|done_init| are global
variables.  The compiler's optimizer transformed this such that the
code actually executed corresponded to\footnote{Unfortunately, only
  the 32-bit x86 version of gcc optimizes the function like this, and
  our implementation of SLI assumes a 64-bit x86 program, and this
  prevented us from testing with the real bug.}:

\begin{verbatim}
  _Unwind_ForcedUnwind() {
1:  l = libgcc_s_forcedunwind;
2:  if (l == NULL &&
3:      done_init) {
4:    libgcc_s_forcedunwind = l =
        _forcedunwind_impl;
5:    done_init = 1;
7:  }
8:  l();
  }
\end{verbatim}

Our test is then to have two threads loop executing this:

\begin{verbatim}
    while (1) {
10:     pthread_barrier_wait();
11:     _Unwind_ForcedUnwind();
12:     pthread_barrier_wait();
13:     done_init = 0;
14:     libgcc_s_forcedunwind = NULL;
    }
\end{verbatim}

SLI produced six suggested fixes when run on a log generated by
running this test.  The first of these had five critical sections: one
covering the load on line \verb|1| to the load of \verb|done_init| on
line \verb|3|, and one each for each of the stores on lines \verb|4|,
\verb|5|, \verb|13|, and \verb|14|.  The other suggestions were
supersets of this suggestion, extending it to include various accesses
in \verb|pthread_barrier_wait|.

This illustrates an important weakness of the approach.  First,
because our implementation of SLI does not know anything about any
operating system-provided functionality, it cannot take advantage of
any existing synchronization present in the program (in this case, the
\verb|pthread_barrier_wait|s make the critical sections protecting
statements \verb|13| and \verb|14| redundant).  It also means that the
analysis must explore these standard functions, and can sometimes
attempt to ``fix'' the benign races inherent in synchronization
operations, which is unlikely to be productive.

\verb|thunderbird| is Mozilla bug number
391259\cite{thunderbird39125}, a simple time-of-check, time-of-use
race in the IMAP client component of Thunderbird, a popular
open-source e-mail client.  We modified Thunderbird to include some
additional debugging messages and used a custom scheduler in order to
make the bug reproduce more readily; the test is otherwise identical
to the behavior which a user might have encountered.  The relevant
parts of the program are as follows:

\begin{verbatim}
void nsImapProtocol::CloseStreams() {
  if (m_transport) {
      m_transport->Close(NS_ERROR_ABORT);
      m_transport = nsnull;
  }
}
\end{verbatim}

\begin{verbatim}
PRBool nsImapProtocol::ProcessCurrentURL() {
  if (m_transport)
    m_transport->SetTimeout(
      TIMEOUT_READ_WRITE, PR_UINT32_MAX);
}
\end{verbatim}

If \verb|m_transport| is set to \verb|nsnull| by \verb|CloseStreams()|
in between the two accesses in \verb|ProcessCurrentURL| then the
program will crash.  This is essentially the same bug as
\verb|toctou|, but embedded in a much large program.  As such, the
final result is similar: a single suggested fix, with two critical
sections, one containing the two accesses in \verb|ProcessCurrentURL|
and one containing the assignment in \verb|CloseStreams|.  However,
the process of generating a fix takes much longer: nearly eighty
minutes, rather than a few seconds.  The vast bulk (more than 99\%) of
this time is spent in the replay engine, reflecting the greater
complexity of the target program and the fact that the bug simply took
longer to reproduce, both of which lead to much larger log files.
Note also that the log in this case starts at a snapshot of the
program's state taken after it had completed initialisation, whereas
the other test cases start at the very first instruction in the
program; without this, the disparity would be even larger.

\subsection{Effects of backtracking further}
\label{sect:eval:backtrack}

\begin{figure}
\includegraphics{clog/clog.pdf}
\caption{Time taken by the analysis phases of the thunderbird bug, in
  seconds, versus the level of backtracking applied to the crashed
  thread, in dynamic branches.  Mean and standard deviation of three
  runs.}
\label{fig:eval:backtrack}
\end{figure}

One important parameter to the system is how far to backtrack through
the crashed thread.  For implementation reasons, our prototype will
always backtrack to a branch instruction, and for the above tests we
limited this backtracking to ten branches.  Figure
\ref{fig:eval:backtrack} shows the effect of changing this parameter
upon the time taken by the non-replay components of the
\verb|thunderbird| test (the replay parts were unchanged).  It can be
seen that the time taken increases rapidly as the distance which we
backtrack increases, by a factor of more than 500 when going from a
single level of backtracking to fifty levels.  Note, however, that the
total time taken by the non-replay analysis is, even with a
backtracking depth of 50, still just 620ms, or 0.013\% of the total
time taken.  None of our tests depend on more than three levels of
backtracking to produce a correct fix (and the \verb|thunderbird| test
requires just one), and so this suggests that SLI should be able to
backtrack sufficiently to solve most bugs in a reasonable amount of
time.

\section{Related work}\editorial{This is a bit of a bestiary.  Could do with a bit more analysis.}

There have been a number of previous systems which tackle similar
problems.  Most recently, Kivati\cite{Chew2010a} attempts to fix
single-variable atomicity violations automatically by combining a
static analysis pass with some runtime support.  The result is able to
prevent many common kinds of race-like bugs with low overhead.  There
are several important differences between their approach and ours:

\begin{itemize}
\item SLI is only activated once a bug has been observed, whereas
  Kivati runs at all times.  This means that it is more likely to
  ``fix'' perfectly benign races.  It also means that the fixes cannot
  easily be applied without also requiring the Kivati runtime,
  whereas, once generated, SLI fixes can stand alone without any of
  the rest of the SLI infrastructure, which may sometimes improve
  performance.
\item Kivati requires access to the program's source code during the
  initial static analysis phase, whereas SLI only requires the binary.
\item SLI can be applied to a wider class of bugs than Kivati, such as
  the \verb|twovar| example described above.
\end{itemize}

Another approach, taken by systems such as
Isolator\cite{Ramalingam2009} and ToleRace\cite{Kirovski2007},
restricts the problem domain to asymmetric races, where one thread is
correctly following a locking discipline while some other thread is
not, and seeks to ensure that the correct thread continues to be
correct despite the misbehavior of the incorrect one.  This might,
for instance, be useful if the correct thread is controlled by an
application while the incorrect one is controlled by a library which
the application writer is unable to modify.  As with Kivati, they do
not target specific bugs.

Atom-Aid\cite{Lucia2009} is another approach to race bug
mitigation, in this case using hardware transactional memory support.
Their approach is to bundle sequences of memory accesses into
transactions according to some heuristics, effectively reducing the
number of permissible schedules and hence the scope for memory
ordering related bugs.  Provided the necessary hardware is available,
this is simple and reasonably efficient, and should also eliminate a
reasonable selection of non-trivial bugs.  The main downside of this
approach is that it requires non-standard (and presently non-existent)
hardware, which makes it less practically useful than it otherwise
would be.

There have also been a number of attempts to automatically fix heap
management bugs, such as buffer overflows and use-after-free errors,
including AutoPaG\cite{Lin2007} and Exterminator\cite{Novark2007}.
These systems both take an example of a buffer overflow bug (assumed
to be deterministic) and use various analyses to determine the root
cause of the bug, eventually using this to produce a potential fix.
In that, they are remarkably similar to the system currently under
discussion; the main difference being the type of bug targeted.

All of these systems attempt to fix bugs or otherwise prevent them
from happening.  An alternative strategy is to make errors less
serious when they do happen.  The most famous example of such a
strategy is probably failure obliviousness\cite{Rinard2004}, which
waits until the protected program makes an invalid memory reference
and then attempts to fix it from the resulting exception handler.
DieHard\cite{Berger2006} is conceptually similar, but works
pre-emptively rather than from a fault handler, by guessing where
memory errors are likely to occur and modifying the program's memory
map to make those errors as harmless as possible.  In this way
programs are able to continue executing in spite of the presence of
errors which would otherwise cripple them.  Failure obliviousness
cannot, however, completely remove any errors, and so can be seen as
complementary to those discussed here.

RX\cite{Qin2007} takes a third strategy.  Here, rather than
attempting to fix the bug, an attempt is made to determine which
subset of a program's functionality is bug-free, and then to restrict
the program's inputs to only exercise that functionality.  The result
is that inputs which might have triggered the bug continue to produce
incorrect output, but the damage is at least contained rather than
propagating throughout the program and potentially leading to a crash.
This is arguably safe, although not according to the definition used
in this paper, and can cover a wide variety of bugs with little
overhead.

\section{Future work}

There are a number of potential extensions of this work, beyond the
obvious ones of broadening the evaluation and improving performance.
At a high level, SLI must balance the use of static analysis, which
considers many possible executions and produces general fixes, and
dynamic analysis, which considers only the observed execution and
produces much more targeted fixes.  We do not claim to have found the
optimal combination of these two approaches, or even that a global
optimum exists; better characterizing the trade-offs involved is
likely to suggest useful improvements.

There is a similar balance to be struck between attempting to be
completely generic and using semantic knowledge, both of the program
and of its libraries.  At present, we make very little use of this
information, and so our implementation is generic across a wide range
of applications but struggles with more complicated bugs.  Carefully
incorporating more semantic information, and providing a generic way
for programmers to introduce their own semantic models, might improve
our ability to produce useful, performant fixes.  One particularly
intriguing approach would be to combine SLI with an invariant
inference scheme such as Daikon\cite{Ernst2007} or
DIDUCE\cite{Hangal2002}, which would allow us to obtain such semantic
information without compromising SLI's current ability to run on
almost arbitrary unmodified binaries.  We intend to investigate this
idea more fully in the future.

\section{Conclusions}

We have presented SLI, a system for automatically fixing specific
synchronisation bugs in shared-memory programs using only their
binaries, with minimal user intervention.  We have demonstrated that
it can be used to fix real-world bugs in at least some cases, and
discussed the compromises and trade-offs which are necessary in order
to produce a practically useful implementation.  While these
techniques do have a number of limitations and drawbacks, we feel that
they provide a useful basis for ongoing work to extend the set of
situations in which they are applicable.\editorial{Wibble wibble
  wibble}

\bibliographystyle{eurosys}

\bibliography{library}

\end{document}

