\documentclass[10pt,letter,twocolumn]{sigplanconf}
\setlength{\textheight}{9in}
\setlength{\textwidth}{6.5in}
\setlength{\headheight}{0in}
\setlength{\headsep}{0in}
\setlength{\topskip}{0in}
\usepackage{verbatim}
\usepackage{color}
\usepackage{graphicx}
%\bibpunct{[}{]}{,}{a}{}{;}

\usepackage{amsmath}
\usepackage{subfigure}

%\newcommand{\editorial}[1]{\textcolor{red}{\footnote{\textcolor{red}{#1}}}}
\newcommand{\editorial}[1]{}
\newcommand{\needCite}{\editorial{need cite}}
\newcommand{\smh}[1]{\editorial{SMH says: #1}}

\newbox\subfigbox             % Create a box to hold the subfigure.
\makeatletter
  \newenvironment{subfloat}% % Create the new environment.
    {\def\caption##1{\gdef\subcapsave{\relax##1}}%
     \let\subcapsave=\@empty % Save the subcaption text.
     \let\sf@oldlabel=\label
     \def\label##1{\xdef\sublabsave{\noexpand\label{##1}}}%
     \let\sublabsave\relax    % Save the label key.
     \setbox\subfigbox\hbox
       \bgroup}%              % Open the box...
      {\egroup                % ... close the box and call \subfigure.
     \let\label=\sf@oldlabel
     \subfigure[\subcapsave]{\box\subfigbox}}%
\makeatother

\begin{document}

\conferenceinfo{SOSP 2011}{date, City.} 
%\copyrightyear{2011} 
%\copyrightdata{[to be supplied]} 

\titlebanner{Submitted to SOSP 2011}        % These are ignored unless
%\preprintfooter{short description of paper}   % 'preprint' option specified.

\title{Speculative Lock Insertion}
%\subtitle{Subtitle Text, if any}

% For double-blind reviewing:
\authorinfo{}{}{}
%\authorinfo{Name1}
%           {Affiliation1}
%           {Email1}
%\authorinfo{Name2\and Name3}
%           {Affiliation2/3}
%           {Email2/3}

\maketitle

\begin{abstract}

The recent move to multicore hardware means that synchronization bugs
(e.g.\ race conditions, atomicity violations) will become increasingly
common.  In this paper, we introduce Speculative Lock Insertion (SLI),
a new technique which can automatically fix some of these kinds of
bugs in program binaries. SLI starts with a reproduction of the bug,
uses a combination of static and dynamic analysis to characterize it,
and finally generates and applies a binary patch which fixes the
bug. We demonstrate the technique's effectiveness using both real and
artificial bugs, and discuss some of the implementation challenges and
limitations.

\end{abstract}

%% \category{D.2.5}{Testing and Debugging}{Debugging aids}

%% \terms
%% Reliability

%% \keywords
%% Synchronization, automated bug-fixing

\section{Introduction}

The increasing availability of multi-core and multi-processor systems
is driving a trend towards software with a greater degree of
parallelism, but, while potentially paying dividends in improved
responsiveness, throughput, and power consumption, multi-threaded
programming has an unfortunate tendency to lead to very subtle bugs.
Even worse, it is often difficult to trigger these bugs reliably,
which means that they are less likely to be discovered by testing and
harder to fix once they have been discovered.  A number of techniques
have been proposed for reducing the likelihood of such errors,
including transactional memory\cite{Shavit1997} and automatic
parallelization\cite{Bacon1994}, but these cannot be transparently
applied to the large body of existing concurrent software.  There is
therefore a need for techniques which can assist in fixing bugs in
programs written using the currently widely-used shared memory model
of concurrency.  In this paper, we introduce SLI, or Speculative Lock
Insertion, as one potential approach to this problem.  SLI
automatically fixes observed synchronization bugs, given only the
program binary and a reproduction of the bug, generating a modified
binary whose behavior is identical to that of the original except that
it no longer suffers from the bug.  Furthermore, the fixes will
usually have very low performance overhead, and the process of
generating the fix itself takes only a moderate amount of time
(ranging from seconds in simple cases to a few minutes in more
complicated ones).  SLI does not depend on programmer annotations or
semantic knowledge of the program's intended behavior; it does
however, depend on having observed the bug, and on having captured it
in a deterministic replay system (DRS).

SLI does not attempt to fix every possible synchronization bug.
Instead, we consider bugs caused by one thread reading an in-memory
structure while some other thread is on the process of updating it and
an unfortunate interleaving causes the reading thread to crash.  There
are several key challenges here:

\begin{itemize}
\item Extracting a higher level abstract ``read operation'' from the
  crashing thread.  This consists of the memory loads which are
  relevant to the observed crash, plus the minimal amount of local
  computation required to tie them together (address computations, for
  instance).

\item Identifying memory regions which constitute a structure.  This
  might, for instance, be the first three entries in a linked list, or
  all of the nodes on a particular path through a
  DAG.

\item Determining which stores issued by other threads might have
  raced with the read operation in a dangerous way.

\item Embodying the information obtained as a fix which can be applied
  directly to the program binary.
\end{itemize}

The first challenge is key; given a characterisation of the read
operation and a DRS log, the other three are straightforward.  We
represent these abstract operations using state machines derived using
a combination of static analysis, applied to the program text, and
dynamic analysis, applied to the DRS log.  These state machines
characterise and approximate the parts of the crashing thread's
behaviour which are most relevant to the observed crash, allowing SLI
to extract the useful information from the vast sea of superfluous
detail provided by the DRS, and hence to proceed to a useful fix.

\section{Capturing the bug}

Before SLI starts, the bug to be fixed must first be captured using a
deterministic replay system.  This work does not attempt to advance
the state of the art in DRSes, but does depend on them in order to be
feasible, and so we discuss them briefly here.  The only requirement
we place on the choice of DRS is that it must allow us to replay the
relevant fragment of execution as many times as necessary and produce
the same sequence of memory accesses each time.  This captured
execution does not need to be precisely the same as the original
crashing execution (although excessive imprecision here could lead to
SLI fixing the wrong bug).  The most obvious way of capturing an
execution, used in our prototype, is to simply record every single
memory access issued by the program, which is effective but has
extremely high overhead.  This could be reduced by using a more
intelligent recording mechanism such as PRES\cite{Park2009} or
ODR\cite{Altekar2009}, both of which record only a few critical events
and discover the rest only when they are needed during replay.  This
can reduce overhead to a level where it is sensible to run with
recording enabled by default.  ESD\cite{Zamfir2010} is an extreme form
of this approach, and logs nothing at all but instead attempts to
recreate the path to failure given just the state of the program at
the time of the crash.  In a slightly different context, an automatic
program exerciser such as CHESS\cite{Musuvathi2008} could be used to
detect unknown bugs, which could then be passed to SLI to be
automatically characterized and fixed.\editorial{I want to use the
  phrase closed-loop here}

\section{Building abstract read operations}
\label{sect:build_state_machines}

The first phase of our algorithm is to identify the abstract read
operation which the program was performing when it crashed.  This is
represented by a series of state machines, each corresponding to and
approximating a fragment of the program starting at some instruction
executed by the crashing thread and ending at the point of the crash.
The state machine can be evaluated when one of the program's threads
executes the starting instruction and predicts, given the state of
memory and the thread's registers, whether the thread would crash if
it were executed in isolation starting from that state.  In that
sense, the state machine captures the part of the crashing thread's
behavior which is most relevant to the bug which is to be fixed.

The state machines can be regarded as small programs in a very simple
graphical language, and the process of producing them as a kind of
compilation.  The language has two basic components, states and
directed edges.  States can be either internal, in which case they
have two outgoing edges and a predicate which controls which is taken
in any given evaluation, or terminal, in which case they have no
outgoing edges and are labelled with either \verb|crash| or
\verb|No crash|.  Edges link states, and are labelled with a list of
store operations.  The predicates for internal states, and the address
and value of store operations, are represented in a simple expression
language which has forms for examining registers, such as \verb|rax|
or \verb|rsp|, and for examining values loaded from memory.  It also
has the usual operators from C-like languages, like \verb|+| and
\verb|==|, which have the standard semantics, and a few simple
functions such as \verb|BadAddr| (which tests whether a pointer can be
safely dereferenced) and \verb|CondEq| (which takes an x86
\verb|eflags| condition code word and checks whether the Z flag is
set, indicating that the values compared were equal).

Figure~\ref{fig:state_machines:a} shows the state machine generated
for instruction \verb|A| in Figure~\ref{fig:broken_privatize}, and
illustrates most of the important points of the scheme.  Starting from
the top of the diagram, the state machine issues the store
\verb|load(global1@A) -> (rsp)|, which corresponds to instruction
\verb|B| and indicates that the value loaded from \verb|global1| at
instruction \verb|A| is stored in the memory location pointed at by
register \verb|rsp|.  The state machine then evaluates
\verb|load(global1@A) == 0| and goes left if the value is false
(corresponding to the branch at instruction \verb|D| being taken) or
right if it is true (corresponding to the branch at \verb|D| not being
taken).  In either case, it performs one final test on the contents of
memory, with the result determining whether or not the program
crashes.  The remainder of this section details our algorithm for
producing these state machines automatically.

\begin{figure*}
 \begin{subfloat}
  \begin{minipage}{80mm}
\begin{verbatim}
A: mov (global1) -> %rax
B: mov %rax -> (%rsp)
C: cmp $0, %rax
D: jne F
E: mov &fallback -> (%rsp)
F: mov (%rsp) -> %rcx
G: mov (%rcx) -> %rdx
H: add $48, %rdx
J: mov (%rdx) -> %rax
K: ret
\end{verbatim}
  \end{minipage}
  \caption{Thread 1}
 \end{subfloat}
 \begin{subfloat}
  \begin{minipage}{80mm}
\begin{verbatim}
V: mov &struct1 -> (variable1)
W: mov &variable1 -> (global1)
...
X: mov $0 -> (global1)
Y: mov $0 -> (variable1)
...
Z: jmp V



\end{verbatim}
  \end{minipage}
  \caption{Thread 2}
 \end{subfloat}
 \caption{A buggy example of the privatize synchronization pattern.
   The author of thread 2 intended variable1 to be private after X,
   and so de-initialized it at Y, but thread 1 caches a pointer to it
   in a register at A which prevents it from being properly
   privatized.  This leads to a bug: if A happens before X and Y
   happens before G, rdx will contain a bad pointer at instruction J,
   leading to an immediate crash.}
 \label{fig:broken_privatize}
\end{figure*}

\begin{figure*}[t]
\subfigure[Instruction A]{\includegraphics[scale=0.29]{diagrams/statementA.pdf}
  \label{fig:state_machines:a}}
\subfigure[Instruction B]{\includegraphics[scale=0.29]{diagrams/statementB.pdf}
  \label{fig:state_machines:b}}
\subfigure[Instruction C]{\includegraphics[scale=0.29]{diagrams/statementC.pdf}
  \label{fig:state_machines:c}}
\subfigure[Instruction D]{\includegraphics[scale=0.29]{diagrams/statementD.pdf}
  \label{fig:state_machines:d}}
\subfigure[Instruction E]{\includegraphics[scale=0.3]{diagrams/statementE.pdf}
  \label{fig:state_machines:e}}
\subfigure[Instruction F]{\includegraphics[scale=0.3]{diagrams/statementF.pdf}
  \label{fig:state_machines:f}}
\subfigure[Instruction G]{\includegraphics[scale=0.3]{diagrams/statementG.pdf}
  \label{fig:state_machines:g}}
\subfigure[Instruction H]{\includegraphics[scale=0.3]{diagrams/statementH.pdf}
  \label{fig:state_machines:h}}
\subfigure[Instruction J, the proximal
  cause]{\includegraphics[scale=0.3]{diagrams/statementJ.pdf}
  \label{fig:state_machines:j}}
\caption{State machines produced for the example program in
  Figure~\ref{fig:broken_privatize}.  Internal states are indicated by
  diamonds, terminal states by ovals, and edges by lines.}
\label{fig:state_machines}
\end{figure*}

\subsection{The proximal cause}
\label{sect:prox_cause}
The first step is to locate the first point in the log at which
something has definitely gone wrong, and hence to obtain a direct
cause of the crash and to nominate one thread as being directly
responsible for it.  A naive approach would simply use the point at
which the program crashed.  In principle, this is always correct, and
for some simple bugs, such as \verb|NULL|-dereferences or assertion
failures, it works well.  However, for more complicated classes of
bugs, such as use-after-frees, there can be a significant lag between
the first definitely bad behavior (such as the use of released memory)
and the program crash, and this can reduce the effectiveness of later
phases.  This can be mitigated by applying a dynamic analysis tool,
such as Valgrind\cite{Nethercote2007}, to the captured execution,
which provides a more accurate starting point for the rest of the
analysis.  We have implemented a simple use-after-free detector as
part of our prototype; combining this with other forms of analysis or
with application-specific knowledge would be straightforward, and
would allow other classes of bugs to be detected.  The result of this
initial analysis is generally a state with only one internal state,
referred to as the proximal cause; for the example, it is shown in
Figure~\ref{fig:state_machines:j}.

\subsection{Deriving earlier state machines}
This proximal cause is accurate but not, by itself, sufficient to
derive a fix, as by the time the faulty instruction is executed it is
usually too late to attempt to fix it.  It is therefore useful to move
the expression backwards through the captured execution, and hence to
determine an equivalent expression which can be evaluated earlier.  We
do this inductively, moving back one instruction at a time through the
DRS log and deriving a state machine for each.  There are three main
classes of relevant instructions: register-register arithmetic
instructions, branches, and memory accesses; we consider each in turn
(more complicated instructions can generally be treated as
combinations of these basic classes).

\subsubsection{Arithmetic instructions}

We assume that we have a state machine corresponding to the point
immediately after the instruction in question, and we wish to
construct one corresponding to a point immediately before it.  If the
register-register arithmetic instruction is regarded as a
transformation on the program's register state then this can be
accomplished by applying the same transformation to the given state
machine.  For instance, in the example in
Figure~\ref{fig:broken_privatize}, the instruction preceding the
proximal cause is \verb|add $48, %rdx|.  This transforms \verb|rdx|
into \verb|rdx+48|.  Applying this transformation to the proximal
cause of the crash produces the state machine shown in
Figure~\ref{fig:state_machines:h}, which is valid at the start of
instruction \verb|H|.  Other simple register-to-register arithmetic
instructions can be handled in the same way, and hence the crash
reason can be backtracked across any sequence of such
instructions.\editorial{The reason this works is something to do with
  the underlying category of state machines being linear with respect
  to register-register instructions expressed as homomorphisms, but a)
  that's not really the kind of thing you say in a systems paper, and
  b) I don't understand it well enough to explain it correctly,
  anyway.}

\editorial{Our implementation uses libVEX to decode x86 instructions
  into a sequence of micro-operations which can be used as input to
  this process.} 

\subsubsection{Memory accesses}

Memory accesses are more difficult to handle, for three main reasons:

\begin{itemize}
\item The pointer aliasing problem\needCite{}: given a load and a
  store, it is not always clear whether they access the same memory
  location.
\item Non-determinism: due to the actions of other threads, it cannot
  be assumed that loading the same location twice will produce the
  same result.
\item Temporality: the exact order in which loads and stores are
  issued is often important in the kinds of synchronisation bugs which
  SLI targets, but the transformation-based approach used for
  arithmetic instructions does not preserve it.
\end{itemize}

We avoid these problems by leaving memory accesses explicit in the
state machines in most cases.  Because the memory accessing
instructions remain explicit in the state machines, we do not need to
be able to determine whether two pointers alias.  This is fortunate,
as doing so is difficult, even in a more conventional model checking
environment where higher-level information and programmer annotations
are available\needCite{}.

Consider again the example.  We have already illustrated how to
generate state machines for instructions \verb|J| and \verb|H|.  The
next instruction for which a machine must be derived is \verb|G|, as
that is immediately before \verb|H|.  This is simply the machine for
\verb|H| with \verb|rdx| replaced with \verb|load(rcx@G)|, because
instruction \verb|G| replaces \verb|rdx| with a load of the memory
location pointed at by \verb|rcx|.  This is shown in
Figure~\ref{fig:state_machines:g}.  Likewise, instruction \verb|F|
replaces \verb|rcx| with the contents of the memory location pointed
at by \verb|rsp|, and so the state machine for instruction \verb|F| is
as shown in Figure~\ref{fig:state_machines:f}.

Accesses to the local stack are an important exception.  Cross-thread
accesses to the stack are extremely rare, while intra-thread accesses
are extremely common, and so treating every stack access as being
potentially involved in a race significantly complicates the analysis
for little gain in power.  We therefore use a simple heuristic, based
on the contents of the DRS log, to attempt to resolve these accesses.
When we encounter a store instruction, we check through the DRS log to
determine whether it stored to the stack, and, if it did, which loads
then loaded the stored value.  If any of those loads occur in the
state machine after the store instruction then we assume that they
will always load the stored value, and so eliminate them.

\subsubsection{Branch instructions}
\label{sect:branch_instrs}
Branch instructions require more care, as they may involve parts of
the program which were not used in the captured execution and for
which no state machines will be available.  This would be simple if we
could assume that any change to the program's control flow would be
sufficient to avoid the bug, but this is not the case as many branches
are irrelevant to the observed bug.  Consider, for instance, this
example:

\begin{verbatim}
1   p = global_ptr;
2   if (!p->foo)
3       abort();
4   if (p->need_churn)
5       churn(p->bar->bazz);
\end{verbatim}

Assume that the program was observed to crash on line 5 because some
other thread was updating the structure and set \verb|need_churn|
before setting \verb|bar|.  \verb|foo| must have been true on line 2,
as otherwise the program would have aborted on line \verb|3|, and so
if one were to assume that any changes to the program's control flow
would be sufficient to avoid the bug then one would conclude that
ensuring that this code only ran when \verb|foo| is false would fix
the bug.  This is unlikely to lead to an effective solution.

We determine the effects of unexecuted code using a simple static
analysis.  We first build a fragment of the program's static control
flow graph starting from the branch instruction and stopping when we
encounter an instruction for which a state machine has already been
derived (or an indirect branch which we cannot predict; see
\S\ref{sect:indirect_branches})\footnote{We also impose a limit on the
  number of instructions examined, but we have never reached this
  limit in practice.}.  We then eliminate any loops in the graph using
a scheme described in \S\ref{sect:loops} and so produce a DAG of
instructions rooted at the branch instruction and whose leaves are
state machines which have already been derived.  These state machines
can then be propagated backwards through the graph using exactly the
same inductive algorithm as we use to move backwards through the
dynamic trace, allowing state machines to be derived for the internal
nodes of the graph and ultimately for the original state machine.

In the example, instruction \verb|F| could have been preceded by
either \verb|D| or \verb|E|.  Assume that in the observed crash it was
preceded by \verb|D| (or, to put it another way, that the branch at
\verb|D| was taken).  \verb|D| is a branch instruction, and,
statically, can be followed by either \verb|E| or \verb|F|.  \verb|E|
is always followed by \verb|F|, and a state machine has already been
derived for \verb|F|.  The CFG therefore contains just three nodes,
representing \verb|D|, \verb|E|, and \verb|F|, with edges from
\verb|D| to \verb|E| and \verb|F| and one from \verb|E| to \verb|F|.
We now search the CFG for any node which does not have a state machine
but whose successors do; in this case, only \verb|E| satisfies these
constraints, and so we will derive a state machine for it first.
\verb|E| is a store to a stack location, and so the stack resolution
heuristic is triggered.  Assuming that the store was ever executed in
the captured execution, it will predict that the load at \verb|F| will
load the stored value.  The load will therefore be eliminated, and so
the state machine for instruction \verb|E| will be as shown in
Figure~\ref{fig:state_machines:e}.  It is now possible to combine the
machines for \verb|E| and \verb|F| to produce one for \verb|D|.  This
is illustrated in Figure~\ref{fig:state_machines:d} (the left-hand
branch is the machine for instruction \verb|F| and the right-hand one
that for instruction \verb|E|).  The state machines for instructions
\verb|C|, \verb|B| and \verb|A| can now be derived using the
mechanisms already illustrated, producing the results shown in
figures~\ref{fig:state_machines:c}, \ref{fig:state_machines:b} and
\ref{fig:state_machines:a}.

Note that identical state machines would have been derived if the
program had not taken the branch immediately before crashing (which
might happen if the \verb|fallback| structure was itself invalid); the
only difference is that \verb|E|'s state machine will be derived from
the captured execution rather than a hypothetical execution generated
by static analysis.  This is useful: by eliminating uninteresting
aspects of the observed behavior, SLI is able to generalize from one
crash to closely related ones, and hence fix them at the same time,
without eliminating an excessive number of safe schedules.  This
example also illustrates that the stack resolution heuristic is not
equivalent to assuming a completely static data flow graph, as it is
interleaved with control flow discovery and hence respects simple
control-flow dependencies.  Separating the two processes into
independent phases would lose this property, and result in far less
accurate characterizations.\editorial{ref phase order problem?}

\subsubsection{Indirect branches}
\label{sect:indirect_branches}
Indirect branches, and any other branches which compute their target
dynamically, pose an additional challenge here, as it is generally
difficult to statically predict the target of the branch.
Fortunately, one common case is return instructions, and we can handle
these by inlining called functions.

Other indirect branch instructions are more challenging.  We solve
this problem by using the captured trace as a simple oracle: if the
branch instruction exists in the dynamic trace, we assume that the
instruction will always branch to the same place (if it occurs several
times then we use the last target).  If the instruction did not occur,
we place a special analysis-failed node in the graph.  Once the CFG is
complete, we eliminate all branches to these failed nodes; if that
causes some node to have no known successors then that node is also
marked as analysis-failed, and the process iterates until all failed
nodes are removed.  Branches taken in the captured execution will
always be preserved at this stage, as the oracle will always be able
to provide at least some prediction of their target.  As such, this
step can be seen as pruning the set of paths considered to be only
those which are sufficiently similar to the captured execution.

\subsubsection{Loops}
\label{sect:loops}
Loops also complicate this simple algorithm.  We avoid the problem by
breaking them, removing a subset of the graph's edges so as to
eliminate the loop.  We choose edges to remove based on two
heuristics.  First, we try not to remove any edges which are present
in the captured execution.  Second, we try not to partition the graph,
so as many instructions as possible --- and hence as much of the
program's behavior as possible --- are represented in the final state
machine.

Breaking loops has the useful side-effect of disambiguating the labels
used to refer to load instructions: in a loop-free control flow graph,
each instruction is executed at most once, and so dynamic instructions
can be referred to unambiguously by their static location in the CFG.
In the case of the x86 architecture, all common instructions which
perform multiple loads can be converted into loops, which can then be
broken in the usual way, and so this is sufficient to ensure that any
static instruction issues at most one dynamic load and hence that load
labels refer to at most one load.

\section{Locating relevant structures}

Once the abstract read operation has been suitably characterised, the
next step is to discover memory structures to which it can be applied.
Rather than attempting to represent these (potentially complicated)
structures explicitly, we instead represent them as specialisations of
the already-derived state machines.  In other words, we take each
state machine and convert it into a set of closely-related state
machines, each of which will check one particular dynamic instance of
the structure to be examined.

We rely on the DRS log in order to achieve this.  Our approach is
simply to identify all points in the log which are ``similar'' to the
point for which the state machine was originally derived and to create
a specialisation for each by substituting in appropriate constant
values for all references to thread-local state such as registers, and
stack locations.  This has the useful side-effect of ``detaching'' the
state machine from a particular point in the program's execution and
allowing it to be applied to other memory configurations.

Similar is defined here to mean that the instruction pointer and call
stack match.  A more flexible definition would allow more dynamic
instances of the structure to be discovered, and so more
potentially-conflicting updates would be discovered and a more
complete fix could be generated, but would increase the risk of
unrelated concrete operations being falsely identified as instances of
the dynamic operation, and hence memory locations being falsely
labelled as dynamic instances of the structure to be synchronized, and
hence the generation of overly-pessimistic fixes\editorial{Holly run
  on sentence, Batman.}.  We have not investigated this trade off in
any detail.

Dynamically allocated memory complicates this simple procedure.  The
specialisations, as described, in effect assume that memory locations
which are shared between threads have a form of type-stability in the
region of interest.  We mitigate this by limiting the range over which
the specialised state machines are applicable.  Newly-created
specialised state machines are evaluated at the point in the log at
which they are constructed, and a record kept of the memory locations
which they access.  If any of these locations were obtained through a
known dynamic allocator then the machine is restricted so that it is
only used between the point at which that memory was last allocated
and the point at which it is released (and if multiple locations are
dynamically allocated then their ranges of validity are intersected).
This effectively weakens the type-stability assumption, from assuming
that a particular memory location always has a particular type to
assuming that it can only be re-typed after being released and
re-allocated.\editorial{This isn't right: after specialisation, we
  could still refer to pointers in the heap, and we won't track
  validity of the referenced objects.  Probably doesn't matter in
  practice.}

We still assume that the read operation can be applied at any point
where the memory structure has the correct type, and ignore any
existing synchronisation or control flow properties of the program
which would restrict the situations in which it could be
used\footnote{This assumption also implies that we can identify all of
  the program's memory allocation APIs.}.  If this assumption is false
then SLI will produce an overly-conservative fix, synchronising the
read operation against write operations with which it could never
actually race, fixing the bug but with unnecessarily high performance
overhead.  This could be ameliorated using programmer-supplied
semantic annotations, but we have not needed to do so yet.

\section{Discovering possible racing write operations}
\label{sect:multi_threading}

Once the read operation has been identified and a suitable selection
of dynamic instances of the racing structure discovered, SLI can
proceed to investigate the crashing operation's interactions with
other threads, and thence to determine what additional synchronisation
would be necessary to prevent the observed crash.  Our approach has
two stages.  First, we determine which stores could possibly conflict
with loads of memory locations used by the read operation; this allows
us to make the read operation behave as-if atomically.  Second, we
determine if there are any regions in the DRS log where executing the
read operation atomically would still crash; these generally
correspond to update operations against which the read operation must
be synchronised.

Determining the possibly-conflicting stores is straightforward.  We
already have, from the previous analysis, a list of the memory
locations which each state machine loads, and it is then simple to use
the DRS log to discover all instructions which store to one of those
locations.  As before, we use calls to the memory allocator to
temporally scope memory locations and avoid synchronising against
accesses to other structures which simply happen to have been assigned
the same virtual addresses.

To determine the regions of the log when a state machine predicts a
crash, we replay the log over the range of validity of the state
machine and evaluate the state machine before and after every
possibly-conflicting store instruction.  In many cases, the machine
will always evaluate to \verb|no-crash|, which indicates that the read
operation is always safe when executed atomically and so no further
synchronisation needs to be added.  If the operation is not always
safe to execute atomically then there will be some \verb|crash|
regions in the log.  If the starting and ending stores of the region
are issued by the same thread then this corresponds to a simple update
of the memory structure, and all that is needed is for the relevant
range of instructions in the storing thread to be synchronised to not
run in parallel with the read operation.  Otherwise, the update
operation spans several threads, and SLI is unable to generate a fix.
In that case, we simply ignore the crashing region and synchronise
against any remaining stores.

\section{Producing a fix}
We now have, for each specialised state machine:

\begin{itemize}
\item The set of loads which it issues which might be involved in a
  race;
\item A list of ranges of the dynamic execution where issuing the read
  operation might be unsafe; and
\item A list of all of the static store instructions which might race
  with the read operation.
\end{itemize}

The task is to combine these, across all of the state machines, and
synthesize from them an appropriate fix for the observed bug.  For
SLI, the fix will consist of a newly-created global (recursive) lock
plus a number of lock acquire and release operations.  We must use
these to ensure that the read operation does not occur in parallel
with any of the store instructions, and does not occur during any of
the unsafe ranges.

As stated, this involves comparing ranges of the program's dynamic
execution to instructions or sets of instructions in its static image.
This is not entirely well-defined.  We must therefore either convert
the static instruction references to points in the dynamic execution
or dynamic ranges of execution to some suitable static representation;
we choose to convert the dynamic ranges to static ones.  In other
words, we will find some self-contained fragment of the program's
static control flow graph and declare that to be equivalent to the
dynamic range.

This is most straightforward if the dynamic range is contained
entirely within a single function invocation.  However, even this case
is not entirely trivial.  The most obvious approach is to simply
acquire the lock on the instruction which corresponds to the start of
the range and drop it again on the instruction which corresponds to
its end, but this is unsafe because there might be some other branch
in between the two instructions which would allow the lock to be
acquired but never released.  It would be possible to design a simple
analysis to detect such branches to and arrange to drop the lock if
one is ever taken, but this would cause any irrelevant branches (as
discussed in \S\ref{sect:branch_instrs}) to terminate the locked
region, causing the fixes to be much less effective.

We therefore use a more subtle approach.  Starting from an empty
control flow graph, we add every instruction which is executed in the
range, with branches to instructions not executed in the range
replaced with special stub instructions.  We expand the control flow
graph by exploring the code with is reachable from these stub
instructions until we reach an indirect branch (including the end of
the function), and then trim the graph back by removing any
instruction which cannot reach one of the instructions which was in
the original dynamic range.  The remaining instructions are precisely
those which are reachable from the instructions in the dynamic range
and which are able to return to it, and it is these instructions which
we protect.  Any branch outside of this set is treated as the end of
the critical section and modified so that it drops the lock.  The
instruction corresponding to the start of the dynamic range is
labelled as the CFG's entry point; this will be significant later.

In many cases the region to be protected will include multiple
function invocations.  Functions which are contained entirely within
the region are straightforward, and can be largely ignored: the
mechanism already described will ensure that we acquire the lock
precisely once before calling them, and release it precisely once
after they return\footnote{Abnormal control flow transfers such as
  longjmp break this pattern; we check whether the DRS log contains
  any such transfer out of the called function, and abort if it does,
  but do not otherwise handle them.}.  Function invocations which are
in progress at the start or end of the range are more challenging.  We
handle them by expanding the dynamic range at the start and end by the
minimum amount such that every function which is called after the
start of the dynamic range has returned before it ends, and hence
sidestep the problem.  Equivalently, we nominate the last stack frame
which is common throughout the range as being responsible for the bug
and then map any accesses made by functions called from that frame to
the relevant call instruction.

The set of loads is also expanded into a fragment of control flow
graph in much the same way.  Starting from a graph which contains just
the instructions which are to be protected, we expand forwards to the
end of the function and then trim any excess instructions.  We then
nominate some instructions as entry points of the graph, such that no
entry point can reach another one and every instruction is reachable
from at least one entry point.

The individual store instructions are also converted into trivial
single-instruction control flow graphs.

The CFGs are now converted into fragments of machine code which are
equivalent to the original code except:

\begin{itemize}
\item They can be safely relocated, updating instruction pointer-relative
  addresses as appropriate;
\item Any branches to other instructions in the CFG refer to the
  equivalent instructions in the new fragment of machine code; and
\item Any branches to instructions not in the CFG are modified to
  drop the lock before jumping.
\end{itemize}

\noindent
Sometimes code patches can overlap.  A moderate amount of care is
required to ensure that the resulting composite fix behaves correctly,
but this is not conceptually difficult provided that the lock is
recursively acquirable; see below for details.

The original program must now be modified such that instructions which
were labelled as entry points of a CFG now acquire the lock and branch
to the relevant instruction in the patch.  Other instructions in the
program are left unmodified; this ensures that paths which were not
considered while deriving the fix are unaffected.

Modifying entry point instructions is sometimes difficult, as the
instruction to be patched might be too small to encode a branch
instruction, and enlarging an instruction is dangerous unless one is
able to prove that the following instruction is never the target of a
branch.  SLI avoids this issue by using the processor's debugging
facilities to set breakpoints on the acquiring instructions, and then
transferring to the new code from the relevant exception handler.  On
x86 architectures, the breakpoint instruction is a single byte, and so
always fits in the instruction to be patched.

After all of the patches have been constructed, the resulting code can
be compiled into an ELF shared library which can be loaded into the
target program using \verb|LD_PRELOAD| (or an equivalent mechanism)
and which will apply the generated fix.  

There is a risk that the proposed fix will introduce a deadlock.  We
avoid this issue with a simple timeout scheme: if a thread takes more
than a second to acquire an SLI-introduced lock, it will time out, and
immediately jump back to the unpatched code.  This is sufficient to
ensure forward progress, but renders the purported fix ineffective and
could lead to very poor performance.  Fortunately, it has not been a
problem for us so far.

\subsection{Selecting a fix}
\label{sect:selectfix}

This process might produce multiple possible fixes if multiple state
machines are available, and it is then necessary to select an
appropriate one to instantiate into a binary patch.  Some can be
discarded by very simple heuristics (for instance, fixes in which
every atomic section is a single memory access can be immediately
eliminated), but there will in general be multiple possible fixes to
choose from.  We use a very simple cost heuristic to do so: the cost
of a fix is given by $U.n_u + C_s.n_s + {\sum_{i}}s_i$ where $n_u$ is
the number of crashing regions which we discarded because they started
and ended on different threads, $n_s$ is the total number of critical
sections, $s_i$ is the number of accesses in the $i$th critical
section, and $C_s$ and $U$ are constants reflecting the cost of
introducing a new empty critical section and of only partially fixing
the bug.  SLI then selects the candidate fix with the lowest cost.
Our prototype sets $U=1000$ and $C_s=10$, strongly preferring fixes
for which all unsafe states can be eliminated and weakly preferring
fixes with a smaller number of critical sections.

This simple heuristic has worked well in our experience to date
(\S\ref{sect:evaluation}), as there are generally only a small number
of possible fixes, all of which are correct and none of which would
obviously lead to pathological performance.

\subsection{Example}
\label{sect:final_example}

Our earlier example derived the state machine shown in
Figure~\ref{fig:state_machines:a} for the program shown in
Figure~\ref{fig:broken_privatize}.  The only register referenced in
the machine is \verb|rsp|, and so specialization will then simply
amount to substituting in constant values for that register.  This
will not affect the structure of the machine.  The only locations
accessed when evaluating this machine will be \verb|global1|,
\verb|fallback|, and \verb|variable1|.  None of these are dynamically
allocated, and so the machine is valid throughout the log.  The
possibly-conflicting stores list will then consist of every dynamic
instance of instructions \verb|V|, \verb|W|, \verb|X|, and \verb|Y|.

\begin{figure}[thb]
\includegraphics[scale=0.3]{diagrams/specialise_3.pdf}
\caption{Results of specialising Figure~\ref{fig:state_machines:a}}
\label{fig:specialised_example_machine}
\end{figure}

We now move on to identifying the unsafe regions in the log.  This
requires us to evaluate the state machine before and after every
possibly-conflicting store.  In this case, this will always evaluate
to \verb|no-crash|, which is correct: if the reader were executed
atomically, it would never crash, regardless of what state the writer
was in.  There are therefore no unsafe regions, and the instructions
to be protected are simply:

\begin{itemize}
\item All of the loads issued by thread 1 which are mentioned in the
  state machine.  In this case, there are only two; \verb|A| and
  \verb|G|.
\item The instruction \verb|V|.
\item The instruction \verb|W|.
\item The instruction \verb|X|.
\item The instruction \verb|Y|.
\end{itemize}

We must now construct appropriate code patches.  Consider the load set
(the store instructions are trivial).  The control flow graph will in
this case contain every instruction from \verb|A| to \verb|G| in
Figure~\ref{fig:broken_privatize} and \verb|A| will be nominated as
the entry point.  The patch will therefore consist of duplicates of
those instructions followed by a lock release operation and a branch
back to instruction \verb|H|, and instruction \verb|A| will be
modified to acquire the lock and jump to the start of the patch.  Note
several important properties of this patch:

\begin{itemize}
\item When the branch instruction at \verb|D| is duplicated, it is
  rewritten such that both the taken and untaken exits point into the
  new patch, rather than into the original code.
\item The instruction which crashed, \verb|J|, is not included in any
  critical region.  By the time instruction \verb|J| executes, the
  race has already happened, and so it is too late to try to prevent
  it and protecting that instruction would not be helpful.
\item If the program enters the code shown in
  Figure~\ref{fig:broken_privatize}'s thread 1 anywhere other than
  instruction \verb|A| it will not be affected by the patch.  In
  particular, there is no danger of the lock being released without
  first being acquired.  However, the program will not be protected
  against any other possible races.
\item The fix is correct: it completely eliminates the observed bug.
\end{itemize}

This is not the only fix which will be suggested, however.  State
machine generation will also have produced machines for other
instructions in the crashing thread.  Consider, in particular, the
state machine shown in Figure~\ref{fig:state_machines:f}.  As this
accesses both registers and the stack, it can be specialized.  Assume
now that the DRS log contains at least one instance of the read
operation in which the branch at \verb|D| is taken and one in which it
is not.  In that case, there will be two specialisations, shown in
Figure~\ref{fig:example_specialisations}, one corresponding to the
branch-taken case and one to the branch-not-taken one.

\begin{figure}[thb]
\subfigure[Branch taken]{\includegraphics[scale=0.34]{diagrams/specialise_1.pdf}
  \label{fig:specialise_taken}}
\subfigure[Branch not taken]{\includegraphics[scale=0.34]{diagrams/specialise_2.pdf}
  \label{fig:specialise_not_taken}}
\caption{Results of specialising Figure~\ref{fig:state_machines:f}}
\label{fig:example_specialisations}
\end{figure}

These machines produce another suggested fix.  Machine
Figure~\ref{fig:specialise_taken} will predict a crash whenever
\verb|variable1| is zero, i.e. whenever thread 2 is between
instructions \verb|Y| and \verb|V|, and so there will be at least one
unsafe dynamic range.  Assume for the sake of exposition that there is
precisely one such range.  The CFG will contain all of the
instructions from \verb|Y| to \verb|V|, crossing the back edge of the
loop.  A patch will be created which duplicates these instructions
before dropping the lock and jumping back to instruction \verb|W|, and
instruction \verb|Y| will be modified to acquire the lock and branch
to this patch, as shown in Figure~\ref{fig:patch1}.

\begin{figure}
  \begin{subfloat}
    \begin{minipage}{60mm}
\begin{verbatim}
V: mov &struct1 -> (variable1)
W: mov &variable1 -> (global1)
...
X: mov $0 -> (global1)
Y: acquire_and_jmp Y'
U: ...
Z: jmp V
\end{verbatim}
    \end{minipage}
  \end{subfloat}
  \begin{subfloat}
    \begin{minipage}{50mm}
\begin{verbatim}
Y':  mov $0 -> (variable1)
U':  ...
Z':  jmp V'
V':  mov &struct1 -> (variable1)
a:   release()
b:   jmp W
\end{verbatim}
    \end{minipage}
  \end{subfloat}
  \caption{Partial patch based on the state machine in figure~\ref{fig:specialise_taken}.}
  \label{fig:patch1}
\end{figure}

The only load instruction mentioned in the state machines is \verb|G|,
and that will be instantiated into a trivial single-instruction patch
as the store instructions were in the previous example.

The potentially conflicting stores will be \verb|Y| and \verb|V| in
this case.  These are more interesting, as they overlap with the
existing critical section.  In particular, there are now two versions
of \verb|V| in the program (the original version and the one in the
previous patch), and both must be patched, while \verb|Y|, as the
entry point of the previous patch, has been effectively moved, and the
new version is the one which must be patched.  The resulting patch set
will be as shown in Figure~\ref{fig:patch2}.  These patches will also
fix the bug, and, assuming that there are only a small number of
instructions between \verb|Y| and \verb|Z|, they will be preferred by
the prioritisation heuristic, because they require fewer critical
sections.

\begin{figure}
  \begin{subfloat}
    \begin{minipage}{60mm}
\begin{verbatim}
V: jmp V''
W: mov &variable1 -> (global1)
...
X: mov $0 -> (global1)
Y: acquire_and_jmp Y'
U: ...
Z: jmp V
\end{verbatim}
    \end{minipage}
  \end{subfloat}
  \begin{subfloat}
    \begin{minipage}{50mm}
\begin{verbatim}
Y':  acquire_and_jmp Y''
U':  ...
Z':  jmp V'
V':  jmp V'''
a:   release()
b:   jmp W
\end{verbatim}
    \end{minipage}
  \end{subfloat}
  \begin{subfloat}
    \begin{minipage}{50mm}
\begin{verbatim}
Y'': mov $0 -> (variable1)
     release()
     jmp U'
\end{verbatim}
    \end{minipage}
  \end{subfloat}
  \begin{subfloat}
    \begin{minipage}{50mm}
\begin{verbatim}
V'': mov &struct1 -> (variable1)
     release()
     jmp W
\end{verbatim}
    \end{minipage}
  \end{subfloat}
  \begin{subfloat}
    \begin{minipage}{50mm}
\begin{verbatim}
V''':mov &struct1 -> (variable1)
     release()
     jmp a
\end{verbatim}
    \end{minipage}
  \end{subfloat}
  \caption{Complete patch based on the state machine in
    Figure~\ref{fig:specialise_taken}, extending
    Figure~\ref{fig:patch1}.}
  \label{fig:patch2}
\end{figure}

It could be argued that this smaller fix is inferior to the larger
alternative, despite completely eliminating the crash and potentially
imposing lower overhead, as it is less ``sympathetic'' to the existing
structure of the program.  The author of thread 2 had presumably
intended to privatize the structure at instruction \verb|X|, and so
might reasonably have defined a ``correct'' fix to be one which
ensures correct privatization, a goal which is achieved by the first
fix but not by the second.  SLI, by contrast, has no notion of
intended behavior, or indeed any form of good software engineering
practice, and so selects its fix based on the more mundane concerns of
avoiding the crash and minimizing the impact on performance.  This is
both a strength and a weakness: a strength in that it increases the
likelihood that a low-overhead fix will be found, and a weakness in
that the fixes cannot be translated back to source-level patches and
applied unthinkingly by the application programmer.

Producing a long-term, maintainable fix for a bug is, in general, a
different problem to producing a short-term one which simply
eliminates its symptoms, and the techniques used by SLI are much more
applicable to the latter.  This will be true of any approach which
does not rely on programmer annotations (ignoring trivial systems
which just pattern-match the buggy code against a library of common
bugs and their standard fixes).\editorial{This could do with being a
  bit earlier.}

\section{Evaluation}
\label{sect:evaluation}

\begin{table*}
\begin{tabular}{lllllll}
Name of test & Nature                 & Number of & Size of logfile & Number of & Total number of \\
             &                        & fixes     &                 & state machines & state machine states \\ \hline
toctou       & Synthetic TOCTOU race  & 1        & 28MiB   & 9 & 19\\
twovar       & Synthetic two-variable & 1        & 31MiB   & 13 & 31\\
             & atomicity violation    &          & \\
publish      & Synthetic broken       & 2        & 31MiB   & 8 & 24 \\
             & publish pattern        & \\
privatize    & Synthetic broken       & 2        & 43MiB   & 9 & 25 \\
             & privatize pattern      & \\
\hline
glibc        & Kernel of a genuine    & 8        & 48MiB   & 19 & 139\\
             & atomicity violation    &          & \\
\hline
thunderbird  & Genuine TOCTOU         & 1        & 758MiB  & 7 & 15
\end{tabular}
\caption{Summary of the results for each test case.}
\label{tab:output_summary}
\end{table*}

\begin{table*}
\begin{tabular}{lllll}
Name of test & Total time taken & Loading initial memory image & Replaying logfile & All analysis phases \\ \hline
toctou       & $ 0.51 \pm 0.01$ & $ 0.18 \pm 0.01$     & $ 0.19 \pm 0.00$ & $ 0.15 \pm 0.00$\\
twovar       & $ 0.75 \pm 0.01$ & $ 0.18 \pm 0.01$     & $ 0.42 \pm 0.00$ & $ 0.14 \pm 0.00$\\
publish      & $ 0.48 \pm 0.03$ & $ 0.18 \pm 0.02$     & $ 0.17 \pm 0.00$ & $ 0.13 \pm 0.00$\\
privatize    & $ 2.34 \pm 0.78$ & $ 0.18 \pm 0.02$     & $ 1.04 \pm 0.01$ & $ 1.12 \pm 0.75$\\
\hline
glibc        & $ 2.46 \pm 0.06$ & $ 0.19 \pm 0.01$     & $ 1.20 \pm 0.05$ & $ 1.07 \pm 0.02$\\
\hline
thunderbird  & $ 356  \pm 1$    & $ 1.76 \pm 0.02$     & $ 354  \pm 1$    & $ 0.58 \pm 0.01$\\
\end{tabular}
\caption{Time taken for the various phases of operation, in seconds.
  Mean and standard deviation of analysing a single reproduction five
  times.}
\label{tab:perf_summary}
\end{table*}

As shown in tables \ref{tab:output_summary} and
\ref{tab:perf_summary}, our prototype implementation is able to fix a
reasonable selection of artificial bugs within a few seconds, given
only the program binary and a log which shows the bug reproducing, and
is able to fix at least one real-world bug in a little over five
minutes.  The data also shows that the prototype avoids state machine
explosion, generating only a small number of distinct state machines
each of which has only a small number of states (a little under four
on average, and in no case more than twenty-three).  All experiments
were conducted on an Intel Q6600 with 8GiB of RAM running 64-bit Linux
2.6.28.

One important observation here is that while the total time taken by
the \verb|thunderbird| bug was much greater than for any of the other
bugs, the bulk of this time was spent in the replay engine and the
remainder in loading the larger memory image, with the time spent in
the analysis phases largely unchanged.  This is encouraging.  One
obvious criticism of this kind of approach is that it might suffer an
equivalent of the model checking state explosion problem and hence
collapse when faced with bugs in realistically-sized programs, and if
that were happening then it would show up as an increase in the time
spent in the analysis phases.  This has clearly not happened in this
case.

We also investigated how the analysis depends on the exact way in 
which a particular bug is reproduced, by running our tool
on five independent reproductions of the \verb|glibc| bug.  Every
reproduction produced the same set of state machines and suggested
fixes.  The time taken by the analysis process varied significantly,
however (from eight to thirteen seconds), mostly because the time
taken to reproduce the bug varied and hence produced differently sized
logs to be parsed. Similar results were obtained for the other
bugs.\editorial{Not sure this is all that interesting, or that I've
  phrased it very well...}

\subsection{Effects of backtracking further}
\label{sect:eval:backtrack}

One important parameter to the system is how far to backtrack through
the crashed thread, and hence how many state machines to generate,
before attempting to derive a fix.  For implementation reasons, our
prototype will always backtrack to a branch instruction, and for the
above tests we limited this backtracking to ten branches.
Figure~\ref{fig:eval:backtrack} shows the effect of changing this
parameter on the time taken by the non-replay components of the
\verb|thunderbird| test (the replay components were unchanged).  It
can be seen that the time taken increases moderately as the distance
which we backtrack increases, from $0.57$ seconds when backtracking
three branches to $0.90$ seconds when backtracking fifty.  None of our
tests depend on more than three levels of backtracking to produce a
correct fix (and the \verb|thunderbird| test requires just one), and
so this suggests that SLI should be able to backtrack sufficiently to
solve most bugs without requiring excessive resources.\editorial{Meh.}

\begin{figure}
\includegraphics{clog/clog.pdf}
\caption{Time taken by the analysis phases of the thunderbird bug, in
  seconds, versus the level of backtracking applied to the crashed
  thread, in dynamic branches.  Mean and standard deviation of five
  runs.}
\label{fig:eval:backtrack}
\end{figure}


\subsection{Detailed discussion of test bugs}
\label{sect:bug_descr}

We now discuss our test bugs in more detail.

\verb|toctou| is a simple two-thread time-of-check, time-of-use race.
In this test, one thread loops incrementing a counter, while another
thread repeatedly issues pairs of loads of the counter and asserts
that the loads returned the same value.  Our prototype generates a
single suggested fix consisting of two critical sections, one
protecting the write-back of the incremented counter in the first
thread and the other protecting the two loads in the second thread.
This is a correct and minimal fix.

\verb|twovar| is a two-variable atomicity violation.  In this test,
there are two global variables, and one thread loops setting both to 5
and then setting both to 7 while another thread loops loading both and
asserting them to be equal.  SLI again produces a single correct fix
in this case.  The core of the second thread consists of two
instructions:

\begin{verbatim}
l1: mov (global1) -> %rax
l2: cmp %rax, (global2)
    jne __assert_fail
\end{verbatim}

The state machine for \verb|l1| is

\begin{verbatim}
if load(global1@l1) != load(global2@l2)
 then crash
 else no-crash
\end{verbatim}

\noindent
This produces a single candidate fix, consisting of two critical
sections: one protecting instructions \verb|l1| and \verb|l2| in the
second thread, and four single-instruction sections each of which
protects a single store in the other thread.  This correctly
eliminates the bug.  Note that, as this bug involves two variables, it
would not be eliminated by Kivati\cite{Chew2010a}.

\verb|publish| is a buggy implementation of the publish pattern.  In
this pattern, a structure is initialized by one thread and then
published by writing its address into a global pointer.  Other threads
then occasionally read this global pointer and, if it contains a
non-\verb|NULL| pointer, use the referenced object.  This is safe if
correctly implemented, but in this test the programmer published the
structure before finishing constructing it, which leads to the other
thread eventually crashing.  The test case consists of two threads,
one of which repeatedly publishes and un-publishes a structure and the
other of which repeatedly tests whether it has been published and, if
it has, attempts to use it in a way which leads to an immediate crash
if initialization is not complete.  Note that in this case the bug is
in the publishing thread, but the crash is observed in the consuming
one.

Our tool produced two suggested fixes in this case.  One of these was
expected, consisting of two critical sections, one protecting the
consuming thread from the point at which it loaded the pointer to the
point at which it used its contents and the other protecting the
producing thread from the point at which it published the structure to
the point at which it finished initializing it.  This is a correct
fix.

The other suggestion was somewhat surprising.  Our test harness
repeatedly published, initialized, unpublished, and then deinitialized
the same structure.  SLI was able to look through this pattern, and
determined that it was sufficient to prevent the consuming thread from
validating the published structure at any point between the
deinitialization in one iteration and the initialization in the
subsequent one.  It therefore suggested a fix which protected the load
which the consuming thread used to perform validation in one critical
section and the range of the publishing thread from the
deinitialization to the subsequent initialization in another,
completely ignoring the accesses related to publishing and
un-publishing the structure.  While somewhat surprising, this is also
a correct fix, completely preventing the observed bug, and, as it
produces slightly smaller critical sections, might preserve a greater
degree of concurrency than the more obvious one.  In this case, SLI
has produced a fix which is actually better than might be expected of
a purely manual process, precisely because it operates at a very low
level without any reference to the program's intended semantics.

\verb|privatize| is the converse of \verb|publish|: a thread is
attempting to make a structure private, and does it incorrectly.  It
is similar to the example program in Figure~\ref{fig:broken_privatize}, which has already been extensively
discussed.

\verb|glibc| is a kernel of glibc bug 2644 \cite{glibc2644}, which
affected versions of glibc up to 2.5 and could lead to a crash if
multiple threads were shut down at the same time.  A simplified
version of the code involved is shown in Figure~\ref{fig:glibc}, where
\verb|forcedunwind| and \verb|done_init| are global variables.  Note
that the bug here depends on the compiler's optimizer, and is not
apparent at the source-code level\footnote{Unfortunately, only the
  32-bit x86 version of gcc optimizes the function like this, and our
  implementation of SLI assumes a 64-bit x86 program, and this
  prevented us from testing with the real bug.}.  SLI operates
entirely at the machine-code level, and so this does not present any
additional complexity.

\begin{figure*}
  \begin{subfloat}
    \begin{minipage}{52mm}
\begin{verbatim}
_Unwind_ForcedUnwind() {
   if (forcedunwind == NULL)
      pthread_cancel_init();
   forcedunwind();
}
pthread_cancel_init() {
   if (done_init) return;
   forcedunwind =
     _forcedunwind_impl;
   done_init = 1;
}
\end{verbatim}
    \end{minipage}
    \caption{Before optimizations}
  \end{subfloat}
  \begin{subfloat}
    \begin{minipage}{52mm}
\begin{verbatim}
  _Unwind_ForcedUnwind() {
1:  l = forcedunwind;
2:  if (l == NULL &&
3:      done_init) {
4:    forcedunwind = l =
5:       _forcedunwind_impl;
6:    done_init = 1;
7:  }
8:  l();
  }
\end{verbatim}
    \end{minipage}
    \caption{After optimizations}
  \end{subfloat}
  \begin{subfloat}
    \begin{minipage}{35mm}
\begin{verbatim}
    while (1) {
10:   pthread_barrier_wait();
11:   _Unwind_ForcedUnwind();
12:   pthread_barrier_wait();
13:   done_init = 0;
14:   forcedunwind = NULL;
    }
\end{verbatim}
    \end{minipage}
    \caption{Test harness}
  \end{subfloat}
  \label{fig:glibc}
  \caption{Source code for the glibc test case.}
\end{figure*}

SLI produced six suggested fixes when run on a log generated by
running this test.  The first of these had five critical sections: one
covering the load on line \verb|1| to the load of \verb|done_init| on
line \verb|3|, and one each for each of the stores on lines \verb|4|,
\verb|6|, \verb|13|, and \verb|14|.  The other suggestions were
supersets of this suggestion, extending it to include various accesses
in \verb|pthread_barrier_wait|.  This illustrates an important
weakness of the approach.  Because SLI does not know anything about
any OS-provided functionality, it cannot take advantage of any
existing synchronization present in the program (in this case, the
\verb|pthread_barrier_wait|s make the critical sections protecting
statements \verb|13| and \verb|14| redundant).  It also means that the
analysis must explore these standard functions, and can sometimes
attempt to ``fix'' the benign races inherent in synchronization
operations, which is unlikely to be productive.

\verb|thunderbird| is Mozilla bug number
391259\cite{thunderbird39125}, a simple time-of-check, time-of-use
race in the IMAP client component of Thunderbird, a popular
open-source e-mail client.  We modified Thunderbird to include some
additional debugging messages and used a custom scheduler in order to
make the bug reproduce more readily; the test is otherwise identical
to the behavior which a user might have encountered.  The relevant
parts of the program are as follows:

\begin{verbatim}
void nsImapProtocol::CloseStreams() {
  if (m_transport)
      m_transport = nsnull;
}
PRBool nsImapProtocol::ProcessCurrentURL() {
  if (m_transport)
    m_transport->SetTimeout(
      TIMEOUT_READ_WRITE, PR_UINT32_MAX);
}
\end{verbatim}

\noindent
If \verb|m_transport| is set to \verb|nsnull| by \verb|CloseStreams()|
in between the two accesses in \verb|ProcessCurrentURL| then the
program will crash.  This is essentially the same bug as
\verb|toctou|, but embedded in a much large program.  As such, the
final result is similar: a single suggested fix, with two critical
sections, one containing the two accesses in \verb|ProcessCurrentURL|
and one containing the assignment in \verb|CloseStreams|.  This fixes
the bug.

\section{Related work}\editorial{This is a bit of a bestiary.  Could do with a bit more analysis.}

A number of previous systems have tackled similar problems.  Most
recently, Kivati\cite{Chew2010a} attempts to fix single-variable
atomicity violations automatically by combining a static analysis pass
with some runtime support.  The result is able to prevent many common
kinds of race-like bugs with low overhead.  There are several
important differences between their approach and ours:

\begin{itemize}
\item SLI is only activated once a bug has been observed, whereas
  Kivati runs at all times.  This means that it is more likely to
  ``fix'' perfectly benign races.  It also means that the fixes cannot
  easily be applied without also requiring the Kivati runtime,
  whereas, once generated, SLI fixes can stand alone without any of
  the rest of the SLI infrastructure.  In other words, while SLI's
  overheads are higher (due to the use of a DRS), they are only paid
  until a fix is generated for the nominated bug, whereas Kivati's
  must be paid for as long as the program is to be protected.
\item Kivati requires access to the program's source code during the
  initial static analysis phase, whereas SLI requires only the binary.
\item SLI can be applied to a wider class of bugs than Kivati, such as
  the \verb|twovar| example described above.
\item Kivati is, however, often able to prevent bugs which have never
  been seen, whereas SLI must observe the program crash at least once
  before attempting a fix; this might make it more useful if the
  program to be protected has a large number of extremely unlikely
  bugs, rather than a small number of moderately unlikely ones.
\end{itemize}

Another approach, taken by systems such as Isolator
\cite{Ramalingam2009} and ToleRace\cite{Ratanaworabhan2008}, restricts
the problem domain to asymmetric races, where one thread is correctly
following a locking discipline while some other thread is not, and
seeks to ensure that the correct thread continues to be correct
despite the misbehavior of the incorrect one.  This might, for
instance, be useful if the correct thread is controlled by an
application while the incorrect one is controlled by a library which
the application writer is unable to modify.  As with Kivati, they do
not target specific bugs.\editorial{...}

Atom-Aid\cite{Lucia2009} also attempts to mitigate race bugs, in
this case by using hardware transactional memory to
bundle sequences of memory accesses into
transactions according to some heuristics.  This reduces the
number of permissible schedules and hence the scope for memory
ordering related bugs.  Provided the necessary hardware is available,
this is simple and reasonably efficient, and should eliminate a
reasonable selection of non-trivial bugs.  The main downside of the
approach is that it requires non-standard (and presently non-existent)
hardware, which makes it less practically useful than it otherwise
would be.

Dimmunix\cite{Jula2008} solves the closely-related problem of
preventing deadlocks in code which uses mutex-like synchronisation.
It relies, as SLI does, on having observed the bug at least once, and
then synthesises additional synchronisation which prevents it from
re-occurring.  The most important difference is that whereas Dimmunix
need only be concerned with lock operations, which are relatively
rare, SLI must consider memory accesses, which are extremely common,
and this requires the use of somewhat different techniques.
Gadara\cite{Wang2008} also attempts to solve deadlock bugs using a
completely different offline analysis to detect bugs before they
happen, but requires access to the program's source code, which may
not always be available.

There have also been a number of attempts to automatically fix heap
management bugs, such as buffer overflows and use-after-free errors,
including AutoPaG\cite{Lin2007} and Exterminator\cite{Novark2007}.
These systems both take an example of a buffer overflow bug (assumed
to be deterministic) and use various analyses to determine the root
cause of the bug, eventually using this to produce a potential fix.
In that, they are remarkably similar to the system currently under
discussion; the main difference being the type of bug targeted.

All of these systems attempt to fix bugs or otherwise prevent them
from happening.  An alternative strategy is to make errors less
serious when they do happen.  The most famous example of such a
strategy is probably failure obliviousness\cite{Rinard2004}, which
waits until the protected program makes an invalid memory reference
and then attempts to fix it from the resulting exception handler.
DieHard\cite{Berger2006} is conceptually similar, but works
preemptively rather than from a fault handler, by guessing where
memory errors are likely to occur and modifying the program's memory
map to make those errors as harmless as possible.  In this way
programs are able to continue executing in spite of the presence of
errors which would otherwise cripple them.  Failure obliviousness
cannot, however, completely remove any errors, and so can be seen as
complementary to the other schemes discussed here.

RX\cite{Qin2007} takes a third strategy.  Here, rather than
attempting to fix the bug, an attempt is made to determine which
subset of a program's functionality is bug-free, and then to restrict
the program's inputs to only exercise that functionality.  The result
is that inputs which might have triggered the bug continue to produce
incorrect output, but the damage is at least contained rather than
propagating throughout the program and potentially leading to a crash.
This is arguably safe, although not according to the definition used
in this paper, and can cover a wide variety of bugs with little
overhead.

All of these approaches are primarily dynamic in nature.  There have
also been many systems which attempt to detect races using static
analysis, such as \cite{Pratikakis2006} or \cite{Engler2003}, or via
model checking, such as \cite{Elmas06preciserace}.  These techniques
have the advantage that the bug to be fixed does not first have to be
exhibited (and, indeed, they are often used to discover bugs in code
which has never been run) and have precisely no runtime overhead, so
are attractive wherever they are applicable.  However, many programs
have sufficiently complicated structures that a sound static analysis
is impractical, and they cannot as easily compensate for this by
taking advantage of any exhibition which might be available or by
being directed towards fixing a specific bug.  Bugs which can be
exhibited are likely to be more important than those which have never
been seen, and so this is often a significant
limitation. \editorial{...}

\section{Future work}

There are a number of potential extensions of this work, beyond the
obvious ones of broadening the evaluation and improving performance.
At a high level, SLI must balance the use of static analysis, which
considers many possible executions and produces general fixes, and
dynamic analysis, which considers only the observed execution and
produces much more targeted fixes.  We do not claim to have found the
optimal combination of these two approaches, or even that a global
optimum exists; better characterizing the trade-offs involved is
likely to suggest useful improvements.

There may also be scope for significantly optimising the DRS used.
SLI, at present, collects an enormous amount of information which it
then discards, and collecting less information could lead to
worthwhile performance improvements.

There is a similar balance to be struck between attempting to be
completely generic and using semantic knowledge, both of the program
and of its libraries.  At present, we make very little use of this
information, and so our implementation is generic across a wide range
of applications but struggles with more complicated bugs.
Incorporating more semantic information, or providing a generic way
for programmers to introduce their own semantic models, might improve
our ability to produce useful, performant fixes.  One particularly
intriguing approach would be to combine SLI with an invariant
inference scheme such as Daikon\cite{Ernst2007} or
DIDUCE\cite{Hangal2002}, which would allow us to obtain such semantic
information without compromising SLI's current ability to run on
almost arbitrary unmodified binaries.  We intend to investigate this
idea more fully in the future.

The current timeout-based mechanism for avoiding deadlocks is also a
weakness, and can lead to poor performance or incompletely fixed bugs.
This could be ameliorated to some extent by using further static
analysis to detect which patches are likely to lead to deadlocks and
to penalize them in the fix selection phase.  Alternatively, SLI could
be integrated with a deadlock immunity system such as
Dimmunix\cite{Jula2008}, which would detect and fix deadlocks when
they happen.  The system would then hopefully converge on a state
which is both deadlock and race free.

\section{Conclusions}

We have presented SLI, a system for automatically fixing specific
synchronization bugs in shared-memory programs using only their
binaries, with minimal user intervention.  We have demonstrated that
it can be used to fix real-world bugs in at least some cases, and
discussed the compromises and trade-offs which are necessary in order
to produce a practically useful implementation.  While these
techniques do have a number of limitations and drawbacks, we feel that
they provide a useful basis for ongoing work to extend the set of
situations in which they are applicable.\editorial{Wibble wibble
  wibble}

\bibliographystyle{abbrv}

\bibliography{library}

\end{document}

